{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformers: Create your own poem! with AI_Train.ipynb",
      "provenance": [],
      "mount_file_id": "1xWtxFtplWzx7f6ZTEWcjLshe7KXwmPA8",
      "authorship_tag": "ABX9TyOcHizIeSrj3151MJlY7S+c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ancastillar/Transformers-Create-your-own-poem-/blob/main/Transformers_Create_your_own_poem!_with_AI_Train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import libraries"
      ],
      "metadata": {
        "id": "4B9XFhexfkY5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Abywl7XSNs8",
        "outputId": "05741257-af2b-451f-814e-cea92a438b8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: aitextgen in /usr/local/lib/python3.7/dist-packages (0.5.2)\n",
            "Requirement already satisfied: transformers>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from aitextgen) (4.20.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from aitextgen) (1.11.0+cu113)\n",
            "Requirement already satisfied: pytorch-lightning>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from aitextgen) (1.6.4)\n",
            "Requirement already satisfied: fire>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from aitextgen) (0.4.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire>=0.3.0->aitextgen) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from fire>=0.3.0->aitextgen) (1.15.0)\n",
            "Requirement already satisfied: torchmetrics>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (0.9.2)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (4.1.1)\n",
            "Requirement already satisfied: protobuf<=3.20.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (3.17.3)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (2.8.0)\n",
            "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (2022.5.0)\n",
            "Requirement already satisfied: pyDeprecate>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (0.3.2)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (6.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (4.64.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (3.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning>=1.3.1->aitextgen) (3.0.9)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.6.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.37.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.4.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (57.4.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.46.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (3.3.7)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (3.2.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.5.1->aitextgen) (0.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.5.1->aitextgen) (3.7.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.5.1->aitextgen) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.5.1->aitextgen) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (2.0.12)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (1.3.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (21.4.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (6.0.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (0.13.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (1.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (1.7.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.7/dist-packages (0.0.25)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (0.12.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: Jinja2>=2.4 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n",
            "Requirement already satisfied: click>=2.0 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous>=0.21 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug>=0.7 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.4->Flask>=0.8->flask-ngrok) (2.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: flask==0.12.2 in /usr/local/lib/python3.7/dist-packages (0.12.2)\n",
            "Requirement already satisfied: itsdangerous>=0.21 in /usr/local/lib/python3.7/dist-packages (from flask==0.12.2) (1.1.0)\n",
            "Requirement already satisfied: Jinja2>=2.4 in /usr/local/lib/python3.7/dist-packages (from flask==0.12.2) (2.11.3)\n",
            "Requirement already satisfied: Werkzeug>=0.7 in /usr/local/lib/python3.7/dist-packages (from flask==0.12.2) (1.0.1)\n",
            "Requirement already satisfied: click>=2.0 in /usr/local/lib/python3.7/dist-packages (from flask==0.12.2) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.4->flask==0.12.2) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install aitextgen\n",
        "!pip install flask-ngrok\n",
        "!pip install flask==0.12.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "#Visualizations\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "sns.set(rc = {'figure.figsize':(35,10)})\n",
        "sns.set_palette(\"Paired\")\n",
        "sns.set_style(\"white\")\n",
        "from flask import Flask, request, render_template\n",
        "from flask_ngrok import run_with_ngrok\n",
        "\n",
        "##########Models\n",
        "from aitextgen import aitextgen\n",
        "import torch\n",
        "import sys\n",
        "import os\n",
        "import random\n",
        "import time \n",
        "import datetime\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    current_device = torch.cuda.current_device()\n",
        "    print(\"Available GPUs: \", torch.cuda.get_device_name(current_device))\n",
        "    print()\n",
        "\n",
        "!nvidia-smi\n",
        "\n",
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, GPT2Config, AdamW, get_linear_schedule_with_warmup, GPT2TokenizerFast\n",
        "from torch.utils.data import Dataset, random_split, DataLoader, RandomSampler, SequentialSampler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAInlBf8TN3_",
        "outputId": "2d6c940c-6d25-4995-9d1e-11773d91fd0c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available GPUs:  Tesla T4\n",
            "\n",
            "Sun Jul  3 17:34:04 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   73C    P0    33W /  70W |  10626MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Data"
      ],
      "metadata": {
        "id": "UM66iavGf3aQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "col_poem = \"stanza_text\"\n",
        "\n",
        "#------------------------------------------------\n",
        "\n",
        "df_poems = pd.read_csv(\"/content/drive/MyDrive/proyecto_NLP/data/poe_poems_stanzas.csv\")\n",
        "df_poems = df_poems[(df_poems[col_poem].notna()) & (df_poems[col_poem]!=\" \")]\n",
        "\n",
        "df_poems = df_poems.drop(137, axis=0)\n",
        "print(\"Dimension of datase:\", df_poems.shape)"
      ],
      "metadata": {
        "id": "Cj-VEZsSTvgj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e76a36f7-91c4-40af-c2ac-9f3d85150c2d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimension of datase: (214, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##沒 Global Functions"
      ],
      "metadata": {
        "id": "vbAy8fYFjuTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PoemDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, data, tokenizer, max_length, gpt2_type='gpt2'):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.input_ids = []\n",
        "        self.attn_masks = []\n",
        "        \n",
        "        for i in data:\n",
        "          \n",
        "            encodings_dict = tokenizer('<BOS>' + i + '<EOS>',\n",
        "                                     truncation=True,\n",
        "                                     max_length=max_length,\n",
        "                                     padding='max_length'\n",
        "                                    )\n",
        "\n",
        "            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
        "            self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
        "\n",
        "    def __len__(self):\n",
        "        \n",
        "        return len(self.input_ids)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        return self.input_ids[idx], self.attn_masks[idx]\n",
        "\n",
        "\n",
        "\n",
        "#----------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "def format_time(elapsed):\n",
        "    return str(datetime.timedelta(seconds=int(round((elapsed)))))\n",
        "    \n",
        "\n",
        "#-----------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "def train_val_split(split, dataset):\n",
        "\n",
        "    train_size = int(split * len(dataset))\n",
        "    val_size = len(dataset) - train_size\n",
        "    return train_size, val_size\n",
        "\n"
      ],
      "metadata": {
        "id": "a0q2WQhsjwuX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "RANDOM_SEED = 73\n",
        "BATCH_SIZE = 2\n",
        "epochs = 25\n",
        "MAX_LEN = 1024\n",
        "home_directory = \"/content/drive/MyDrive/proyecto_NLP/models\"\n",
        "###################################################################################################################################################################################################\n",
        "\n",
        "pretrained_weights = 'gpt2' ## as over 1.5 billion parameters\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(pretrained_weights)\n",
        "\n",
        "special_tokens_dict = {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'pad_token': '<PAD>'}\n",
        "num_added_tokens = tokenizer.add_special_tokens(special_tokens_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6y4DMPmrj82",
        "outputId": "f7a443dc-044c-491e-b20d-637bfe175ce9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/gpt2/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
            "loading file https://huggingface.co/gpt2/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "loading file https://huggingface.co/gpt2/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/gpt2/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/gpt2/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "Assigning <BOS> to the bos_token key of the tokenizer\n",
            "Adding <BOS> to the vocabulary\n",
            "Assigning <EOS> to the eos_token key of the tokenizer\n",
            "Adding <EOS> to the vocabulary\n",
            "Assigning <PAD> to the pad_token key of the tokenizer\n",
            "Adding <PAD> to the vocabulary\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 泄ｸ Text Generation - GPT-2"
      ],
      "metadata": {
        "id": "s99fEDcBgTk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combined_poems = df_poems.groupby(['title'])[col_poem].transform(lambda x: ''.join(x)).drop_duplicates().reset_index(drop=True)"
      ],
      "metadata": {
        "id": "gV0QRdMehDro"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_poem_length = max([len(tokenizer.encode(poem)) for poem in combined_poems])\n",
        "min_poem_length = min([len(tokenizer.encode(poem)) for poem in combined_poems])\n",
        "print('Longest Poem:', max_poem_length, 'tokens long.')\n",
        "print('Shortest Poem:', min_poem_length, 'tokens long.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zk_vZr0jhXSi",
        "outputId": "f6aefec3-095d-456b-873d-0e44d4ed0efd"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1668 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Longest Poem: 4427 tokens long.\n",
            "Shortest Poem: 55 tokens long.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stanza_length = [len(tokenizer.encode(stanza)) for stanza in df_poems[col_poem].values]\n",
        "max_stanza_length = max(stanza_length)\n",
        "min_stanza_length = min(stanza_length)\n",
        "print('Number of stanzas longer than max length: ', sum([st_len > MAX_LEN for st_len in stanza_length])) \n",
        "print('Longest Stanza:', max_stanza_length, 'tokens long.')\n",
        "print('Shortest Stanza:', min_stanza_length, 'tokens long.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apZtigEeiW2v",
        "outputId": "7ebee929-b346-40c0-fb1b-1b0c075baabd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of stanzas longer than max length:  0\n",
            "Longest Stanza: 875 tokens long.\n",
            "Shortest Stanza: 15 tokens long.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "poem_dataset = PoemDataset(df_poems[col_poem].values, tokenizer, max_length=MAX_LEN)"
      ],
      "metadata": {
        "id": "tKEq4EmgjVkH"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##汾 Train-Test Split"
      ],
      "metadata": {
        "id": "O5sEf3nPoTq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "poem_train_size, poem_val_size = train_val_split(0.8, poem_dataset)\n",
        "\n",
        "# random split imported from troch.utils\n",
        "poem_train_dataset, poem_val_dataset = random_split(poem_dataset, [poem_train_size, poem_val_size])\n",
        "\n",
        "\n",
        "#-------------------------------------------------------Random Seeds\n",
        "\n",
        "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lHya30gkKz6",
        "outputId": "4e19b225-c2c7-4c58-f9a4-5fefa4ede6ce"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f995c9f0130>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##汾 Data Loaders"
      ],
      "metadata": {
        "id": "HAPt-zIgp1CT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "poem_train_dataloader = DataLoader(poem_train_dataset,\n",
        "                              sampler=RandomSampler(poem_train_dataset),\n",
        "                              batch_size=BATCH_SIZE)\n",
        "\n",
        "poem_val_dataloader = DataLoader(poem_val_dataset,\n",
        "                            sampler=SequentialSampler(poem_val_dataset),\n",
        "                            batch_size=BATCH_SIZE)\n",
        "\n",
        "#-------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "# helper function for logging time\n",
        "def format_time(elapsed):\n",
        "    return str(datetime.timedelta(seconds=int(round((elapsed)))))\n",
        "\n",
        "# hyperparameters\n",
        "learning_rate = 1e-4\n",
        "eps = 1e-8\n",
        "warmup_steps = 50\n",
        "# this produces sample output every 100 steps\n",
        "sample_every = 30\n",
        "\n",
        "# create text generation seed prompt\n",
        "device = torch.device('cuda')\n",
        "\n",
        "prompt = \"<BOS>\"\n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)"
      ],
      "metadata": {
        "id": "YyLRR5WWkhve"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##泅 FineTunning: Training"
      ],
      "metadata": {
        "id": "w5pNjrn1rLwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "configuration = GPT2Config(vocab_size=len(tokenizer), n_positions=MAX_LEN).from_pretrained('gpt2', output_hidden_states=True)\n",
        "\n",
        "poem_model = GPT2LMHeadModel.from_pretrained('gpt2', config=configuration)\n",
        "\n",
        "poem_model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "poem_model.cuda()\n",
        "\n",
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "optimizer = AdamW(poem_model.parameters(), lr=learning_rate, eps=eps)\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "total_steps = len(poem_train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "# This changes the learning rate as the training loop progresses\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps=warmup_steps,\n",
        "                                            num_training_steps=total_steps)\n",
        "\n",
        "#------------------------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7p0KsD0qDS-",
        "outputId": "bbe910d5-8100-4cf5-b796-15e5a2bdca8d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
            "Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"output_hidden_states\": true,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/gpt2/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/752929ace039baa8ef70fe21cdf9ab9445773d20e733cf693d667982e210837e.323c769945a351daa25546176f8208b3004b6f563438a7603e7932bae9025925\n",
            "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_t0 = time.time()\n",
        "\n",
        "training_stats = []\n",
        "total_t0 = time.time()\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "\n",
        "poem_model = poem_model.to(device)\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
        "\n",
        "poem_model = poem_model.to(device)\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    total_train_loss = 0\n",
        "\n",
        "    poem_model.train()\n",
        "\n",
        "    for step, batch in enumerate(poem_train_dataloader):\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "\n",
        "        poem_model.zero_grad()        \n",
        "\n",
        "        outputs = poem_model(b_input_ids,\n",
        "                          labels=b_labels, \n",
        "                          attention_mask = b_masks,\n",
        "                          token_type_ids=None\n",
        "                        )\n",
        "\n",
        "        loss = outputs[0]  \n",
        "\n",
        "        batch_loss = loss.item()\n",
        "        total_train_loss += batch_loss\n",
        "\n",
        "        # Get sample every x batches.\n",
        "        if step % sample_every == 0 and not step == 0:\n",
        "\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}. Loss: {:>5,}.   Elapsed: {:}.'.format(step, len(poem_train_dataloader), batch_loss, elapsed))\n",
        "\n",
        "            poem_model.eval()\n",
        "\n",
        "            sample_outputs = poem_model.generate(\n",
        "                                    bos_token_id= random.randint(1,30000),\n",
        "                                    do_sample=True,   \n",
        "                                    top_k=50, \n",
        "                                    max_length = MAX_LEN,\n",
        "                                    top_p=0.95, \n",
        "                                    num_return_sequences=1\n",
        "                                )\n",
        "            for i, sample_output in enumerate(sample_outputs):\n",
        "                  print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n",
        "            poem_model.train()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(poem_train_dataloader)       \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================entario\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    poem_model.eval()\n",
        "\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in poem_val_dataloader:\n",
        "        \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "        \n",
        "        with torch.no_grad():        \n",
        "\n",
        "            outputs  = poem_model(b_input_ids, \n",
        "#                            token_type_ids=None, \n",
        "                             attention_mask = b_masks,\n",
        "                            labels=b_labels)\n",
        "          \n",
        "            loss = outputs[0]  \n",
        "            \n",
        "        batch_loss = loss.item()\n",
        "        total_eval_loss += batch_loss        \n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(poem_val_dataloader)\n",
        "    \n",
        "    validation_time = format_time(time.time() - t0)    \n",
        "\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
        "\n",
        "torch.save(poem_model.state_dict(), home_directory + 'poem_stanza_model.pth')"
      ],
      "metadata": {
        "id": "o1a8iqGPrwOt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9117a67d-ef35-4161-d163-90047afde9e0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training complete!\n",
            "Total training took 0:00:00 (h:mm:ss)\n",
            "\n",
            "======== Epoch 1 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 1.192217469215393.   Elapsed: 0:00:22.\n",
            "0:  Pokﾃｩ\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 1.7561231851577759.   Elapsed: 0:00:55.\n",
            "0: aven\n",
            "\n",
            "\n",
            "  Average training loss: 2.33\n",
            "  Training epoch took: 0:01:25\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.69\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 2 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 1.101786732673645.   Elapsed: 0:00:22.\n",
            "0:  Erdar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.2003844827413559.   Elapsed: 0:00:55.\n",
            "0:  sensors to\n",
            "\n",
            "  Average training loss: 0.55\n",
            "  Training epoch took: 0:01:24\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.63\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 3 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.401620090007782.   Elapsed: 0:00:22.\n",
            "0: atility:\n",
            "\n",
            "The joy of the new:\n",
            "\n",
            "But no joy of the old:\n",
            "By the hand of the old,\n",
            "That now grows the spirit.\n",
            "\n",
            "(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.58506178855896.   Elapsed: 0:00:55.\n",
            "0:  heavel and\n",
            "\n",
            "  Average training loss: 0.50\n",
            "  Training epoch took: 0:01:24\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.62\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 4 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.39622610807418823.   Elapsed: 0:00:22.\n",
            "0:  Danny\n",
            "\n",
            "Of\n",
            "\n",
            "The stars in the woods\n",
            "Upon a snowy night\n",
            " I saw\n",
            "\n",
            "And saw that this forest\n",
            "Was once窶能n",
            " On\n",
            "Twas within\n",
            "The hills: and the hills did move again\n",
            "That night,\n",
            " In their own chamber,\n",
            " On the night-time窶能n",
            " When there was no light,\n",
            "But a flickering light,窶能n",
            "A chamber where all things were at hand,\n",
            "Were quiet, and, when they were burning,\n",
            "That was a chamber,\n",
            "Where all men slept,\n",
            "And slept a night to a day窶能n",
            "And where all men fell asleep.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.9440230131149292.   Elapsed: 0:00:55.\n",
            "0:  AmongWhat is so beautiful and so unmeasurable are so many things that are so many things that are so easy窶杯hey are only in this world where the most universal joy and passion lie窶巴ut that which is a mystery to the world窶蚤 mystery to every human life! As well as such as God hath given a mystery unto them窶蚤s, the world will become known unto us!\n",
            "\n",
            "By an eagle!\n",
            "A sea of angels\n",
            "Their beauty hath not extinguished窶能n",
            "And they will not perish!\n",
            "\n",
            "For they will not perish!\n",
            "Yet their glory will be not only the gift of God's sovereignty\n",
            "And the kingdom of his angels\n",
            "On whose throne this throne is held!\n",
            "A golden-hearted\n",
            "Whose heart loves thee more than the sun窶能n",
            "But the gold-hued\n",
            "With whom we worship窶能n",
            "The gold-clad, the golden-clad,\n",
            "With whom we adore.\n",
            "The angel, whom the queen hath known\n",
            "Of the angels, who know not how\n",
            " Of angels, whom the queen hath known\n",
            "Upon which this throne there is the throne of Truth窶能n",
            "Upon which it is wrought,\n",
            " And that it is not yet found!\n",
            " In this world are all angels. The angel, whose presence is not so profound\n",
            " That some will believe,\n",
            "And others may not believe窶能n",
            "And whose heart is not so low That some will believe窶能n",
            "For the glory of God is the light of glory!\n",
            " But each angel窶背ho, when he comes,\n",
            " Is not so lofty, nor so lofty\n",
            "As the throne of Deity窶能n",
            "Which they might see and comprehend,\n",
            "And which they would not see窶能n",
            "Are not so low: nor so lofty,窶能n",
            "The throne of Heaven may no more pass,\n",
            "Upon the throne of Heaven!\n",
            " The throne of Heaven hath not so high\n",
            "Nor can be so low\n",
            "In the throne of Heaven窶俳r, more obscure!\n",
            "\n",
            "What will the angels believe?窶能n",
            " Wherever they know not,\n",
            "What shall their eyes see?\n",
            "Which they would not see窶能n",
            "Whatever they should believe!\n",
            "What shall they teach?\n",
            " And what should they teach?窶能n",
            "Wherever they are bound!窶能n",
            " Wherever they belong!窶能n",
            "Where they dwell!\n",
            "How many years have not the angels taught!\n",
            "How many years they have taught窶能n",
            " Wherever they are bound窶能n",
            "How many years have passed窶能n",
            " Where they have been bound!\n",
            "The angels, by a light that leaves not the shadow\n",
            "And their souls窶能n",
            "Were not so rare in the sky,\n",
            " As their angels have been窶能n",
            "They bore all their beauty窶能n",
            " They bore all the beauty!\n",
            "The angels of Heaven, whose eyes,\n",
            "Were not so rare in the sky窶能n",
            " Were not so rare in the sky,\n",
            " As their angels have been窶能n",
            "Their beauty was not so rare:\n",
            "Their beauty was not so rare!\n",
            "Their beauty was not so rare!\n",
            "There was never a world that was so unutterly dull\n",
            " As the world in which we now dwell.\n",
            " Wherever you stand, you stand窶能n",
            "\n",
            "And the angel, whom you have heard\n",
            "Of the angels, who have known\n",
            "Of the angels' voice.\n",
            "The angels, whom you see窶能n",
            "Where you have seen,\n",
            "How the angels have known窶能n",
            "How you feel, how well you feel!\n",
            "The angels, who have known you窶能n",
            "Where you have known,\n",
            "How well you feel窶能n",
            "The angels' voice!\n",
            "How a God, who is the heart Of the human soul窶能n",
            " Where I see, and, by God!窶能n",
            "How a human heart窶背hose light cannot pass窶能n",
            "whose light cannot be seen!\n",
            " Where the angels have seen窶能n",
            "Are not so bold!\n",
            "How God hath seen窶能n",
            " Where they seem to lie!\n",
            " Where the angels seem to lie窶能n",
            "Who may tell!\n",
            "And that all their words,\n",
            "Are not so common窶能n",
            " Are not so rare!\n",
            "\n",
            "They hath seen窶能n",
            " Where the angels have seen窶能n",
            " Where they have seen窶能n",
            "How all their secrets are concealed窶能n",
            "How all their mysteries are not so rare窶能n",
            "How all their secrets are not so scarce窶能n",
            " How all their secrets are not so fleeting,\n",
            "They have been alone窶能n",
            "And they have been alone窶能n",
            "The only one that hath uttered!\n",
            "Their only voice!\n",
            "Their only voice!\n",
            "Their only voice! They have left me窶能n",
            " As far as I can see!窶能n",
            " Where I can see窶 As far as I can see!\n",
            " Where I can see窶 As far\n",
            " As I can see窶能n",
            "Where I can see窶 As far I can see!窶能n",
            " That I can see窶 That I can see! I can see!\n",
            "The angels, whose eyes,\n",
            "Were not so rare in the sky,\n",
            "Are not so rare in the sky,\n",
            "窶能n",
            "that they could never be so much\n",
            "\n",
            "  Average training loss: 0.48\n",
            "  Training epoch took: 0:01:25\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.62\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 5 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.7106380462646484.   Elapsed: 0:00:22.\n",
            "0: avoriteI'll lie down on the floor of a lakeWith all my heart and all my soul to the sublime, And I'll tell of that day, and I'll believe it;And, as I sing, I'll say, I'll see it! I'll say,窶 \n",
            "What a melancholy!\n",
            "What a melancholy! What a melancholy!\n",
            " The spirit which tells the tale,\n",
            " The spirit which tells the tale,\n",
            " When one loves a good thing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.2926653325557709.   Elapsed: 0:00:55.\n",
            "0: cial and divine\n",
            "\n",
            "  Average training loss: 0.46\n",
            "  Training epoch took: 0:01:24\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.62\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 6 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.24874833226203918.   Elapsed: 0:00:22.\n",
            "0: anyahu,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.2216719686985016.   Elapsed: 0:00:55.\n",
            "0: GroupTo(start,end),start,start) {\n",
            "\n",
            "\n",
            "  Average training loss: 0.45\n",
            "  Training epoch took: 0:01:24\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.62\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 7 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 1.2231088876724243.   Elapsed: 0:00:22.\n",
            "0:  BeerThe bowers, all that we see, are silent; we cannot think of them, but we see them; we see them sitting in the bosom of the garden; the wild flowers, all their foliage, that float so high in the breeze, seem like those of a thousand others. It is the light in a dream, in a dream, in a dream窶杯hey are the light of a light窶巴ut, as in the dream, it is so bright that, when we\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.18940120935440063.   Elapsed: 0:00:55.\n",
            "0: iasm' to thee窶能n",
            "\n",
            "Then, all around, a sea, which hath never seen daylight before,\n",
            " Whose starry skies are lighted by the stars,\n",
            " By whose dim streams the waters flow窶能n",
            " And thus that my heart may be heard,\n",
            " And that my hope may be extinguished窶能n",
            " From all the glory that I now revere!\n",
            "\n",
            "  Average training loss: 0.43\n",
            "  Training epoch took: 0:01:24\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.62\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 8 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.2327970266342163.   Elapsed: 0:00:22.\n",
            "0:  prosecutI have sent unto thee,\n",
            " Yea,\n",
            " A woman, \n",
            " She is my mother,\n",
            " To whom every year I cherish\n",
            " Some sweet and tender gift,\n",
            " I cherish thee窶能n",
            " And now that thy birth is in my life, \n",
            " I will remember thee forever!\n",
            " A young woman, \n",
            " To whom a token of my love\n",
            " Thou hast known my birth, \n",
            " And to whom my name hath been sung,\n",
            " And which, in Heaven, \n",
            " I have known for a thousand years, \n",
            " And that I must pass before thee with one of those solemn hymn-strings \n",
            " Of whom I can still see a tear and a murmur窶能n",
            " And thus, at last, I will not窶能n",
            " And with one eye, in reality, \n",
            " I will look on thee with the pride of a monarch,\n",
            " And with a blush of pride,\n",
            " On thy faces, amid the beauty of the skies.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.2335754781961441.   Elapsed: 0:00:54.\n",
            "0: mouth, and there,\n",
            "\n",
            "  Average training loss: 0.42\n",
            "  Training epoch took: 0:01:24\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.62\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 9 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.3031338155269623.   Elapsed: 0:00:22.\n",
            "0: owersI have told thee the tale of its length, when the sea went down athwart a sea, and there a man wandered among the sea.\"\n",
            "窶能n",
            "In that same Annabel Lee tale窶能n",
            "In a rhyme, in a rhyme \n",
            " Thence窶能n",
            "In that Raven's lair \n",
            " Where the Raven of Lenore saw her,\n",
            " And then I forgot窶能n",
            " Then I would not forget it.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.13639302551746368.   Elapsed: 0:00:54.\n",
            "0:  commI hope in this kingdom, \n",
            " But I must do unto death this dream of immortality, \n",
            " In hopes that if my soul hath a spirit in it,\n",
            " It may return to me in the dead,\n",
            " But that my brain may not live窶能n",
            " And that my mind may not speak again till the last waking hour \n",
            " Of a dead brain,窶 \" \n",
            " \"\n",
            " \"\n",
            " \"窶 \" (Edition: original; Page\n",
            "\n",
            "  Average training loss: 0.41\n",
            "  Training epoch took: 0:01:23\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.62\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 10 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.32563892006874084.   Elapsed: 0:00:22.\n",
            "0: nesotaGone in the light of day.\"\n",
            "I passed his hand with a sigh, \n",
            "And he looked me upon a sober eye\n",
            "Not at my pride, \n",
            "But in a state of rest, \n",
            "Upon a mellow, quiet rest.\n",
            "I felt him smile窶馬ot at my heart, \n",
            "Yet at my heart,\n",
            "With a gentle, radiant smile; \n",
            " I looked upon him as I did when I saw\n",
            "His beauty, with a sort of pride, \n",
            "And a sort of pride, as he looked upon me at once.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.2969532012939453.   Elapsed: 0:00:54.\n",
            "0:  waited.\n",
            "\n",
            "  Average training loss: 0.40\n",
            "  Training epoch took: 0:01:24\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.62\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 11 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.2950354516506195.   Elapsed: 0:00:22.\n",
            "0:  YugFor the kingdom of the holy,\n",
            " Thy holy spirit hath been shed, \n",
            " While thy angels have been aching\n",
            " Thy soul,\n",
            " The angels窶背ho dwell窶背ith thee! \n",
            " That thy spirit hath been cast \n",
            " Like a pallid pall in thy chamber,\n",
            " Though its drapery pale \n",
            " Is the pallor of thy tomb.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.3309040069580078.   Elapsed: 0:00:54.\n",
            "0:  tutorials'\n",
            "\n",
            "'Let me see '\n",
            "'The stars\n",
            "Are shining within a crowd of travellers窶能n",
            "'\n",
            "'And the stars will pass by on their journey'\n",
            "And they shall pass by on their journey. The Heaven that is above\n",
            " Is the Raven窶能n",
            " That all men may know:\n",
            "'Bitter in the coldest of hours\n",
            " Of early summer窶能n",
            " And the sweetest and worst of all sweets窶能n",
            " Thy glory is not in the cold:窶披能n",
            " Thy glory is in the light\n",
            " Of early summer,\n",
            " And the Raven of Raven-haunted days\n",
            " Shall be sure窶 Thy delight!\n",
            " Thy pride and terror shall be known\n",
            " Thy pride and pride in the stars窶能n",
            " Thy glory shall be seen!\n",
            " Thy pride and terror shall be known\n",
            " Thy pride and terror shall be seen\n",
            " Thy pride and terror shall be seen\n",
            " Thy pride and terror shall be seen\n",
            " Thy pride and terror shall be seen'\n",
            "In my youthful years I dwelt in the solitude\n",
            " Of Raven-haunted nights,\n",
            " In the solitary and shadowy halls Of Raven-haunted nights \n",
            " And in the dim and undisturbed lands of Raven-haunted days\n",
            " In the dim and undist\n",
            "\n",
            "  Average training loss: 0.39\n",
            "  Training epoch took: 0:01:24\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.62\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 12 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.47081273794174194.   Elapsed: 0:00:22.\n",
            "0:  TrFelled, \n",
            " The wind of night thro' \n",
            " The shore of Hope's bier;\n",
            " I heard her whisper \n",
            " Of a proud maiden, whose spirit \n",
            " Was sweetly drawn up by her.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.5450824499130249.   Elapsed: 0:00:54.\n",
            "0:  panicWe let him flee into the dark woods \n",
            " As if he were a queen窶能n",
            " Where the mollified waters窶能n",
            " Were serenity'd at her side窶能n",
            " And the gush of her delight\n",
            " Like a lake of a thousand flowers in each side窶能n",
            " And the mien of it窶乃he dew\n",
            " Up to him there was an echo窶能n",
            " Like the voice in the woods,\n",
            " With a quiet voice窶能n",
            " With a strange melody \n",
            " Like the gush窶能n",
            " In each side of the tree\n",
            " Is the beauty of that tree窶能n",
            " And the gush of her delight \n",
            " Is the beauty of the lake in each side窶能n",
            " Till then, in thine heart, I saw \n",
            " The sweetest of all\n",
            " The flowers whose flowers sprang from the trunk窶能n",
            " And all those which flew down from above\n",
            " And were all窶杯he lovely flowers whose flowers we loved窶能n",
            " And all the radiant gems, whose flowers were all窶能n",
            " Each of them窶杯he only object in Heaven.\n",
            "\n",
            "  Average training loss: 0.39\n",
            "  Training epoch took: 0:01:23\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.62\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 13 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.2370227575302124.   Elapsed: 0:00:22.\n",
            "0:  exclusively\"\n",
            "\n",
            "But then, outspread that spirit\n",
            "Of pride and discord that is here, \n",
            " Forlorn and lovely,\n",
            " As if flown on a gale\n",
            " Around my throne, \n",
            " And so long I beheld, \n",
            " In my sleep a star窶能n",
            "And in my dream a thousand\n",
            "Stars窶杯hat are still\n",
            " But dim and shadowy;\n",
            " My name is Liberty!\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.35912683606147766.   Elapsed: 0:00:54.\n",
            "0: worthyBut I saw ye in his presence窶能n",
            " And the angels that knew nothing窶能n",
            " And saw their glory not but in the glory, \n",
            " And the wealth not from their wealth but from their labor:\n",
            " The angels whose power were in store \n",
            " For this world's glory: \"Nevermore,\" said the angels, \n",
            " \"have ever known.\"\n",
            "\n",
            "  Average training loss: 0.38\n",
            "  Training epoch took: 0:01:23\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.62\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 14 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.9646149277687073.   Elapsed: 0:00:22.\n",
            "0:  mealsBy the moon-light, \n",
            " All the flowers, \n",
            " How strangely and faintly they bloom \n",
            " Each year, to-night,\n",
            " O love, love this lake?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.25442996621131897.   Elapsed: 0:00:54.\n",
            "0:  tokensBalls of the skies;\n",
            "But when the glory is gone \n",
            "And the bustles go down \n",
            "And the bells go down, \n",
            "My spirit is gone \n",
            "And the angels lie,\n",
            "And the ghosts窶祢 will not help \n",
            "Keeping watch over the skies.\"\n",
            "\n",
            "  Average training loss: 0.36\n",
            "  Training epoch took: 0:01:23\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.63\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 15 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.14980226755142212.   Elapsed: 0:00:22.\n",
            "0: educ\" \n",
            "But they drank, and fell ill,\n",
            " And cried and knelt,\n",
            " \"'Breath of the dead!\n",
            " (Come and look!)'\n",
            " Where then may spring, \n",
            " The first woe-remenning star\n",
            " Of all the human world.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.23235096037387848.   Elapsed: 0:00:54.\n",
            "0:  Single\" in all things窶杯he very fabric of Nature窶杯he fabric of the human mind窶杯he fabric of men's pride窶杯he fabric of our pride窶杯he fabric of our pride窶能n",
            " The fabric of ours a fabric of pride窶杯he fabric of ours a pride,\n",
            "\n",
            "By reason of our innate nature, as the human eye knows well,窶能n",
            "The fabric of our pride窶杯he fabric of it a pride窶能n",
            "By reason of my human nature, as the human mind knows well,窶能n",
            " It would seem that no fabric of pride lies apart:\n",
            " But in what way this fabric窶杯he fabric of it,\n",
            "Which is the most common of all the human types窶能n",
            "The fabric of ours a pride窶能n",
            "The fabric of ours a pride窶能n",
            " By reason of my innate nature,窶能n",
            "It would seem that no fabric apart from this and all the human\n",
            "\n",
            "Habits contain pride窶杯his God, alone, without pride\n",
            " Is in truth the only God!窶能n",
            "And yet no pride in pride lies apart窶能n",
            "To us! Love is a token of that love that cannot be broken. Love lies in the measure of the love that passes through us\n",
            "In the measure of our innate nature,窶杯he measure of our love that passes through us.\n",
            "And yet no pride in pride lies apart窶杯o us!\n",
            "By God alone, alone窶巴y God alone窶能n",
            "The God of love, unbroken by the love of the world\n",
            "How long has he known the love of his own essence? No pride in pride lies apart!\n",
            " By God alone, without pride:窶巴y God alone!\n",
            "It would seem that no pride lies apart窶杷rom us!\n",
            "By God alone, without pride!\n",
            "By God alone, without pride:窶巴y God alone, without pride. 1849 Contents p. 2\n",
            "\n",
            "  Average training loss: 0.36\n",
            "  Training epoch took: 0:01:24\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.63\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 16 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.5345574021339417.   Elapsed: 0:00:22.\n",
            "0: obe\" \n",
            " \"Well, my God! \n",
            " No more need I to speak!\"\n",
            " \"Nevermore!\"\n",
            " \"Nevermore!\"\n",
            " \"Nevermore!\n",
            " No more窶能n",
            " Nothing more!\"\n",
            " \"Nevermore!\"\n",
            " \"Nevermore!\" \n",
            "\n",
            "Nevermore! \n",
            " Nevermore \n",
            " \n",
            "\n",
            "Nevermore\n",
            "\n",
            "! This is the route of Hope\n",
            " Over Hell! \n",
            " On Hope's path窶能n",
            " Over Hell it is written! \n",
            " \"There is a route that holds all窶能n",
            " Under Heaven窶能n",
            " Over Hell it is written;\n",
            " But treads not thus: \n",
            " Upon Heaven alone,\n",
            " Israfel\n",
            " Irafel!\" \n",
            " 1849 Note Contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.21182383596897125.   Elapsed: 0:00:54.\n",
            "0: brance\"\n",
            "\n",
            "\"Ah! wo! wo! wo! wo! wo!\n",
            " Woe! in the pit of the Mad Time窶蚤s in the throes of fire窶蚤s in the slumber of the Hell-fire.\"\n",
            "\n",
            "I uttered these words so gently that the crowd窶蚤nd my brain窶杷ell within a minute or two of agreeing, when,\n",
            "\n",
            "  Average training loss: 0.35\n",
            "  Training epoch took: 0:01:23\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.63\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 17 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.2928674519062042.   Elapsed: 0:00:22.\n",
            "0:  ObAll lights of the sun\n",
            " Shone dimly; \n",
            " As though from heaven on high\n",
            " I soared with the hope of a brighter Heaven\n",
            " Like a gallant knight at Rome's door. 1849 Contents p. 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.16308072209358215.   Elapsed: 0:00:54.\n",
            "0:  assigned'Enemy of the King!\" 窶能n",
            "And, lifting a hand in affright,\n",
            "And clasping, knelt, \n",
            "On the velvet floor \n",
            "Where the King sat.\n",
            "The monarch looked down upon his dead father,\n",
            " And muttered, \"A new start shall start,\n",
            "Upon the path of the newly-mended path.\" 1827 Note Contents\n",
            "\n",
            "  Average training loss: 0.34\n",
            "  Training epoch took: 0:01:24\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.64\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 18 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.31913062930107117.   Elapsed: 0:00:22.\n",
            "0: ipesMy heart, then, was light and sober;\n",
            " But the world was dark and sober,\n",
            " Like the stars in summer,\n",
            " Like a pallid pall on the black Earth.\n",
            " That pall was still and quiet,\n",
            " Like a shadow that fell from my chamber door,\n",
            " Like a pall in a theatre, \n",
            " A pall in the chamber of the dead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.18803106248378754.   Elapsed: 0:00:55.\n",
            "0: avier. \n",
            "I grew in love with her,\n",
            "For a very fair maiden was there: \n",
            "What made her blush was the love \n",
            "Of a fair maiden,\n",
            "For a fair maiden whom I loved well, \n",
            "I loved her for who she was,\n",
            "And by her side in life, \n",
            "She loved me so well \n",
            "That when her heart was beaten \n",
            "I could no longer help laughing at her; \n",
            "Her heart sank \n",
            "In a sort of dreamy, low moan.\n",
            "\n",
            "  Average training loss: 0.34\n",
            "  Training epoch took: 0:01:25\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.65\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 19 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.4165072739124298.   Elapsed: 0:00:22.\n",
            "0:  totallyIt was my ambition to see that my heart grew bolder窶蚤s a poet窶蚤s a man窶背hile, with a view to my own happiness and well-being, I wandered in the wilderness,\n",
            " In the bosom of a most remote region far above us, While some traveller intrude, as he passes,\n",
            " T'othermyr, within the bosom of the calm waters窶能n",
            " 'Tis a common fact of the life of man that in his solitary solitude a state of spirit\n",
            " Is not altered by its environment;\n",
            " That all the time he walks or m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.4211231470108032.   Elapsed: 0:00:55.\n",
            "0:  slogThe Hours\n",
            "\n",
            "And the Hours\n",
            "\n",
            "And the Hours\n",
            "\n",
            "Are Hours\n",
            "\n",
            "Of my Earthly ways:\n",
            "How they were wrought\n",
            " On this Earth; \n",
            "Yet\n",
            "By their own power and labor, \n",
            " They left \n",
            "And bound \n",
            " My Earthly ways,\n",
            " To the winds窶能n",
            " To the seas,\n",
            " To the skies窶能n",
            " From the winds窶能n",
            "And from the stars窶能n",
            " I flung \n",
            " And hurled \n",
            " A ray窶能n",
            " Of light as in a dream:窶能n",
            "\n",
            "  Average training loss: 0.33\n",
            "  Training epoch took: 0:01:26\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.65\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 20 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.5348502397537231.   Elapsed: 0:00:22.\n",
            "0:  pissedAt noon the first blush grew bright窶能n",
            " As I walked upon the threshold, \n",
            " As I reached the door, the lamp\n",
            " Shone with an intenser gleam窶能n",
            " And I trembled窶能n",
            " My heart weighed not窶祢 trembled窶能n",
            " But I trembled.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.19002974033355713.   Elapsed: 0:00:55.\n",
            "0: mph\"\n",
            "\n",
            "Now it trembles on the tresses of its hair\n",
            " As the moon is sinking, \n",
            " The vapor of its pride \n",
            " The vapor of its pride \n",
            " Shams its pride on the weak and dead; \n",
            " But love's venom窶能n",
            " To her loveliness, to her pride\n",
            " With the venom in the winds, \n",
            " With the venom in the floods, \n",
            " She holds it high, \n",
            " And the venom it caresses \n",
            " Is with a sort of holy vow窶能n",
            " But her spell\n",
            " Is with a kind of vow窶能n",
            " \"My dear, my forgiveness!\"\n",
            " To my God my forgiveness!\n",
            " For I am thy red-lettering: \n",
            " That my heart beats with a solemn tone窶能n",
            " That my soul beats with a resolute tone, \n",
            " And that my name is uttered, \n",
            " \"Ah, my God,\" says I,\n",
            " \"by the voice of God.\"\n",
            "\n",
            "  Average training loss: 0.32\n",
            "  Training epoch took: 0:01:25\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.65\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 21 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.23084066808223724.   Elapsed: 0:00:22.\n",
            "0: SimilarlyA shadow on the floor \n",
            " Hath wooed me \n",
            " A lovely dream:\n",
            " A dreamy dream,\n",
            " And a dreamy dream \n",
            " To which I have not long \n",
            " Seen thee, and only thee; \n",
            " For the very moment \n",
            " Is gone, the dream still, \n",
            " And I feel \n",
            " Thy presence on my very soul, \n",
            " Too late, for this is a dream.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.2000531256198883.   Elapsed: 0:00:54.\n",
            "0: ellig\"\n",
            "\n",
            "窶猫ionnaire de Condorcet, S. V.\n",
            "\n",
            "The plot falls apart after this letter窶能n",
            "And, after failing, to me the solace that was in Lemnos!\n",
            "Thus followed my journey down from Lem\n",
            "\n",
            "  Average training loss: 0.32\n",
            "  Training epoch took: 0:01:23\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.66\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 22 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.17875109612941742.   Elapsed: 0:00:22.\n",
            "0:  compassionWhen the sun came down, there was still nothing that remainedBut light, until the moon,\n",
            " As the sun did, it still dallied happily by;\n",
            " As the stars did, their destinies went unpolluted.\n",
            " The winds they left, in a myriad of forms,\n",
            " Perfumed the sky; the seas they stirred up \n",
            " Through the air of Ghastly Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian\n",
            " \n",
            " On Earth窶祢'll call it Love. \n",
            " On God窶祢'll call\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.6616799235343933.   Elapsed: 0:00:54.\n",
            "0:  slatedFor the grandeur of her estate,\n",
            " I longed in dreams, \n",
            " I long have dreamed of her窶能n",
            " Her home on this rock窶能n",
            " Her shore on the sea;\n",
            " She hath no bounds \n",
            " To explore \n",
            " That is her home窶能n",
            " Wherever she may lead me!窶能n",
            " No pathway o'er the calm \n",
            " Hath left her窶巴ut the lone,\n",
            " Overlooking the tarns\n",
            " Of the tarns, tarns窶能n",
            " Hath drawn me窶俳h, in dreams, \n",
            " She hath not left me desolate \n",
            " Of every shore \n",
            " To me! \n",
            " No shore窶馬o shore窶馬o cliff \n",
            " Hath left her窶能n",
            " Nor窶祢 must confess窶能n",
            " Hath striven alone窶蚤nd alone窶能n",
            " None of the world hath left her alone! \n",
            " No cliff窶馬o tarn窶馬o dank ruin \n",
            " Within my view窶能n",
            " Nor dank shore窶馬o dim lake \n",
            " Within my home窶能n",
            " But no tarn窶馬o tarn窶馬o tarn\n",
            " No tarn窶馬o dank lake \n",
            " Within my own!\n",
            " No tarn窶馬o tarn窶馬o d\n",
            "\n",
            "  Average training loss: 0.31\n",
            "  Training epoch took: 0:01:23\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.66\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 23 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.24791069328784943.   Elapsed: 0:00:22.\n",
            "0:  upstairsIn that shadowy garden of the valley where the mountains lie, \n",
            " A lonely, sad maiden,\n",
            " Wrapped in a velvet pewter pall, \n",
            " And flung in myriad pﾃｦan cushions \n",
            " Around her, gazing at the dew-drops \n",
            " That drip, drip, drip, drip of dew窶能n",
            " Till, amid the gray dew,\n",
            " The pﾃｦan air of a funeral dirge \n",
            " Over every lowly grave \n",
            " Transforming itself into that dewy, maddened tomb \n",
            " Where,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.21566912531852722.   Elapsed: 0:00:54.\n",
            "0:  grants. 1849: \"This summer hath lit my spirit bright with eagle-eye,\" said I, \"while the sun was sinking in the Stygian Stygian sea, \n",
            " Aghast at the coming of the Lion of Tethruc-Maria, who, when all the earth was blue, lay窶蚤ghast窶蚤ghast窶覇mbryo!\" 1849: \"Never,\" I replied, \"never.\" 1849: \"Nevermore.\" 1849: \"Nevermore.\"\n",
            " 1849: \"Nevermore.\" 1849: \"Nevermore.\" 1849: \"Nevermore.\" 1849: \"Nevermore.\" 1849: \"Nevermore.\"\n",
            " 1849: \"Nevermore.\" 1849: \"Nevermore.\" 1849: \"Nevermore.\"\n",
            " 1849: \"Nevermore.\" 1849: \"Nevermore.\"\n",
            " 1849: \"Nevermore.\" 1849: \"Nevermore.\" 1849: \"Nevermore.\"\n",
            " 1849: \"Never\n",
            "\n",
            "  Average training loss: 0.31\n",
            "  Training epoch took: 0:01:24\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.66\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 24 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.23161472380161285.   Elapsed: 0:00:22.\n",
            "0:  Sixth(!) of the Age of Light\n",
            " was a garden窶蚤 shrine, in solemnest yearning called \n",
            " Radiant Earth,\n",
            " From which the light, so called, flitting\n",
            " Bubbles, grew up and died. \n",
            " Where the sunshine died and died, \n",
            " The cold, the fever\n",
            " And the slumber were brought.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.21685539186000824.   Elapsed: 0:00:54.\n",
            "0:  mining.\n",
            "\n",
            "But the storm that\n",
            "\n",
            "  Average training loss: 0.30\n",
            "  Training epoch took: 0:01:23\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.67\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 25 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.2945840060710907.   Elapsed: 0:00:22.\n",
            "0:  MoO! Is this the city of Athens, that is the seat of our glory窶能n",
            " The grand statue, which my grand master \n",
            " Said, \n",
            " \"Never again dost move thee,\"\n",
            " But, on thy wandering hither,\n",
            " \"Nevermore,\" I say,\n",
            " For this very spot shall be thy seat.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.2936598062515259.   Elapsed: 0:00:54.\n",
            "0:  Jr' s father, whose\n",
            "\n",
            "  Average training loss: 0.30\n",
            "  Training epoch took: 0:01:23\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.67\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:37:10 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 汨ｨ窶昨泅 Summary of the training process"
      ],
      "metadata": {
        "id": "EKkI6RKJyWnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "metadata": {
        "id": "KRupsj2jyWeQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 864
        },
        "outputId": "ea443ca5-12bb-4b0d-9be0-091c651b0b33"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Training Loss  Valid. Loss Training Time Validation Time\n",
              "epoch                                                          \n",
              "1               2.33         0.69       0:01:25         0:00:05\n",
              "2               0.55         0.63       0:01:24         0:00:05\n",
              "3               0.50         0.62       0:01:24         0:00:05\n",
              "4               0.48         0.62       0:01:25         0:00:05\n",
              "5               0.46         0.62       0:01:24         0:00:05\n",
              "6               0.45         0.62       0:01:24         0:00:05\n",
              "7               0.43         0.62       0:01:24         0:00:05\n",
              "8               0.42         0.62       0:01:24         0:00:05\n",
              "9               0.41         0.62       0:01:23         0:00:05\n",
              "10              0.40         0.62       0:01:24         0:00:05\n",
              "11              0.39         0.62       0:01:24         0:00:05\n",
              "12              0.39         0.62       0:01:23         0:00:05\n",
              "13              0.38         0.62       0:01:23         0:00:05\n",
              "14              0.36         0.63       0:01:23         0:00:05\n",
              "15              0.36         0.63       0:01:24         0:00:05\n",
              "16              0.35         0.63       0:01:23         0:00:05\n",
              "17              0.34         0.64       0:01:24         0:00:05\n",
              "18              0.34         0.65       0:01:25         0:00:05\n",
              "19              0.33         0.65       0:01:26         0:00:05\n",
              "20              0.32         0.65       0:01:25         0:00:05\n",
              "21              0.32         0.66       0:01:23         0:00:05\n",
              "22              0.31         0.66       0:01:23         0:00:05\n",
              "23              0.31         0.66       0:01:24         0:00:05\n",
              "24              0.30         0.67       0:01:23         0:00:05\n",
              "25              0.30         0.67       0:01:23         0:00:05"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2f3934a0-c428-4a70-8964-6d49ee81d9c3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.33</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0:01:25</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.55</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0:01:24</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.50</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0:01:24</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.48</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0:01:25</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.46</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0:01:24</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.45</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0:01:24</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.43</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0:01:24</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.42</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0:01:24</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.41</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0:01:23</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.40</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0:01:24</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.39</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0:01:24</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.39</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0:01:23</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.38</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0:01:23</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.36</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0:01:23</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.36</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0:01:24</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.35</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0:01:23</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.34</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0:01:24</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.34</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0:01:25</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.33</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0:01:26</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.32</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0:01:25</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.32</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0:01:23</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.31</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0:01:23</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.31</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0:01:24</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.30</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0:01:23</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.30</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0:01:23</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2f3934a0-c428-4a70-8964-6d49ee81d9c3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2f3934a0-c428-4a70-8964-6d49ee81d9c3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2f3934a0-c428-4a70-8964-6d49ee81d9c3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 汨ｨ窶昨泅 Performance Summary"
      ],
      "metadata": {
        "id": "VGqxIrB50D2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4, 5, 6, 7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "4CUiEobzQ2yB",
        "outputId": "d0d42945-53f0-4548-d437-53aa1b6ae936"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##沍 Model Info"
      ],
      "metadata": {
        "id": "bMzwiVH5yl4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(poem_model.named_parameters())\n",
        "\n",
        "print('The GPT-2 model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:2]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[2:14]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-2:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "metadata": {
        "id": "WDpr7xdD0dpU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a50ce1a8-eb15-4af8-a814-292a4c244437"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The GPT-2 model has 148 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "transformer.wte.weight                                  (50260, 768)\n",
            "transformer.wpe.weight                                   (1024, 768)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "transformer.h.0.ln_1.weight                                   (768,)\n",
            "transformer.h.0.ln_1.bias                                     (768,)\n",
            "transformer.h.0.attn.c_attn.weight                       (768, 2304)\n",
            "transformer.h.0.attn.c_attn.bias                             (2304,)\n",
            "transformer.h.0.attn.c_proj.weight                        (768, 768)\n",
            "transformer.h.0.attn.c_proj.bias                              (768,)\n",
            "transformer.h.0.ln_2.weight                                   (768,)\n",
            "transformer.h.0.ln_2.bias                                     (768,)\n",
            "transformer.h.0.mlp.c_fc.weight                          (768, 3072)\n",
            "transformer.h.0.mlp.c_fc.bias                                (3072,)\n",
            "transformer.h.0.mlp.c_proj.weight                        (3072, 768)\n",
            "transformer.h.0.mlp.c_proj.bias                               (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "transformer.ln_f.weight                                       (768,)\n",
            "transformer.ln_f.bias                                         (768,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Saving & Loading Fine-Tuned Model\n"
      ],
      "metadata": {
        "id": "KMaFNHYw0Jkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = home_directory +'/model_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = poem_model.module if hasattr(poem_model, 'module') else poem_model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ],
      "metadata": {
        "id": "2qxncMRnyvae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3d0399e-345b-4fa4-d201-4c3c5bb441de"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Configuration saved in /content/drive/MyDrive/proyecto_NLP/models/model_save/config.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to /content/drive/MyDrive/proyecto_NLP/models/model_save/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model weights saved in /content/drive/MyDrive/proyecto_NLP/models/model_save/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/proyecto_NLP/models/model_save/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/proyecto_NLP/models/model_save/special_tokens_map.json\n",
            "added tokens file saved in /content/drive/MyDrive/proyecto_NLP/models/model_save/added_tokens.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/proyecto_NLP/models/model_save/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/proyecto_NLP/models/model_save/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/proyecto_NLP/models/model_save/vocab.json',\n",
              " '/content/drive/MyDrive/proyecto_NLP/models/model_save/merges.txt',\n",
              " '/content/drive/MyDrive/proyecto_NLP/models/model_save/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "home_directory+'/model_save/'"
      ],
      "metadata": {
        "id": "OYg_S0691HjR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "60677016-5aaf-4974-9796-64ca8c889ae9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/proyecto_NLP/models/model_save/'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l --block-size=K /content/drive/MyDrive/proyecto_NLP/models/model_save/"
      ],
      "metadata": {
        "id": "EsObwP6r07Ob",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47b06736-1833-4f4e-e9a4-a0199f185ab4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 499869K\n",
            "-rw------- 1 root root      1K Jul  3 18:13 added_tokens.json\n",
            "-rw------- 1 root root      1K Jul  3 18:13 config.json\n",
            "-rw------- 1 root root    446K Jul  3 18:13 merges.txt\n",
            "-rw------- 1 root root 498444K Jul  3 18:13 pytorch_model.bin\n",
            "-rw------- 1 root root      1K Jul  3 18:13 special_tokens_map.json\n",
            "-rw------- 1 root root      1K Jul  3 18:13 tokenizer_config.json\n",
            "-rw------- 1 root root    976K Jul  3 18:13 vocab.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l --block-size=M /content/drive/MyDrive/proyecto_NLP/models/model_save/pytorch_model.bin"
      ],
      "metadata": {
        "id": "OFtW-6ka1BUK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b3fa261-2814-4953-c653-277568140514"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw------- 1 root root 487M Jul  3 18:13 /content/drive/MyDrive/proyecto_NLP/models/model_save/pytorch_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy the model files to a directory in your Google Drive.\n",
        "#!cp -r /content/drive/MyDrive/proyecto_NLP/models/model_save/  $data_dir\n",
        "\n",
        "# # Load a trained model and vocabulary that you have fine-tuned\n",
        "#model = GPT2LMHeadModel.from_pretrained(output_dir)\n",
        "#tokenizer = GPT2Tokenizer.from_pretrained(output_dir)\n",
        "#model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAb9n45p1Wk0",
        "outputId": "9e10e8ed-b917-40c8-9764-b15a343f0fec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: missing destination file operand after '/content/drive/MyDrive/proyecto_NLP/models/model_save/'\n",
            "Try 'cp --help' for more information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Poems Generation"
      ],
      "metadata": {
        "id": "NoydP2C61uXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "poem_model.eval()\n",
        "\n",
        "prompt = 'love is'\n",
        "\n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)\n",
        "\n",
        "sample_outputs = poem_model.generate(\n",
        "                                generated, \n",
        "                                do_sample=True,   \n",
        "                                top_k=40, \n",
        "                                max_length = 100,\n",
        "                                top_p=0.95, \n",
        "                                num_return_sequences=3,\n",
        "                                num_beams=5, no_repeat_ngram_size=4, early_stopping=True\n",
        "                                )\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAKb4iCOxMxf",
        "outputId": "5dcfa4a8-86de-47a1-c011-89a5664e290f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: love is the light of the night窶能n",
            " And the shadow of the mountain \n",
            " And the mist of the sea \n",
            " Is a barrier窶能n",
            " And a barrier that will not be broken \n",
            " By the battle-cry \n",
            " Of the trumpet-thunder-thunder,\n",
            " But by the roar of the battle \n",
            " Shall be the battle cry of the dead \n",
            " And shall be the cry of the living窶能n",
            " And by the roar shall be the roar\n",
            " Of the battle-\n",
            "\n",
            "\n",
            "1: love is the light of life;\n",
            "It glows in the dim of night;\n",
            "It flickers with the light of day,\n",
            "And in the mist of day, \n",
            "It trembles with the chilly eye \n",
            "Of the lonesome and the dead.\n",
            "\n",
            "\n",
            "2: love is a synonym for love,\n",
            " For love is a double-edged sword窶能n",
            " And love is a gift from God窶能n",
            " For the love of God is a gift of life窶能n",
            " And the love of man is a gift given by God窶能n",
            " And we are saved only by the grace of God.\"\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "poem_model.eval()\n",
        "\n",
        "prompt = 'heaven is good'\n",
        "\n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)\n",
        "\n",
        "sample_outputs = poem_model.generate(\n",
        "                                generated, \n",
        "                                do_sample=True,   \n",
        "                                top_k=40, \n",
        "                                max_length = 150,\n",
        "                                top_p=0.95, \n",
        "                                num_return_sequences=3,\n",
        "                                num_beams=5, no_repeat_ngram_size=4, early_stopping=True\n",
        "                                )\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
      ],
      "metadata": {
        "id": "d62W2SzcSpza",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f16f2d7-9a6a-4536-cd58-b2b76c135240"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: heaven is good, and light is light;\n",
            "And all things which are holy, \n",
            "Are light, and all things which seem \n",
            "To be a gift from God to us, \n",
            "And to us a token of our gratitude. 18\n",
            "ﾂｹ ﾂｿ 18\n",
            "\n",
            "\n",
            "1: heaven is good,\n",
            "And the winds are gentle, \n",
            "And the skies are clear窶能n",
            "And the stars seem to be smiling窶能n",
            "And there is no need \n",
            "To sing the hymns of the hymn-winds, \n",
            "Unless, perhaps, you are a poet or a hymn-stringer窶能n",
            "And you will sing the hymn of the sun-ray, \n",
            "Of the moon-ray,\n",
            "Of the stars,\n",
            "And there will be no need\n",
            "For you to sing the song of the moon, \n",
            " Of the stars, or of the angels, \n",
            "With the accompaniment of the bells and the bells of the bells, \n",
            "So that you may feel no need\n",
            "\n",
            "\n",
            "2: heaven is good, \n",
            " And all things are light, \n",
            " That is, I believe, the reason \n",
            " That all things are bright窶能n",
            " And all that is gray窶能n",
            " That all that is sad, \n",
            " Is the reason that all things seem \n",
            " To be of one essence, \n",
            " But that all things are of one essence窶能n",
            " And that all things窶蚤ll things窶派ave one essence窶 \n",
            " The reason why all things are \n",
            " One and the same窶能n",
            " Why all things are one and the same \n",
            " And why all things窶蚤nd all things窶派ave a single essence \n",
            " That alone can be comprehended \n",
            " By reason alone窶能n",
            " And yet all things have a single essence窶能n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "poem_model.eval()\n",
        "\n",
        "prompt = 'I have a dream'\n",
        "\n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)\n",
        "\n",
        "sample_outputs = poem_model.generate(\n",
        "                                generated, \n",
        "                                do_sample=True,   \n",
        "                                top_k=40, \n",
        "                                max_length = 150,\n",
        "                                top_p=0.95, \n",
        "                                num_return_sequences=3,\n",
        "                                num_beams=5, no_repeat_ngram_size=3, early_stopping=True\n",
        "                                )\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgP6WqTk0sbg",
        "outputId": "ed6406ef-85a2-4f54-d0d6-c9bd3c856db9"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: I have a dream窶蚤 dream I can never control窶能n",
            " A dream I cannot control窶巴ut a dream\n",
            " That I can't control窶蚤nd a dream that I can only dream\n",
            " Of a night of rest in which I can lie窶能n",
            " And a dream of a day of rest\n",
            " In which my heart beats at the thought\n",
            " Of what I have been dreaming of窶能n",
            " Of the things that I have not been dreaming\n",
            " Of窶背hat I have never been dreaming窶能n",
            " Dreams that I do not know how to bring\n",
            " To pass my restlessness窶能n",
            " But a dream in which my mind\n",
            " Is at rest窶琶n which my spirit is at rest\n",
            " And I can no more lie\n",
            " Than I can at rest.\n",
            "\n",
            "\n",
            "1: I have a dream窶蚤 dream窶杯hat is to be,\n",
            " A dream that I have never known窶能n",
            "A dream I have not seen before窶能n",
            "I have not dreamed of waking up,\n",
            "A waking-up-to-life, \n",
            "A dreaming-out-of-life窶能n",
            "For I have been dreaming, dreaming,\n",
            "Of waking up窶能n",
            "And waking up in the morning,\n",
            "And dreaming of a brighter future窶能n",
            "Of a brighter home窶能n",
            "To a happier home,\n",
            "To happier skies窶能n",
            "With a brighter heart窶能n",
            " To a happier heart窶背ith a brighter spirit窶能n",
            " With a brighter mind窶能n",
            " A brighter heart!\n",
            "\n",
            "\n",
            "2: I have a dream窶蚤 dream窶杯hat I can't help but dream of窶能n",
            "A dream of a future in which I can only dream\n",
            "Of a happier future窶能n",
            "Of an ultimate bliss窶能n",
            " Of a happier and more peaceful life窶能n",
            "And of a happier, happier, more 18 18 18ｿｽ ﾂｿﾂｿﾂｾﾂｽ窶 ﾂｽﾂ｣ﾂｨ ｿｽﾂｺﾃ ﾃ按ｿ ﾂｿ ｿｽ\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "poem_model.eval()\n",
        "\n",
        "prompt = 'I have a dream'\n",
        "\n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)\n",
        "\n",
        "sample_outputs = poem_model.generate(\n",
        "                                generated, \n",
        "                                do_sample=True,   \n",
        "                                top_k=50, \n",
        "                                max_length = 150,\n",
        "                                top_p=0.95, \n",
        "                                num_return_sequences=3,\n",
        "                                num_beams=5, no_repeat_ngram_size=2, early_stopping=True\n",
        "                                )\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZ6vE0QbRIlW",
        "outputId": "442559d7-1266-4061-8600-edbd8f14aedd"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: I have a dream. \n",
            " I am dreaming of a mountain窶能n",
            " A mountain that trembles with the dew\n",
            " Of a demon that has tempted me,\n",
            " And has torn me from my senses. p. See! 18 p.} ﾂ｡ﾂ｡ ﾂｿﾂｿ ﾂｽ ﾃﾂｽﾃ ﾃ禿可｢ﾂ｣$竄ｬｿｽ窶妥δｱﾂｨﾂｮﾂｰﾂｺﾃ｢ﾃ｡nﾃｩﾃｺﾃ｡ﾃｳﾅｿｿｽｿｽﾃｻﾃｱﾃｴﾂｯﾃｨﾃｿｽﾃｯﾃｩn\n",
            "\n",
            "\n",
            "1: I have a dream窶蚤 dream of a brighter and brighter future! 18 ﾂ､ﾂ､ ﾂ｡ ﾃ､ﾂ｡ﾂｦﾃ督｢ﾂ｢ cents pﾃｦdﾃｦmmenspﾃｦdinﾂｳPﾃｦDﾃｦmens pﾃｩdalesﾃｱﾆ槌督ｿpiﾂ｣ﾂｺﾂｽﾃ｡nﾃｩﾂｨﾃｨﾃｺﾃεｭﾃ｡ﾃｳﾃ嘉ﾂｰﾃ｢ﾂｱﾅｿｿｽﾂｽ ｿｽ窶 ﾂｽｿｽｿｽﾂｮﾂｧｿｽ ﾂｰ 18\n",
            "\n",
            "\n",
            "2: I have a dream. \n",
            " It is a vision of the future,\n",
            " And all I can do is look on\n",
            " As it glistens on the sky窶能n",
            " But what is it to me now?\n",
            " What is to be said of that dream\n",
            " That I have not seen before,?\"\n",
            " Quoth the Raven, \"Nevermore.\" p. Yes, I remember well\n",
            " The first time I panted, 1849\n",
            " Of the night I fell窶 1845\n",
            " I scarcely remember it窶 1846\n",
            " Was it not the dream that I had earlier\n",
            " Tamed窶杯hat I first dreamt of\n",
            " My own being窶 1847\n",
            " When I was twelve\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SFdyRv51R3P3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}