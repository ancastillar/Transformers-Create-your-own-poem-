{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformers: Create your own poem! with AI_Train.ipynb",
      "provenance": [],
      "mount_file_id": "1xWtxFtplWzx7f6ZTEWcjLshe7KXwmPA8",
      "authorship_tag": "ABX9TyOtQlb/6g9O6qAcYbvwKro0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ancastillar/Transformers-Create-your-own-poem-/blob/main/Transformers_Create_your_own_poem!_with_AI_Train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import libraries"
      ],
      "metadata": {
        "id": "4B9XFhexfkY5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Abywl7XSNs8",
        "outputId": "678c4b49-f434-4875-d6df-9093a99d008a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: aitextgen in /usr/local/lib/python3.7/dist-packages (0.5.2)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from aitextgen) (1.11.0+cu113)\n",
            "Requirement already satisfied: pytorch-lightning>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from aitextgen) (1.6.4)\n",
            "Requirement already satisfied: transformers>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from aitextgen) (4.20.1)\n",
            "Requirement already satisfied: fire>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from aitextgen) (0.4.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire>=0.3.0->aitextgen) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from fire>=0.3.0->aitextgen) (1.15.0)\n",
            "Requirement already satisfied: pyDeprecate>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (0.3.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (21.3)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (4.64.0)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (2.8.0)\n",
            "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (2022.5.0)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (1.21.6)\n",
            "Requirement already satisfied: torchmetrics>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (0.9.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (4.1.1)\n",
            "Requirement already satisfied: protobuf<=3.20.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (3.17.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (3.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning>=1.3.1->aitextgen) (3.0.9)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.4.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.37.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.35.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.46.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.6.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (2022.6.15)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.5.1->aitextgen) (3.7.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.5.1->aitextgen) (0.8.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.5.1->aitextgen) (0.12.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.5.1->aitextgen) (2022.6.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (1.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (1.7.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (2.0.12)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (21.4.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (6.0.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (4.0.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (0.13.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (1.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.7/dist-packages (0.0.25)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (0.12.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: Werkzeug>=0.7 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: click>=2.0 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous>=0.21 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: Jinja2>=2.4 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.4->Flask>=0.8->flask-ngrok) (2.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: flask==0.12.2 in /usr/local/lib/python3.7/dist-packages (0.12.2)\n",
            "Requirement already satisfied: itsdangerous>=0.21 in /usr/local/lib/python3.7/dist-packages (from flask==0.12.2) (1.1.0)\n",
            "Requirement already satisfied: Jinja2>=2.4 in /usr/local/lib/python3.7/dist-packages (from flask==0.12.2) (2.11.3)\n",
            "Requirement already satisfied: click>=2.0 in /usr/local/lib/python3.7/dist-packages (from flask==0.12.2) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug>=0.7 in /usr/local/lib/python3.7/dist-packages (from flask==0.12.2) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.4->flask==0.12.2) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install aitextgen\n",
        "!pip install flask-ngrok\n",
        "!pip install flask==0.12.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "#Visualizations\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "sns.set(rc = {'figure.figsize':(35,10)})\n",
        "sns.set_palette(\"Paired\")\n",
        "sns.set_style(\"white\")\n",
        "from flask import Flask, request, render_template\n",
        "from flask_ngrok import run_with_ngrok\n",
        "\n",
        "##########Models\n",
        "from aitextgen import aitextgen\n",
        "import torch\n",
        "import sys\n",
        "import os\n",
        "import random\n",
        "import time \n",
        "import datetime\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    current_device = torch.cuda.current_device()\n",
        "    print(\"Available GPUs: \", torch.cuda.get_device_name(current_device))\n",
        "    print()\n",
        "\n",
        "!nvidia-smi\n",
        "\n",
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, GPT2Config, AdamW, get_linear_schedule_with_warmup, GPT2TokenizerFast\n",
        "from torch.utils.data import Dataset, random_split, DataLoader, RandomSampler, SequentialSampler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAInlBf8TN3_",
        "outputId": "d88f9b6c-92c1-4a87-c25f-47b2bf647248"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available GPUs:  Tesla T4\n",
            "\n",
            "Thu Jun 30 00:49:46 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P8    12W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Data"
      ],
      "metadata": {
        "id": "UM66iavGf3aQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "col_poem = \"stanza_text\"\n",
        "\n",
        "#------------------------------------------------\n",
        "\n",
        "df_poems = pd.read_csv(\"/content/drive/MyDrive/proyecto_NLP/data/poe_poems_stanzas.csv\")\n",
        "df_poems = df_poems[df_poems[col_poem].notna()]\n",
        "print(\"Dimension of datase:\", df_poems.shape)"
      ],
      "metadata": {
        "id": "Cj-VEZsSTvgj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9edd8bc4-4df7-40ae-d607-1c3e4cccb415"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimension of datase: (215, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##📜 Global Functions"
      ],
      "metadata": {
        "id": "vbAy8fYFjuTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PoemDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, data, tokenizer, max_length, gpt2_type='gpt2'):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.input_ids = []\n",
        "        self.attn_masks = []\n",
        "        \n",
        "        for i in data:\n",
        "            encodings_dict = tokenizer('<BOS>' + i + '<EOS>',\n",
        "                                     truncation=True,\n",
        "                                     max_length=max_length,\n",
        "                                     padding='max_length'\n",
        "                                    )\n",
        "\n",
        "            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
        "            self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
        "\n",
        "    def __len__(self):\n",
        "        \n",
        "        return len(self.input_ids)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        return self.input_ids[idx], self.attn_masks[idx]\n",
        "\n",
        "\n",
        "\n",
        "#----------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "def format_time(elapsed):\n",
        "    return str(datetime.timedelta(seconds=int(round((elapsed)))))\n",
        "    \n",
        "\n",
        "#-----------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "def train_val_split(split, dataset):\n",
        "\n",
        "    train_size = int(split * len(dataset))\n",
        "    val_size = len(dataset) - train_size\n",
        "    return train_size, val_size\n",
        "\n"
      ],
      "metadata": {
        "id": "a0q2WQhsjwuX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "RANDOM_SEED = 73\n",
        "BATCH_SIZE = 2\n",
        "epochs = 20\n",
        "MAX_LEN = 1024\n",
        "home_directory = \"/content/drive/MyDrive/proyecto_NLP/models\"\n",
        "###################################################################################################################################################################################################\n",
        "\n",
        "pretrained_weights = \"gpt2-large\" ## as over 1.5 billion parameters\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(pretrained_weights)\n",
        "\n",
        "special_tokens_dict = {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'pad_token': '<PAD>'}\n",
        "num_added_tokens = tokenizer.add_special_tokens(special_tokens_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6y4DMPmrj82",
        "outputId": "6ba71f2b-ce07-45d1-bb57-417c27421778"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/gpt2-large/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/79f5e05af067df502528a0d902e82c24c3f1df9ae570c91fcc38e1f3c0af4c45.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
            "loading file https://huggingface.co/gpt2-large/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/7f7bf8a7802a708af08a812bfbdec9335f2c30f761ec14a8cd17b0d61c818876.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "loading file https://huggingface.co/gpt2-large/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/gpt2-large/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/gpt2-large/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/gpt2-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/d82fb41558a2cc40bb6e10a57bbfbd9ff2f3c6614072f05afdfa8f44d566d2ba.55d263c4ba1f8b022997c21dfa03fb8933c57bc9c978354e0a62896cfd837a89\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2-large\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 1280,\n",
            "  \"n_head\": 20,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 36,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "Assigning <BOS> to the bos_token key of the tokenizer\n",
            "Adding <BOS> to the vocabulary\n",
            "Assigning <EOS> to the eos_token key of the tokenizer\n",
            "Adding <EOS> to the vocabulary\n",
            "Assigning <PAD> to the pad_token key of the tokenizer\n",
            "Adding <PAD> to the vocabulary\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🕸 Text Generation - GPT-2"
      ],
      "metadata": {
        "id": "s99fEDcBgTk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combined_poems = df_poems.groupby(['title'])['stanza_text'].transform(lambda x: ' /n /n '.join(x)).drop_duplicates().reset_index(drop=True)"
      ],
      "metadata": {
        "id": "gV0QRdMehDro"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_poem_length = max([len(tokenizer.encode(poem)) for poem in combined_poems])\n",
        "min_poem_length = min([len(tokenizer.encode(poem)) for poem in combined_poems])\n",
        "print('Longest Poem:', max_poem_length, 'tokens long.')\n",
        "print('Shortest Poem:', min_poem_length, 'tokens long.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zk_vZr0jhXSi",
        "outputId": "6bd95bf7-af38-4482-eba2-b5b7d01ac21e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1753 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Longest Poem: 6465 tokens long.\n",
            "Shortest Poem: 55 tokens long.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stanza_length = [len(tokenizer.encode(stanza)) for stanza in df_poems[col_poem].values]\n",
        "max_stanza_length = max(stanza_length)\n",
        "min_stanza_length = min(stanza_length)\n",
        "print('Number of stanzas longer than max length (1024 tokens): ', sum([st_len > MAX_LEN for st_len in stanza_length])) \n",
        "print('Longest Stanza:', max_stanza_length, 'tokens long.')\n",
        "print('Shortest Stanza:', min_stanza_length, 'tokens long.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apZtigEeiW2v",
        "outputId": "1f1150cc-bf4c-4482-d9dd-bde758f0a204"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of stanzas longer than max length (1024 tokens):  1\n",
            "Longest Stanza: 1948 tokens long.\n",
            "Shortest Stanza: 15 tokens long.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "poem_dataset = PoemDataset(df_poems[col_poem].values, tokenizer, max_length=MAX_LEN)"
      ],
      "metadata": {
        "id": "tKEq4EmgjVkH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##🐝 Train-Test Split"
      ],
      "metadata": {
        "id": "O5sEf3nPoTq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "poem_train_size, poem_val_size = train_val_split(0.8, poem_dataset)\n",
        "\n",
        "# random split imported from troch.utils\n",
        "poem_train_dataset, poem_val_dataset = random_split(poem_dataset, [poem_train_size, poem_val_size])\n",
        "\n",
        "\n",
        "#-------------------------------------------------------Random Seeds\n",
        "\n",
        "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lHya30gkKz6",
        "outputId": "ae943bde-da44-49fb-c2fd-7e95451a0096"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f84065be810>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##🐝 Data Loaders"
      ],
      "metadata": {
        "id": "HAPt-zIgp1CT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "poem_train_dataloader = DataLoader(poem_train_dataset,\n",
        "                              sampler=RandomSampler(poem_train_dataset),\n",
        "                              batch_size=BATCH_SIZE)\n",
        "\n",
        "poem_val_dataloader = DataLoader(poem_val_dataset,\n",
        "                            sampler=SequentialSampler(poem_val_dataset),\n",
        "                            batch_size=BATCH_SIZE)\n",
        "\n",
        "#-------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "# helper function for logging time\n",
        "def format_time(elapsed):\n",
        "    return str(datetime.timedelta(seconds=int(round((elapsed)))))\n",
        "\n",
        "# hyperparameters\n",
        "learning_rate = 1e-4\n",
        "eps = 1e-8\n",
        "warmup_steps = 20\n",
        "# this produces sample output every 100 steps\n",
        "sample_every = 10\n",
        "\n",
        "# create text generation seed prompt\n",
        "device = torch.device('cuda')\n",
        "\n",
        "prompt = \"<BOS>\"\n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)"
      ],
      "metadata": {
        "id": "YyLRR5WWkhve"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##🚀 FineTunning: Training"
      ],
      "metadata": {
        "id": "w5pNjrn1rLwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "configuration = GPT2Config(vocab_size=len(tokenizer), n_positions=MAX_LEN).from_pretrained(\"gpt2\", output_hidden_states=True)\n",
        "\n",
        "poem_model = GPT2LMHeadModel.from_pretrained(\"gpt2\", config=configuration)\n",
        "\n",
        "poem_model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "poem_model.cuda()\n",
        "\n",
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "optimizer = AdamW(poem_model.parameters(), lr=learning_rate, eps=eps)\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "total_steps = len(poem_train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "# This changes the learning rate as the training loop progresses\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps=warmup_steps,\n",
        "                                            num_training_steps=total_steps)\n",
        "\n",
        "#------------------------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7p0KsD0qDS-",
        "outputId": "755aaa61-8fa1-4ac1-f995-a8da2f80537b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
            "Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"output_hidden_states\": true,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/gpt2/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/752929ace039baa8ef70fe21cdf9ab9445773d20e733cf693d667982e210837e.323c769945a351daa25546176f8208b3004b6f563438a7603e7932bae9025925\n",
            "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_t0 = time.time()\n",
        "\n",
        "training_stats = []\n",
        "total_t0 = time.time()\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "\n",
        "poem_model = poem_model.to(device)\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
        "\n",
        "poem_model = poem_model.to(device)\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    total_train_loss = 0\n",
        "\n",
        "    poem_model.train()\n",
        "\n",
        "    for step, batch in enumerate(poem_train_dataloader):\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "\n",
        "        poem_model.zero_grad()        \n",
        "\n",
        "        outputs = poem_model(  b_input_ids,\n",
        "                          labels=b_labels, \n",
        "                          attention_mask = b_masks,\n",
        "                          token_type_ids=None\n",
        "                        )\n",
        "\n",
        "        loss = outputs[0]  \n",
        "\n",
        "        batch_loss = loss.item()\n",
        "        total_train_loss += batch_loss\n",
        "\n",
        "        # Get sample every x batches.\n",
        "        if step % sample_every == 0 and not step == 0:\n",
        "\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}. Loss: {:>5,}.   Elapsed: {:}.'.format(step, len(poem_train_dataloader), batch_loss, elapsed))\n",
        "\n",
        "            poem_model.eval()\n",
        "\n",
        "            sample_outputs = poem_model.generate(\n",
        "                                    bos_token_id= random.randint(1,30000),\n",
        "                                    do_sample=True,   \n",
        "                                    top_k=50, \n",
        "                                    max_length = MAX_LEN,\n",
        "                                    top_p=0.95, \n",
        "                                    num_return_sequences=1\n",
        "                                )\n",
        "            for i, sample_output in enumerate(sample_outputs):\n",
        "                  print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n",
        "            \n",
        "            poem_model.train()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(poem_train_dataloader)       \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    poem_model.eval()\n",
        "\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in poem_val_dataloader:\n",
        "        \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "        \n",
        "        with torch.no_grad():        \n",
        "\n",
        "            outputs  = poem_model(b_input_ids, \n",
        "#                            token_type_ids=None, \n",
        "                             attention_mask = b_masks,\n",
        "                            labels=b_labels)\n",
        "          \n",
        "            loss = outputs[0]  \n",
        "            \n",
        "        batch_loss = loss.item()\n",
        "        total_eval_loss += batch_loss        \n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(poem_val_dataloader)\n",
        "    \n",
        "    validation_time = format_time(time.time() - t0)    \n",
        "\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
        "\n",
        "torch.save(poem_model.state_dict(), home_directory + 'poem_stanza_model.pth')"
      ],
      "metadata": {
        "id": "o1a8iqGPrwOt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cd723ea-2f98-44a9-80f9-3baac63a21f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training complete!\n",
            "Total training took 0:00:00 (h:mm:ss)\n",
            "\n",
            "======== Epoch 1 / 20 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    10  of     86. Loss: 2.5830790996551514.   Elapsed: 0:00:07.\n",
            "0:  Poké\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    20  of     86. Loss: 0.8006391525268555.   Elapsed: 0:00:25.\n",
            "0: aven\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.980342447757721.   Elapsed: 0:00:43.\n",
            "0:  Erdis\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     86. Loss: 0.4827865958213806.   Elapsed: 0:01:04.\n",
            "0:  sensors are\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    50  of     86. Loss: 0.6772293448448181.   Elapsed: 0:01:22.\n",
            "0: atility/\n",
            "\n",
            "I can not\n",
            "\n",
            "\n",
            "for\n",
            "\n",
            "me.\n",
            "\n",
            "My\n",
            "\n",
            "\n",
            "M\n",
            "\n",
            "\n",
            "me.\n",
            "\n",
            "!\n",
            "\n",
            "\n",
            "!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.35321658849716187.   Elapsed: 0:01:30.\n",
            "0:  heav's\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    70  of     86. Loss: 0.31799352169036865.   Elapsed: 0:01:54.\n",
            "0:  Danny and\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    80  of     86. Loss: 0.36221328377723694.   Elapsed: 0:02:13.\n",
            "0:  Among to which no man can escape without death.\n",
            "\n",
            "\n",
            "—,—,——,—,—,—,——\n",
            "\n",
            " The The The \",— The \"\n",
            "\n",
            "The: the soul's soul's soul's soul\n",
            "\n",
            "—\" \"\n",
            " The \"; the,\n",
            " and\n",
            "—,—\n",
            "—The—— (or—\n",
            "\n",
            "  Average training loss: 1.92\n",
            "  Training epoch took: 0:02:29\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.65\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 2 / 20 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    10  of     86. Loss: 0.4376414120197296.   Elapsed: 0:00:08.\n",
            "0: avorite\n",
            "\n",
            "\n",
            "of the human mind\n",
            "\n",
            "\n",
            "which will not fall\n",
            "\n",
            " into the void\n",
            "\n",
            "of the deep\n",
            "\n",
            "\n",
            "of my youth\n",
            "\n",
            "Of the night\n",
            "\n",
            "which was that my life,\n",
            "\n",
            " which has been with me\n",
            "\n",
            "that dreams are\n",
            "\n",
            "but dreamy dreamy\n",
            "\n",
            "and dreamy,\n",
            "\n",
            " which are not dreams,\n",
            "\n",
            " who are not dreams for years\n",
            "\n",
            "\n",
            "that dream\n",
            " of the lonely\n",
            "\n",
            " which is his shadow\n",
            "\n",
            "and all our dreams\n",
            "\n",
            "\n",
            "which lie in the cloud\n",
            "\n",
            " And I may, and I might, And my soul lies on the bed\n",
            " And there is a dream,\n",
            " that dream that comes to me, And I may not dream\n",
            " and dream\n",
            "I have no soul.\n",
            " The moonlight the bright sideOf the nightAnd my dreams\n",
            " And the sound of my own voice\n",
            "But the heart of a dream,and my dreams. And he will be my soul, but still I have no spirit\n",
            "The world that I am not, And the wind that I am not\n",
            "And I must, but I have no voice. I dream is a dream, and I dream is a dream. That I dream is a dream, and I dream is a dream. And it will be that we will dream, and its day was its day was its day\n",
            "And my dream is a dream!That I dream I love, and its day was\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    20  of     86. Loss: 0.7320264577865601.   Elapsed: 0:00:27.\n",
            "0: cialH, or hath been of power, and hath been in power and hath been in the world\n",
            "\n",
            "\n",
            "Of God, or hath been of fire, or hath been the head\n",
            "\n",
            " of the trees, or a man or woman,\n",
            " of the wild grass, or the grassing- tree, etc., etc.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.5599595308303833.   Elapsed: 0:00:46.\n",
            "0: anyahu. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     86. Loss: 0.6996777057647705.   Elapsed: 0:01:05.\n",
            "0: Group, pfrom)\n",
            "\n",
            "#\n",
            "\n",
            "pfrom, psecond, pfrom 2, n\n",
            "\n",
            "\n",
            "pfrom, psecond 2, n\n",
            "\n",
            "\n",
            "for p\n",
            "\n",
            ".\n",
            "\n",
            "— \"\n",
            "\n",
            "—,\n",
            "\n",
            "\n",
            "p in,\n",
            "\n",
            "\n",
            "soul\n",
            "\n",
            "——,\n",
            "\n",
            "\n",
            ",\n",
            "—, or\n",
            "\n",
            "p in,\n",
            "\n",
            "\n",
            "p's, as a child, as a man, or as a woman, etc.—!\n",
            "\n",
            "—\n",
            "\n",
            "———\n",
            "— \" the first, and——\n",
            "—\" and its \"—\n",
            "\n",
            "——, a man——— a bird——\n",
            "\n",
            "—, the first, and—,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    50  of     86. Loss: 0.5533664226531982.   Elapsed: 0:01:24.\n",
            "0:  Beer, coffee, tea, \n",
            "I hate to hear that the sun\n",
            " The thunder, the bells,\n",
            " That my life is,\n",
            "\n",
            "Tenth thing that the song,\n",
            " And I love the melancholy\n",
            "Of the song with a single,\n",
            " For the heart, And the brain:\n",
            " In that moment,\n",
            "And the breath of the sea And the deep,\n",
            "In this hour,And they were ever on the hills and hills of a mountain.\n",
            "And there were no stars,\n",
            "But stars that were dark!\n",
            " Where no soul is wearyingly burning—\n",
            " That no breath is a murmur—\n",
            "And no flame—\n",
            "\n",
            " And no sound,\n",
            "And no breath,\n",
            " In this time—\n",
            "And yet there hath no darkness,\n",
            "\n",
            "And no sigh of anguish.\n",
            "And there is no shadow,\n",
            "And no tears— And no pain,\n",
            " Where no wind sigheth,\n",
            "Whose brow has no brow is a rose,\n",
            "And her eyes are not weary,\n",
            "And her heart hath no love,\n",
            "Where no breath is a sigh,\n",
            "So that no tears hath,\n",
            "And no sigh-tide!\n",
            "Where no tongue hath the eye,\n",
            "Whose eye hath no breath.\n",
            "Whose heart hath no spirit—\n",
            " That no breath hath the air.\n",
            "Whose eye hath been blind for seven years—\n",
            "\n",
            "Who hath broken a heart—\n",
            "who had died by a blow. And when no soul hath made the song,\n",
            " The song that hath gone upon the wind:\n",
            "For the fire that hath no shade,\n",
            "Who hath no voice—\n",
            "And no tears that have sung the melody. For the soul that hath lived—\n",
            "\n",
            "And that hath broken into pieces—\n",
            "Whose life hath not been broken into pieces—\n",
            "And which, to that song hath been spoken:\n",
            " And who hath found the heart,\n",
            "And died\n",
            "And lived—\n",
            "\n",
            "Whom ever been silent—\n",
            " Where we have felt—\n",
            "Where this time they know,\n",
            "And who knows,\n",
            " That there is no shadow—\n",
            " And that all this day,\n",
            "And that all this night!\n",
            "With no wonder—\n",
            "And that there hath been no end—\n",
            " And they are no sigh—\n",
            "And that in this year's past—\n",
            "That she hath never been,\n",
            "\n",
            "And ever will be—\n",
            "And ever will she be,\n",
            "Which is still the song—\n",
            " and will lie on the bed—\n",
            "And she hath seen the moon—\n",
            " And she hath heard the sun—\n",
            "And the sea, and there came me,\n",
            " And there hath been me in an hour!\n",
            "And that hath slept— And that hath left her—\n",
            " And she has not been—\n",
            " In his bed\n",
            " In the sky, and she hath not been— In his heart\n",
            "The light that is night—\n",
            "And that hath drawn him away!\n",
            "The day, and there hath been my soul—\n",
            "And that was not my body,\n",
            "And that it hath been—\n",
            "That my face, and it hath left my eyes—\n",
            "And I have known the dead, and gone up—\n",
            "And the tomb, and it hath been—\n",
            "And this year' past' I shall have fallen—\n",
            "And the world hath broken—\n",
            "And I will not be,\n",
            "That I will not be—\n",
            " And my soul shall no longer dwell—\n",
            "In my eye—\n",
            "And the door is not door—\n",
            " And the door I have left—\n",
            "I shall be—\n",
            " I shall be my dream—\n",
            "It shall not be the moon—\n",
            "And there never will be a shadow\n",
            "And there never will be an old moon\n",
            "In the sky—\n",
            "And a wild night! But which are you now?\"\n",
            "Which are you now?\n",
            "That we are in the midst of the fire—\n",
            "Of her which I have no more—\n",
            "And that I have known my soul!\n",
            "And there hath been no death—\n",
            " And there hath been no death!\n",
            "So that there may not be a shadow of her that has never been!\n",
            "The song—\n",
            " The voice that hath not died!\n",
            "And the voice that hath not been left!\n",
            "That they hath not been left,\n",
            " That they have been left me!\n",
            "How a gentle song it hath been,\n",
            " And the wind that hath not been the storm!\n",
            "And the song that hath gone!\n",
            "But that it hath been gone down,\n",
            "And that it hath gone into the darkness—\n",
            "There hath been no life—\n",
            "And there hath been no light—\n",
            "That I have not slept in my bed—\n",
            "It hath been my dreams—\n",
            " But a little breath in thy lips!\n",
            "And I have not had sleep—\n",
            "\n",
            "And a little sigh in thy sigh!\n",
            "That is the song that hath not been my heart!\n",
            "But I have not seen the flower!\n",
            "It hath been the flowers—\n",
            " The rose hath not been my breath!\n",
            "That hath not been my\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.31182363629341125.   Elapsed: 0:01:43.\n",
            "0: iasm to\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    70  of     86. Loss: 0.43813613057136536.   Elapsed: 0:02:02.\n",
            "0:  prosecutid\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    80  of     86. Loss: 0.5807825326919556.   Elapsed: 0:02:21.\n",
            "0: mouthCursor\n",
            "\n",
            ": (:;)\n",
            "\n",
            "to the man, who, when a man was\n",
            "- all, and how,\n",
            " I was\n",
            "\n",
            "— my father was\n",
            "— the wife—\n",
            "—the child, etc.——\n",
            "\n",
            "to the girl—\n",
            "— her name was and now?\n",
            "\n",
            "  Average training loss: 0.58\n",
            "  Training epoch took: 0:02:38\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.60\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 3 / 20 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    10  of     86. Loss: 1.5194567441940308.   Elapsed: 0:00:08.\n",
            "0: owers, and—\n",
            " I, who am the lord of the kingdom—\n",
            " of a man, whose power is a gift!\n",
            "—\n",
            "In what spirit is the spirit of power!\n",
            "—\n",
            " in what way you can see, and, by whom!\n",
            "—\n",
            " In what spirit!\n",
            "—, in which spirit there could be nothing!\n",
            "In what spirit was the spirit of God!—\n",
            "In what spirit was the spirit of man—\n",
            "I have spoken thus from my heart—\n",
            "Thus I have spoken through my heart—\n",
            "And then I have spoken\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    20  of     86. Loss: 0.4810490310192108.   Elapsed: 0:00:27.\n",
            "0:  commWithUncended;\n",
            "\n",
            "\n",
            "? \n",
            "\n",
            ". \n",
            "\n",
            "! The poet of the sea!\n",
            "\n",
            "? \n",
            "? \n",
            " \n",
            "! The poet of the woods!\n",
            "? \n",
            "!\n",
            " \n",
            "—! The poet of the woods!\n",
            "— The poet of the forest!— The poet of the mountain!— The poet from a mountainside! This is the poem of the valley.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.25570791959762573.   Elapsed: 0:00:45.\n",
            "0: nesotaA man who dreams, I dream, I dream.\n",
            " In the deep and lonely dreams that are haunted.\"\n",
            " The star hath cast, which shadows to shine.\n",
            " That shadow that flickers with the sunset.\n",
            " That glow in the shadow of the moon—\n",
            " It is the sun that flickers with the moon.\n",
            " That beam from the curtain— And its beam from Heaven—\n",
            " Where his eyes fly upon a dream-like pall,\n",
            " That in a dreaming heart, its eyes are on me!\n",
            " That dream is upon me!\n",
            " In a feeling of loneliness which still dwells,\n",
            " But will never return.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     86. Loss: 0.3100624084472656.   Elapsed: 0:01:05.\n",
            "0:  waitedIt was,\n",
            " Let him be as much as could take away its beauty—\n",
            " A lie That bore an evil dream,\n",
            " And all my dreams\n",
            " Be now upon me—\n",
            " To be forever dead to the world.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    50  of     86. Loss: 0.6029403209686279.   Elapsed: 0:01:24.\n",
            "0:  Yugs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.2880837917327881.   Elapsed: 0:01:43.\n",
            "0:  tutorials of this\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    70  of     86. Loss: 0.3644973039627075.   Elapsed: 0:02:02.\n",
            "0:  TrA, b) shall be taken, or shall come within the bounds of the bounds of the bounds of this earth, and dwelt upon\n",
            " \n",
            "The bounds of this earth, and dwelt upon its walls;\n",
            " From the shore of the sea \n",
            "With a sea within this sea, I seek, in thine own heart\n",
            "\n",
            "Into a strange dream of an uncertain future \n",
            "Of a dream that was the first waking \n",
            "Of a shadowy, shadowy dream that lay \n",
            "Upon my chamber floor, me from the waking \n",
            "Of my dead soul!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    80  of     86. Loss: 0.22380724549293518.   Elapsed: 0:02:20.\n",
            "0:  panic as\n",
            "\n",
            "  Average training loss: 0.53\n",
            "  Training epoch took: 0:02:36\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.58\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 4 / 20 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    10  of     86. Loss: 0.6779689192771912.   Elapsed: 0:00:08.\n",
            "0:  exclusively and true!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    20  of     86. Loss: 0.6548184752464294.   Elapsed: 0:00:26.\n",
            "0: worthy\"\n",
            "\n",
            "My life is a journey. It is a journey fraught with danger and strife and gloom and danger and gloom. My mind, that most sublime and most glorious of all human beings, my spirit, my brain, is the fountain of love.\n",
            "\n",
            "There is a danger, and a danger—some dark evil, that could very easily have been cast upon me.\n",
            "And there is a danger—not the sun, and the angels, but the shadows, all of which lie on the ground, in one spot, within the grave, with some darkness, and some gloom, and some gloom in the very midst of a beautiful world.\n",
            "So far from my sight, my brain—the eye—the heart—the heart-place—the heart—all this God bless me and all my love—\n",
            "And there are the things that lie upon the ground, as an emblem of pride,\n",
            "And all this God bless me and all my love—\n",
            " And all these lies upon the ground\n",
            "Of human memory,—\n",
            "And all things that lie upon the ground\n",
            "Of my image—\n",
            "All this God bless me and all my love \n",
            "Of my life—the things that lie upon the ground!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.527568519115448.   Elapsed: 0:00:45.\n",
            "0:  meals.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     86. Loss: 0.3400200307369232.   Elapsed: 0:01:04.\n",
            "0:  tokens\n",
            "\n",
            "\n",
            ", \n",
            "\n",
            "\n",
            "!\n",
            "\n",
            "!\n",
            "\n",
            "!\n",
            "\n",
            "!\n",
            "\n",
            "!\n",
            "\n",
            "!\n",
            "\n",
            "!\n",
            "\n",
            "!\n",
            "\n",
            "!\n",
            "\n",
            "!\n",
            "\n",
            "!\n",
            "\n",
            "!\n",
            "\n",
            "!\n",
            "\n",
            "!\n",
            "\n",
            "!\n",
            "\n",
            "!\n",
            "!\n",
            "\n",
            "!\n",
            "!\n",
            "!\n",
            "\n",
            "!\n",
            "\n",
            "!\n",
            " \n",
            "!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    50  of     86. Loss: 0.41992923617362976.   Elapsed: 0:01:24.\n",
            "0: educAll(p)\n",
            "\n",
            "For each of the spirits\n",
            " Where no light hath flown nor light dimmer\n",
            " All my heart hath flown and dimmer\n",
            " Which never was to shine.\n",
            " That all my earthly life was left to look.\n",
            " That I had no earthly home to live,\n",
            " With no earthly hope to go home.\n",
            "And yet, I never ceased to be content.\n",
            "\n",
            " And I never ceased to think that I may find,\n",
            " And then that I may discover,\n",
            " And that I may see.\n",
            " And then that I may find\n",
            " And that I may see that I may find\n",
            " That this may not be the beginning of the time.\n",
            " But when the night falls,\n",
            " And when the air beats from the valley—\n",
            " And when the night bends,\n",
            " With the soft chill wind leaves the door.\n",
            " For it may not be the beginning of the moment.\n",
            "And when the time passes,\n",
            "When the night passes.\n",
            " For it may not be the beginning of the hour. And how long did the night run?\n",
            "How long did the hour pass?\n",
            "How long did the hour pass?\n",
            "And when the air blows from the valley,\n",
            " But when the air blows from the valley,\n",
            " And when the night falls,\n",
            " And where the night falls,\n",
            " And where the sunset passes. And then, then, there! The voice of the thunder and the roar—\n",
            " All the music of that roar,\n",
            " But there no word is uttered, \n",
            " But all all the music of the thrones.\n",
            " Where there is the sound of the thunder—\n",
            " Wherever there is the sound of the thrones,\n",
            " Wherever there is the roar of the bells\n",
            " Wherever there is the shriek of the bells. And all this is—the sound of the bells—\n",
            " Wherever there is the roar of the bells—\n",
            " Wherever there is the lullaby from the bells—\n",
            " Where there is the sweet voice from the bells—\n",
            " Wherever there is the sweet voice from the bells. For there is nothing more beautiful than there is,\n",
            " But there are nothing more happy, and nothing more sad and wild!\n",
            " On the shore of Heaven\n",
            " That which never passes through the sea,\n",
            " Shall pass through the skies\n",
            " Wherever you are awake— But there are nothing more strange than there—\n",
            " That there are nothing more beautiful than there are—\n",
            " that there is nothing more hideous—\n",
            " That there is nothing more profound and strange than there are—\n",
            " That there is nothing more solemn—that there is nothing more beautiful, and nothing more profound—\n",
            " That there is nothing more solemn than there is—\n",
            " That there is nothing more solemn and lovely—\n",
            " That there is nothing more beautiful and more profound—\n",
            " That there is nothing more extravagant and silly,\n",
            " That there is nothing more beautiful and more beautiful—\n",
            " That there is nothing more beautiful than this,\n",
            " That there is nothing more beautiful and more beautiful—\n",
            " That the spirit and the sound of the bells seem not to hear\n",
            " \n",
            " A song whose melody, and melody,\n",
            " Are not to be uttered—\n",
            " Who would love thee,\n",
            " That would worship thee!\n",
            " Who would love thee,\n",
            " That did not love thee!\n",
            " Who would love thee,\n",
            " That did not love thee!\n",
            " Who would love thee!\n",
            " who did not love thee!\n",
            " And who did\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 1.3405622243881226.   Elapsed: 0:01:42.\n",
            "0:  Single, with his head and hair\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    70  of     86. Loss: 0.33538252115249634.   Elapsed: 0:02:01.\n",
            "0: obeAveragingHeart: I am, and shall be, a young, melancholy, young man\n",
            " Of young love, love of life.\n",
            " As a father tells his wife a few words of wisdom,\n",
            " As a young knight tells his youth a few words of praise;\n",
            " As a young father tells his son that his love, his name is,\n",
            " Shall be, and be, a father in her young mind,\n",
            " And not be happy, not to be loved \n",
            " To her breast!—\n",
            " As a child tells an old tale—\n",
            " In her young years, her youth the maiden's breast\n",
            " But, if her maiden's maiden's maiden's maiden was not happy\n",
            " In her maiden's maiden's life,\n",
            " To her mother's breast!— she tells her tale \n",
            " Upon a lonely mountain, in which her love, her name was,\n",
            " Is, and now is,\n",
            " With a dream in an earlike cloud\n",
            " A dream, and a voice in the air.\n",
            " Who is it? the voice in the air, \n",
            " Who is it to whom my name is spoken?—\n",
            " Who is it to whom, I am speaking?—\n",
            " Who is it whom, I have spoken?\n",
            " Who is it whom, I have spoken? I have spoken,\n",
            " What I have spoken, I have not spoken. \n",
            " Who I have spoken, I have not spoken.\n",
            " Who, I know there are, in the wild,\n",
            " In the forest, in the woods,\n",
            " Where the trees seem no more\n",
            " Of life, and in the forest,\n",
            " Of death, and love, and life,\n",
            " Where the woods seem never to dwell—\n",
            " Which death dwells in the shadows,\n",
            " Which no longer dwells. The night, when it was—\n",
            " Who no longer sleeps—\n",
            " That a dream dwells in the shadows,\n",
            " Which no longer dwells in dreams,\n",
            " Where the night lies,\n",
            " And no longer lies—\n",
            " Which no longer sleeps.\n",
            " Where the night sleeps,— And no longer sleeps.\n",
            " Where the night sleeps,\n",
            " Which the moon hangs,\n",
            " Where the moon falls,\n",
            " Which the moon fell,\n",
            " Which all the stars which be Heaven's star. But in Heaven's bosom,\n",
            " And in the midst a cold air\n",
            " Let the stars which be Heaven's starbearer. Let the stars which be Heaven's star,\n",
            " All these starlit rays, and the stars which be Heaven's star,\n",
            " Which the stars which may be Heaven's star,\n",
            " Be, and be, the stars in Heaven's soul\n",
            "— And that, though they be Heaven,\n",
            " Shall be, and that that is Heaven's star,\n",
            " Shall be the stars in Heaven's heart\n",
            " \n",
            " That is, and shall be Heaven's star,\n",
            " That is, and shall be Heaven's star!\n",
            " And when it hath taken,\n",
            " Who hath taken, \n",
            " That hath given, that hath given,\n",
            " What hath given, that hath given,\n",
            " Where has given, which I have given,\n",
            " Where is given, which I have not given\n",
            " Where the star was seen, which I have not seen \n",
            "\n",
            " Where the sky was drawn, which I have not seen\n",
            " Where the winds were quivering\n",
            " Where the seas were falling. \n",
            " Where the moon was falling, which, I have not seen \n",
            " Where the stars were twining, which were wandering!\n",
            " Where the clouds were burning, which are burning—\n",
            " Where the birds died, which were murmuring \n",
            " Where the trees were falling, which were moaning\n",
            " Where the sea was rising, which were rising—\n",
            " Where the winds were rolling\n",
            " Where the rain was falling. So that the sea \n",
            " Shall be in her own right, \n",
            " And the skies shall be in her own right,\n",
            " Whose brows shall be left wide, \n",
            " Which are now open, with a red star \n",
            " Which hath seen them, and hath heard them \n",
            " Which are still dreaming, \n",
            " That they awake, and that they awake\n",
            " Are dreaming—\n",
            " Where they die— That they awake, and die,\n",
            " Which is the world, the world \n",
            " Which is a mirror of the human heart—\n",
            " Where the starry night, on which it breathes \n",
            " Is half black, and half bright\n",
            " What lies on the rim of the globe\n",
            " Are half broken, and half red!\n",
            " Where the sun is at half-spread, \n",
            " Are half dim-eared glasses, and half bright\n",
            " Of all that the sun looks!\n",
            " Where the moon is at half-spread\n",
            " And half bright, and half silent,\n",
            " Where the stars are half-silvery,\n",
            " Which they dimly dimly dimly dim,\n",
            " Where the starry night has given \n",
            " Which dimly dimly dimly dim\n",
            " Shall shine in a dim light. In an eternal night,\n",
            " Where the sky is dimly dim. And the moon\n",
            " Is half-bright\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    80  of     86. Loss: 0.36427897214889526.   Elapsed: 0:02:20.\n",
            "0: brance of the saints\n",
            "\n",
            "  Average training loss: 0.50\n",
            "  Training epoch took: 0:02:36\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.58\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 5 / 20 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    10  of     86. Loss: 0.2804493308067322.   Elapsed: 0:00:08.\n",
            "0:  ObIy bile \n",
            " Of all the holy angels;\n",
            " Thou hast not the glory of beauty\n",
            " \n",
            " Of all the sacred mysteries.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    20  of     86. Loss: 0.5543277859687805.   Elapsed: 0:00:26.\n",
            "0:  assignedIn mid-life to the \n",
            " (?) time of their death ; and died in mid-life\n",
            " \n",
            "—which, by the time of a solemnly-dressed death, \n",
            "—which were in the thro' the \n",
            "—life —of their life —which, in its hour, \n",
            "—which is the world —is a solemn, revelling, solemn, solemn, solemn \n",
            "—which is a death —which was in the thro' \n",
            "of a solemn, solemn, solemn life \n",
            "—which, by the time that \n",
            "—is a death —is a death —which was in \n",
            "the time that —is a death —which was in the time \n",
            "which is a death —which was \n",
            "of a human being.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.33038443326950073.   Elapsed: 0:00:45.\n",
            "0: ipesI should say nothing but my opinion and my spirit!\n",
            "\n",
            "Let this light shine upon my head!\n",
            "The light on the brow\n",
            "With a voice called me\n",
            "\n",
            "With the voice called me!\n",
            "Come ye here: ye here, when I have seen\n",
            "Ah! my friends! all those who have loved\n",
            "They feel so happy in my presence;\n",
            "That, in my presence, they feel so sad!\n",
            "They think me in a dream—\n",
            "They will lie down on the floor,\n",
            "Upon a floor and a floor,\n",
            "Upon the floor and the floor\n",
            "Upon a floor—\n",
            "Oh! my eyes—for their sad heart!\n",
            "Their hearts are full of tears—\n",
            "And they lie down in their chambers!\n",
            "They lie down in their chambers!—\n",
            "Their hearts are full of pride—\n",
            " They think they know nothing about.\n",
            "They lie down, and they lie down,\n",
            " And they lie down, and they lie down—\n",
            "They lie down—\n",
            " They lie down, and they lie down—\n",
            " They lie down—they lie down—\n",
            " But they lie down, and they lie down—\n",
            "The spirits seem to be dead!\n",
            "They sit down in their chambers—\n",
            "The spirits seem to be dead—\n",
            "They lie down, and they lie down.\n",
            "They sit, and they lie down,\n",
            " And they lie down, and they lie down—\n",
            "The spirits seem to be dead!\n",
            " And they lie down, and they lie down!\n",
            "But they lie down, and they lie down,\n",
            " and they lie down, and they lie down—\n",
            "With a fervent and passionate tone,\n",
            " And with a spirit, and a spirit—\n",
            "They lie down, and they lie down, and they lie down—\n",
            " And they lie down, and they lie down—\n",
            "Their heart hath been broken—and they lie down!\n",
            "They lie down, and they lie down—\n",
            "And they lie down, and they lie down!\n",
            "That hath been their own self—\n",
            "And they lie down, and they lie down!\n",
            "And they lie down, and they lie down!\n",
            "That hath been their own self—\n",
            "And they lie down!\n",
            "That hath been their own—\n",
            "In this world they have lived, and they have died—\n",
            "And they lie down!\n",
            "That hath been their own self—\n",
            "In this world they have dwell—\n",
            "And they lie down, and they lie down!\n",
            "And they lie down, and they lie down—\n",
            "That hath been their own self—\n",
            "In this world they hath gone, and they are dead!\n",
            "They have lived, and they die—\n",
            "But they lie down!—\n",
            "And they lie down, and they lie down!\n",
            "They lie down—and they lie down!—\n",
            "They lie down, and they lie down,\n",
            "Their souls be silent!\n",
            "They lie down—and they lie down!\n",
            "And they lie down, and they lie down!\n",
            " They lie down, and they lie down!\n",
            "They lie down, and they lie down!\n",
            "They lie down, and they lie down!—\n",
            "Their souls lie down!\n",
            "And they lie down!\n",
            "Their hearts lie down!\n",
            "They lie down, and they lie down!\n",
            "They lie down, and they lie down!\n",
            "They lie down, and they lie down!\n",
            "They lie down, and they lie down!\n",
            " They lie down, and they lie down!\n",
            "They lie down, and they lie down!\n",
            "They lie down, and they lie down!\n",
            "They lie down, and they lie down!\n",
            "Their hearts lie down! They lie down!\n",
            "They lie down, and they lie down!\n",
            "They lie down, and they lie down!\n",
            "They lie down, and they lie down!\n",
            "They lie down, and they lie down!\n",
            "They lie down, and they lie down!\n",
            "They lie down, and they lie down!\n",
            "They lie down, and they lie down!\n",
            "Their heart lies down!\n",
            "They lie down!\n",
            "They lie down, and they lie down!\n",
            "Their spirit lies down! They lie down, and they lie down!\n",
            "Their spirit lies down! They lie down!—\n",
            "Their spirit lie down—And they lie down!\n",
            "But they lie down, and they lie down!\n",
            "They lie down, and they lie down!\n",
            " They lie down, and they lie down!\n",
            "They lie down, and they lie down!\n",
            " They lie down, and they lie down!\n",
            "Their passions lie down! they lie down!\n",
            "They lie down, and they lie down!\n",
            " They lie down, and they lie down!\n",
            "Their souls lie down! They lie down!\n",
            "Their pride lies down! They lie down, and they lie down!\n",
            "Their pride lies down! They lie down! They lie down!\n",
            "They lie down, and they lie down!\n",
            "Their spirit, and the spirit, and the spirit\n",
            "Of all beings, hath been\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     86. Loss: 0.3230680525302887.   Elapsed: 0:01:04.\n",
            "0: avier'\n",
            "\n",
            "And\n",
            "'tis no wonder now that my father hath,\n",
            "Upon my brow,\n",
            "Upon my breast\n",
            "My lips\n",
            "My lips are bound\n",
            "And bound in the power which,\n",
            "Is within me,\n",
            "Thwart my pride, and the love of Heaven.\n",
            "Tells the tale which I know\n",
            "To the song which I know—or to the song which I love—\n",
            "The tale which I know—or I love—\n",
            "While I know—\n",
            "\n",
            " I love— I lie—\n",
            " That I love the heart which,\n",
            "And the eye which love it—\n",
            "And the sound which it harks in a song—\n",
            "Yet—as he—\n",
            " The star is the star,\n",
            " The night—\n",
            "The night is the sun—\n",
            "The day is the summer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    50  of     86. Loss: 0.3236652612686157.   Elapsed: 0:01:23.\n",
            "0:  totally)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.3607454299926758.   Elapsed: 0:01:42.\n",
            "0:  slog the bazooka of the moon and rolled the rolling dank lid of her wand — the rill of a demon of the moon and the woollen moor and the shriek of the thunder—the cry of the moon's w\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    70  of     86. Loss: 0.7434288859367371.   Elapsed: 0:02:01.\n",
            "0:  pissed for\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    80  of     86. Loss: 0.20302505791187286.   Elapsed: 0:02:20.\n",
            "0: mph\n",
            "\n",
            "\n",
            "or (?)\n",
            "\n",
            "  Average training loss: 0.49\n",
            "  Training epoch took: 0:02:35\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.57\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 6 / 20 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    10  of     86. Loss: 0.43660640716552734.   Elapsed: 0:00:08.\n",
            "0: Similarly'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    20  of     86. Loss: 0.4339956045150757.   Elapsed: 0:00:26.\n",
            "0: elligAquorace\n",
            "\n",
            "O God, who waddled the seas \n",
            " A pall from that burning summer \n",
            " And brought us back\n",
            " To the quietest, quietest, quietest shore \n",
            " To that night of the night:\n",
            " With the serene solace of an Earth \n",
            " Of thine own shore: A spirit as cold as the night.\n",
            " A spirit that can guide,\n",
            " To guide, to guide, to guide the spirit.\n",
            " On my heart that trembles,\n",
            " That trembles, trembles, trembles, \n",
            " With its own voice that trembled\n",
            " In the tumult of love,\n",
            " That trembled—which trembled—as they wandered \n",
            " As they wandered—that trembled;\n",
            " With their own voice that trembled,\n",
            " With their own voice that trembled, \n",
            " With their own voice that trembled.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.49053245782852173.   Elapsed: 0:00:45.\n",
            "0:  compassion'\n",
            "\n",
            "'They were weary of my spirit'\n",
            "\n",
            "That would not shake my head at them'\n",
            "\n",
            " 'Yet did tremble within my soul'\n",
            "While that soul bore me\n",
            " 'And trembled beneath my spirit'\n",
            " As if I felt there a creeping chill,\n",
            "Of deep thought, of danger,\n",
            "Of desperate love, and in a wilderness that I dared not tread.\n",
            "To the mystic maiden whom the visions of God and men have conquered\n",
            "While it is written, 'It is written, 'it is written, 'it is written in prayer: This will my soul bless thee: That will guide thee, and the light of thy fire\n",
            " In thy dreams, till the sun dies\n",
            "With a deafening voice, till the night turns: What is thy fate?' But those few tears that creep from me\n",
            "With visions which are not yet made—\n",
            "They are not so deep as to fill my soul,\n",
            "And their echoes to the skies\n",
            "Are not so soft to me!\n",
            "With some shadowy voice,\n",
            "And some deep tone,\n",
            "My soul floats in a spirit of wonder—\n",
            "That I might not know what he was dreaming about\n",
            "With which his soul felt so much fear. 'Twas a star in the sky,\n",
            " That the sun seemed to be waning;\n",
            "That the moon was gazing down,\n",
            "Of the night hovering far above the sky. I have not heard that voice of God's—\n",
            "That the stars are burning from the fire\n",
            "Of the stars, that the planets are sinking into that lake—\n",
            "And that the winds are setting in my heart—\n",
            "That I cannot save thee from dreaming—\n",
            " That the angels are smiling at the sight\n",
            " Of some happy maiden of the Night—\n",
            "And the stars are gazing down upon me—\n",
            "That there is not time to weep,\n",
            " To weep for thy own soul, \n",
            " For your heart—\n",
            " But this heart is not alone at heart—\n",
            " That it is an earthly power,\n",
            " For this mortal soul can only seem\n",
            "To belong to the Heavens and Earth.\n",
            "To the Earth, without a name, \n",
            " From this world, that lie-tell, is hid\n",
            "Under my chamber door—\n",
            "And I have a solemn tomb, that the tomb\n",
            "With which none can hide \n",
            "But the spirits of the dead lie,\n",
            "\n",
            "That those who have seen them—\n",
            " Where they dwell, not only in solitude,\n",
            "But have seen them within—\n",
            " That their memories are as soft and unbroken,\n",
            "With a pall of violet mist and gray flowers,\n",
            " For evermore and evermore\n",
            "My soul—\n",
            " And I know not what he is,\n",
            " That he knows no form—\n",
            " That I cannot feel, no tone—\n",
            " That no tone may be given;\n",
            " that no tone may feel:\n",
            "That the world cannot tell me\n",
            "How I am alone—\n",
            " The mystery is obscured by shadows!\n",
            " That the mysteries, which lie on the floor\n",
            "Of the chambers, lie on the floor—\n",
            "That the mystery, which lies in the heart\n",
            "Of the dead—\n",
            " Is so distant that it cannot be known!\n",
            "That it is only a mystery,\n",
            " That it can never be seen!\n",
            " That it cannot be found!—\n",
            " That the mysteries cannot find me!\n",
            " That there is none! The mystery, which I must pass\n",
            "To remember, shall not find me!—\n",
            " That the mysteries, which I may pass\n",
            "To remember, may never find me! \n",
            " That there is none!\n",
            "That the mysteries, which I may pass\n",
            "To remember, may never find me!\n",
            " That there is none!\n",
            "That I may not pass alone!\n",
            "But I may pass into the vault!\n",
            " Where the mysteries, which I may pass\n",
            "To pass through the vault!\n",
            " Have no name!\n",
            "Not one name!\n",
            " Not one word!\n",
            "For the mystery is concealed—\n",
            "In a cloud of violet cloud,\n",
            " With which nothing can hide!\n",
            " The mystery lies so distant as that no light may pass\n",
            "From all over the Earth—\n",
            "That no spirit will ever pass!\n",
            "That the mysteries have no name—\n",
            "That the mysteries are a mystery to himself and himself!\n",
            "That the secrets are a mystery to us all!\n",
            "That the mysteries are an evil mystery,\n",
            "That nothing can save them from all that is evil!\n",
            "That the mysteries have no name!\n",
            "That a spirit cannot save them from all that has evil,\n",
            "That a mortal could save them from all that is evil!\n",
            "That a wizard cannot save them from the power of God!\n",
            "That a spirit cannot save him from evil,\n",
            "That a mortal could save him from the power of the devil!\n",
            " that a spirit cannot save him from all that he loves!\n",
            " that a man shall inherit all the kingdom of Heaven!\n",
            " That a man shall inherit all the earth!\n",
            " That a man shall inherit the kingdom of God!\n",
            " that a man shall inherit all\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     86. Loss: 0.3350307047367096.   Elapsed: 0:01:03.\n",
            "0:  slated\n",
            " \n",
            "—the first rain-drops\n",
            " \n",
            "—the most beautiful and most brilliant light—\n",
            " \n",
            "—the most beautiful and most beautiful light-\n",
            " \n",
            "—the radiant and the radiant and the radiant\n",
            " \n",
            "—the first and only \n",
            " and then \n",
            "—the only thing that will be truly \n",
            " \n",
            "with a happy hope that he may be \n",
            "—one who knows nothing \n",
            " But the truth of life itself \n",
            " Is utterly unknown.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    50  of     86. Loss: 0.3626382052898407.   Elapsed: 0:01:22.\n",
            "0:  upstairs's door of the town hall;—\n",
            " \"Mother, be quiet! The devil dwells upon me!\"\n",
            " (For the most part I could tell no soul of her,)\n",
            " That, with his own eyes, I saw no evil eye—\n",
            " That, with his own eyes— I saw no evil eye—\n",
            " That, with his own eyes— I saw no evil eye—\n",
            " That I saw nothing evil in the world,\n",
            " \n",
            " That I saw no evil eye on the stars:—and the star is the light from Heaven,\n",
            " And it is my hope that it shall never seem to me\n",
            " To see the shadow of Hell!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.7360499501228333.   Elapsed: 0:01:41.\n",
            "0:  grants\n",
            "\n",
            "How good a man he hath been—as he hath been—as he hath been—\n",
            " In what country\n",
            "The world is made of the flowers of a summer's day—\n",
            "And thus far there have been;\n",
            "And in the wildest gardens, in the quietest woods,\n",
            "How well there is God, and how well there is God—\n",
            "How well the wind bends—the wind, the sea, the forest—\n",
            " How well the rain beats. I say,\n",
            "I say, not in a word that I know—but, that a word I know,\n",
            " That a word I know,\n",
            " That a word I know, that a word I know,\n",
            " But nothing of such kind will save us;\n",
            "And nothing of such kind will save us.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    70  of     86. Loss: 1.3328813314437866.   Elapsed: 0:02:00.\n",
            "0:  Sixth. The second was \"the moment of perfect silence\"—the moment when, amid all the pomp and pomp of Heaven, there were no murmuring of angels. The fourth hour was the happiest hour of my life. And the fifth hour is the happiest hour ever.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    80  of     86. Loss: 0.49184098839759827.   Elapsed: 0:02:19.\n",
            "0:  mining\" \"mid-century—midcentury\"—and then \n",
            " \n",
            "'mid\n",
            "'Mid-century, and then\n",
            " \n",
            "'midmidcentury—midcentury—midcentury, \n",
            " \n",
            " I would call it I the last—midcentury—midcentury, \n",
            " \n",
            "And when the winds blew,\n",
            " Then it went wild and \n",
            "'mid—midcentury—midcentury—midcentury\n",
            " \n",
            "'midcentury—midcentury—midcentury, \n",
            "'midcentury—midcentury—midcentury'\n",
            "'midcentury—midcentury—midcentury, \n",
            "'midcentury—midcentury—midcentury' \n",
            "'midcentury—midcentury—midcentury—midcentury. See \n",
            "'midcentury—midcentury—midcentury—midcentury,\n",
            "'midcentury—midcentury—midcentury,'midcentury—midcentury, \n",
            "'midcentury—midcentury—midcentury, \n",
            "'midcentury—midcentury—midcentury, \n",
            "'midcentury—midcentury—midcentury, \n",
            "'midcentury—midcentury—midcentury, \n",
            "'midcentury—midcentury—midcentury—midcentury.\n",
            "\n",
            "  Average training loss: 0.47\n",
            "  Training epoch took: 0:02:35\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.57\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 7 / 20 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    10  of     86. Loss: 0.9228532314300537.   Elapsed: 0:00:08.\n",
            "0:  Mo'Ran, whose\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    20  of     86. Loss: 0.649259626865387.   Elapsed: 0:00:26.\n",
            "0:  Jr (from the moon), and the earth,\n",
            "The moonbeam of the sun.\n",
            "I believe, that there is some strange object—\n",
            "In the twilight hours of this town,\n",
            "Of night, and night,\n",
            "What seems to be growing on my tongue, \n",
            "With what is within me—\n",
            "What is growing on my cheek\n",
            "What can not, that you may be sure,\n",
            "Not be startled by the strange,\n",
            "Unquiet beauty \n",
            "Of the night, and time;\n",
            "And, if you may, be sure, that the sky is far—\n",
            "And the moon is far above—\n",
            "And the stars are far above.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.3139103353023529.   Elapsed: 0:00:45.\n",
            "0: iseI see him sleeping in a bed,\" said the angel— \n",
            " A happy Night, in the Night,\n",
            " With the Night. I knew him only— \n",
            " But he still stood. \n",
            " A shadow of his eye;\n",
            " Where there was none— \n",
            " He slept, still, though— \n",
            " A dream of his beauty,\n",
            " In an enchanted chamber \n",
            " Where shadows had lain!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     86. Loss: 0.2827390134334564.   Elapsed: 0:01:03.\n",
            "0:  pushed-up-his-feet (and so on—),\n",
            " That the spirit's still and still, in the breast-top (as the angel, to their delight, hath departed),\n",
            " And they lie in thy breast-top,\n",
            " And they lie down upon a high throne of thrones:\n",
            " That this Heaven and Earth which so entombed thee—\n",
            " But thus did the angels bind thee,\n",
            " Forgetting my voice.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    50  of     86. Loss: 0.43926215171813965.   Elapsed: 0:01:22.\n",
            "0: holesI saw thee,\n",
            "A pale face gazing,\n",
            "And a radiant tone that said,\n",
            "Not long ago,\n",
            " That thou art a gentle maiden—not\n",
            "Of flowers at the tops of trees \n",
            " With the gentle roses towered.\n",
            "What, then, is thy love?\n",
            "And thy beauty?\n",
            "What, then, is thy passion? \n",
            "What, then, is thy beauty?\n",
            "How, then, have I given thee my life?\n",
            "How, then, have I given thee aught? \n",
            "How, then, did I take away thy breath?\n",
            "How, then, have I given thee aught?\n",
            "How, then, have I taken away thy power?\n",
            "Which hath not no lasting power \n",
            "To this most glorious star? Which hath none—\n",
            "Which all God has known \n",
            "Too well, that thou hast not known?\n",
            "Therefore, I have given thee thy life—\n",
            "And now, I have given thee thee a new name \n",
            "Of the gentle maiden—\n",
            "And now, in remembrance, to be given. \n",
            "While the beauty of thy pride \n",
            "Has waned!\n",
            "While the pain of thy pride \n",
            "Has gone, I have given thee a new name—\n",
            "Yet, with thy death,\n",
            "I have given thee a new name. \n",
            "Whose name shall \n",
            "Never be changed by death?\n",
            "And whose name shall \n",
            "Never be altered by death? \n",
            "Who shall ever think \n",
            "That these things \n",
            "Can be broken by death? \n",
            "How—how, then, have I brought \n",
            " Thy name from heaven!\n",
            "Where the death, \n",
            "Can descend in chaos!\n",
            "A radiant light of glory—\n",
            "And whose name shall \n",
            "Never be changed by death!\n",
            "But whose name shall ever be changed \n",
            "By the power of thy death, \n",
            "By the power of thy death! —\n",
            "But whose name shall ever be changed \n",
            "By the power of thy death? \n",
            "Who shall ever be—\n",
            "How and whether thy spirit shall \n",
            "Tale \n",
            "How well it may die—\n",
            "And who shall ever seem \n",
            "To shake it in the air—\n",
            "To utter it— \n",
            " That the sun may no longer be!\n",
            "With a passionate cry!\n",
            "The moon may no longer be!\n",
            "With a burning passion—\n",
            " Wherever thee may dwell, \n",
            "It is—the sun! —\n",
            " With a fiery thirst! \n",
            "With a burning thirst for breath! \n",
            "Whose heart may dwell,\n",
            "A burning thirst for life! \n",
            "How long shall it be \n",
            "With a passionate cry,\n",
            "To awaken thee?\n",
            "Wherever thy spirit dwell\n",
            "No more!\n",
            "No more!\n",
            "Who is thy soul?\n",
            "How long shall it be—\n",
            "When no more!\n",
            "It will be—and nothing shall save \n",
            "The pride and pride of thy soul! \n",
            " Wherever thou may know,\n",
            "It may be in the bosom of God!\n",
            "That thy spirit dwell—\n",
            "But nothing shall save it!\n",
            "That thy pride and pride may lie \n",
            "Upon the floor!\n",
            "And the mystery of thy crime and crime \n",
            "On the floor!—\n",
            "Which, so far apart from my own, \n",
            "I have left to no visitor—\n",
            "Nor shall the rest of those \n",
            "Never see \n",
            "The fountain where thy spirit dwell \n",
            "Thou art in me!—\n",
            "That, so far apart, \n",
            " I have left thee,\n",
            "And I have left thee,\n",
            "To no visitor,—\n",
            "Nor shall I ever see\n",
            "The fountain where thy soul dwell!—\n",
            "Where a visitor lies! \"\n",
            " A visitor in my chamber!\"\n",
            " \"A visitor, in mine chamber!\"\n",
            " I tell you,\n",
            "How often, when at length \n",
            "Of all the human creatures \n",
            "What are in view! \n",
            "I tell you, how often!\n",
            "What are the days, if not hours, \n",
            "Of the year, when \n",
            "Of all the human beings \n",
            "Are in view! \n",
            "And the stars above and below,\n",
            "Have not seen\n",
            "Their brightest bright \n",
            "What are in view!—\n",
            "That this beautiful day \n",
            "Is but a shadow \n",
            "Which is taken away with a sigh,\n",
            "Which is taken away with the sigh of the visitor,\n",
            "Which is taken away by the visitor,\n",
            "Which is taken away by the visitor—\n",
            " Which may not be seen\n",
            "By my soul—but may be seen!\n",
            "—whose heart is buried,\n",
            "which may not be seen?—who may not be found—\n",
            "\n",
            "whose air is hid \n",
            "And which will be flown \n",
            "With an eagle, \n",
            "To a lonely bird, \n",
            " And to a lone bird, \n",
            "Which will not be seen, but shall perish \n",
            "With a thunder—\n",
            "And who will pass away \n",
            "With an eagle, \n",
            "Who, in heaven,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.28179609775543213.   Elapsed: 0:01:41.\n",
            "0:  MarxistThe\n",
            "\n",
            "Can tell\n",
            "The mystery of fate\n",
            " With a view\n",
            "Of what fate hangs on us\n",
            "In this world, and in the\n",
            "From which all we have been raised\n",
            "Is from a dead sea,\n",
            "I feel it, that fate hangs\n",
            "On my hand in the trunk\n",
            "And my soul—or—myself—not—my mother—\n",
            "And me—the very rest!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    70  of     86. Loss: 2.1519572734832764.   Elapsed: 0:02:00.\n",
            "0:  IchOn, \n",
            " With flowers of many flowers \n",
            " Floating around, \n",
            " The sun on \n",
            " Stoege and the laurel trees\n",
            " Tamed and cultivated \n",
            " The trees, \n",
            " They never grew \n",
            " To wit, \n",
            " For the trees, as they grew, \n",
            " That there arose a new beauty from the \n",
            " Earth of which I have known.\n",
            " Where then \n",
            " Was this beauty \n",
            " Where the beauty of this beautiful world \n",
            " Sprinkle by the splendor of its present \n",
            " Contents p. 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    80  of     86. Loss: 0.35309651494026184.   Elapsed: 0:02:18.\n",
            "0:  Avenue, I found a river—a river—\n",
            " A river—some river, that grew down to my heart,\n",
            " The path of a wild bird, by a river\n",
            " That has not stopped its flight—\n",
            " Where the torrent came from the streams—\n",
            " When the mountain-top fell—\n",
            " Where there was a shower of rain to my eyes,\n",
            " And the sea—which dwelt and grew,\n",
            " And disappeared, \n",
            " To a dream in which I dreamt,\n",
            " The beauty of which is nothing\n",
            " And my heart sinks, \n",
            " To the sad reality of the deep\n",
            " In a deep ocean bound and bound\n",
            " To shore, who can save himself, \n",
            " Or even the soul?\n",
            "\n",
            "  Average training loss: 0.45\n",
            "  Training epoch took: 0:02:35\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.57\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 8 / 20 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    10  of     86. Loss: 0.3902733325958252.   Elapsed: 0:00:08.\n",
            "0:  appliesI, not in my power to command a throne of such power\n",
            "But as a crown of power of the angels—\n",
            "And the throne of heaven given to thee by the angels—\n",
            "And the throne of the demons given to thee by the demons—\n",
            "And the throne of the demons given to thee by the demons,\n",
            " And that most holy emblem given to thee by thy mother,—\n",
            "Of a kingdom of God—of a kingdom that is God,—\n",
            "That is called the kingdom given to thee by the angels—\n",
            "That God himself  \n",
            "A God of wealth and power hath sent thee—but alas! \n",
            " That thou wilt not inherit \n",
            "Its crown of power, or its throne,\n",
            "Therefore it will not inherit—\n",
            "Nor will it inherit this kingdom until it hath departed—\n",
            "But if it be given, it shall be given—\n",
            "And it shall be given—\n",
            "And it will be given—\n",
            "And it will be given—\n",
            "Which is the kingdom given to thee by the angels—\n",
            "Which is given to thee by the angels, and to the devil \n",
            "which thou dost pass by:—and shall be given to thee by the angels—\n",
            "Which is given by the angels—\n",
            "And in token of thy love!\n",
            "And shall be given to thee by the angels—\n",
            "Which is given by the angels—\n",
            " Which is given by them—\n",
            "Which they shall not pass by,\n",
            "Unless they pass in token.\n",
            "Therefore the kingdom given to thee by the angels shall be given—\n",
            "For the kingdom given to thee by the demons—\n",
            "For the kingdom given to thee by the demons is given—\n",
            " For the kingdom given to thee by the demons is given—\n",
            " And by the angels, and so far more than ever in the ages of our human memory—\n",
            "For the kingdom given to thy mother by the angels—\n",
            " And by the angels, and so far more than ever in the ages of ours human memory—\n",
            "For the kingdom given by the angels—and so far more than ever in the ages of ours human memory—\n",
            " for the kingdom given to thee by the angels has been given—\n",
            "For a kingdom given to thee by the angels—\n",
            "And therefore thy birth—whose birth is given—\n",
            "whose birth is given from above \n",
            " Which, when they pass down into the skies, it shall be given—\n",
            " Which they shall not pass through, unless they pass through\n",
            " Which, when they pass by, it shall be given—\n",
            "Which it shall be given in token of thy love\n",
            " Which shall be given in token of thy faith.—To the angels—who, fearing to let go \n",
            " Of these angels whose birth is given—\n",
            "whose birth was given, are given by angels which—\n",
            " That they pass on—\n",
            "That they pass through them, then, into the skies and skies,\n",
            " Of which thou dost pass by:—and thus, when thou art bound—\n",
            " (That thou dost pass by), I may bless thee, and may bring thy beauty to rest. But if so be that such may be,\n",
            " I may forbid thee from parting from this solemn solemn vow.\n",
            "Therefore the kingdom given to thee by the angels hath be given—\n",
            "And a kingdom given to thee by the angels hath been given—\n",
            "And I have been tempted, by the holy spirit, to forbid thee—\n",
            "And a kingdom given to thee by the angels, for their own use hath not been given—\n",
            "And thus I shall forbid thee—\n",
            "And a kingdom given to thee by the angels, to borrow their secrets and spells\n",
            "And to keep their secrets, if I may so deem thy love! (For thus it may be to thy spirit that these angels shall never pass \n",
            " By any route till they pass, until, when they pass through the skies, they pass by—\n",
            "That no route, till they pass by), shall I borrow from them any secrets or spell \n",
            " Of magic.\n",
            "The kingdom given to thee by the angels hath been given—\n",
            " That kingdom given unto thee by the angels hath been given—\n",
            "And that kingdom given to thee by the angels have been given—\n",
            "Which hath been given by them, but not yet, from above, \n",
            " And so far apart as it may pass—\n",
            "And thus hath not the world been given.\n",
            "No king hath known thee—no man hath seen thee—\n",
            "No spirit hath seen thee—\n",
            "No soul hath seen thy beauty. No human eye hath seen thee. Nothing hath seen your form. Nothing hath seen the flower in the garden of Eden—\n",
            "And the violet in the night. And yet nothing hath seen your beauty—\n",
            "And nothing hath seen thee from above, through the stars—\n",
            "For nothing hath given the soul—\n",
            " Nothing hath given her thee—\n",
            " Nothing hath given the angel, whom the angels have given,\n",
            "Nor hath given her thee— And no spirit hath given thy birth—\n",
            " Not even one that I may tell \n",
            " That\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    20  of     86. Loss: 0.544296145439148.   Elapsed: 0:00:26.\n",
            "0:  convertingThere is a kingdom in the desert and a kingdom in the wild—there is a kingdom in the garden and a kingdom in the forest\n",
            "\n",
            "There is a kingdom in the garden, and a kingdom in the forest—there is a king and a queen—there is a king and a queen, and a ruler,\n",
            " They are the only angels that know not thee, \n",
            "There is a kingdom in the garden and a kingdom in the forest—\n",
            "There is a kingdom in the garden and a kingdom in the forest—\n",
            "And a kingdom in the forest and a kingdom in the wilderness\n",
            "There is a kingdom in the garden and a kingdom in the forest—\n",
            "And a kingdom in the garden and a kingdom in the forest. \n",
            "There is a kingdom in the garden, and a kingdom in the forest—\n",
            "And a kingdom in the garden and a kingdom in the forest. \n",
            "There is a kingdom in the garden; and a kingdom in the forest—\n",
            "And a kingdom in the forest—\n",
            "And a kingdom in the forest. \n",
            "There is a kingdom in the garden—and a kingdom in the forest\n",
            "And a kingdom in the garden\n",
            "There is a kingdom in the garden and a kingdom in the forest\n",
            "But a kingdom in the garden and a kingdom in the forest\n",
            "There is a kingdom in the garden and a kingdom in the forest\n",
            " And a kingdom in the garden and a kingdom in the forest. \n",
            "There is a kingdom in the garden and a kingdom in the forest\n",
            "And a kingdom in the garden and a kingdom in the forest.\n",
            " There is a kingdom in the garden and a kingdom in the forest\n",
            "In that kingdom the valley and the forest\n",
            "The valley, from whence the mountains lie, \n",
            "The valley above the valley,\n",
            "The valley beneath the valley—\n",
            "The valley above the valley. \n",
            "There is a kingdom in the garden and a kingdom in the forest\n",
            "And a kingdom in the garden and a kingdom in the forest.\n",
            "There is a kingdom in the garden and a kingdom in the forest\n",
            "And a kingdom in the garden and a kingdom in the forest\n",
            "There is a kingdom in the garden and a kingdom in the forest;\n",
            "And a kingdom in the garden and a kingdom in the forest\n",
            "They are the angels that know not thee; \n",
            " They be the angels that know not thee: \n",
            " They be the angels that know not thee\n",
            " They be all things in heaven and in Earth\n",
            "(for they did not foretell) that the angels were angels\n",
            "And they were all the angels that know not thee: \n",
            " But they were all angels that know not thee: \n",
            " But they were all angels that think not thee; \n",
            " They were all that loved you with a love that gave you hope\n",
            " And they were all that loved you with a fervor that gave you hope\n",
            " And they died \n",
            "In life and death and in the resurrection, \n",
            "And in life and death and in the resurrection! \n",
            "They may well be known to you;\n",
            "They may well be known to the angels who live\n",
            "And they may well be known to the demons who dwell\n",
            "In their native land; \n",
            "And all of these \n",
            "Are here in the valley and in the valley above\n",
            "And they are here in the forest and in the valley above\n",
            "And they are here in the wilderness; \n",
            "And all of these \n",
            "Have gone away in a storm and are here in the valley; \n",
            "And all their power and all their strength \n",
            "Have gone away in a storm and have gone away in a wilderness. \n",
            "All of these are here in the valley and within\n",
            "In the valley above and within—\n",
            "And all of them have gone away in a storm and have gone away in a wilderness. \n",
            "All of them have gone away in a storm and have gone away in a wilderness. \n",
            "All of them have gone away in a storm and have gone away in a wilderness\n",
            "From the valley and the valley above, \n",
            "from the valley above and the valley above \n",
            "From the valley above and the valley above\n",
            "And from the valley above and the valley above \n",
            "From the valley above and the valley above;\n",
            "From the valley above and the valley above\n",
            "And from the valley above and the valley above \n",
            "\n",
            "From the valley above and the valley above and the valley above \n",
            "From all who go up above above the mountains, \n",
            "From the hilltop above and the cliff above\n",
            "And from the hilltop above and from the cliff above \n",
            "Are here: \n",
            "And all the stars are gone up above \n",
            "And all the stars are gone down \n",
            "And all the stars are gone down \n",
            "And all the stars are gone up \n",
            "With all their glory, their holiness, their beauty \n",
            "To us as if they were a crown-jewel \n",
            "To us as if they were a token of our gratitude \n",
            "And to us as if they were a token of ours \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.3770449161529541.   Elapsed: 0:00:45.\n",
            "0: alfAll alone,\n",
            " As the skies grew dim,\n",
            " In the morning-light, \n",
            " In the night-light—\n",
            "\n",
            " Night is the world \n",
            " Night is the world, \n",
            " All \n",
            " And all lies within the eye—\n",
            " All lies within the heart—\n",
            " No matter what \n",
            " Of human life \n",
            " The world trembles by the pall of \n",
            " All-encomp\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     86. Loss: 0.5839576125144958.   Elapsed: 0:01:04.\n",
            "0:  likingIt! o'er the sea,\n",
            " In some obscure spot,\n",
            " O'er the sea, \n",
            " For this moment I slept\n",
            " In a dream where I could no longer lie\n",
            " Up on the mountain-top.\n",
            " O'er my bed—and for this reason my soul\n",
            " Shavings by a wave\n",
            " And dreams of the night. \n",
            " Ah! I could not look\n",
            " While the shore\n",
            " Abracadabra, in dream-land,\n",
            " I drank alone, in dreams,\n",
            " From an island of serenity. \n",
            " Like the lute-strings of Solomon, \n",
            " Over all the shore,\n",
            " In thine own voice a voice I heard\n",
            " As the harps to \"Tame the Dead.\" \n",
            " Like the lute-string of Solomon, \n",
            " Over all the shore, in dream-land\n",
            " Amid the sky of starry night, \n",
            " Like the \n",
            "White-litten harp, \n",
            " O'er the sea, for this hour, \n",
            " On thine throne, in whose throne\n",
            " A crown is given \n",
            " The throne of Olympus,\n",
            " Thy soul, whose soul\n",
            " Is in spirit...\n",
            " O! my God! \n",
            " O! my God!\n",
            " Thy sacred shrine \n",
            " Is on my throne! \n",
            " Oh! for it is in spirit! \n",
            " Ah! for it is in spirit!\n",
            " The shrine on my throne\n",
            " Is on the throne of Olympus!\n",
            " And the shrine\n",
            " On my throne, \n",
            " Is on the throne of Hell, \n",
            " That my soul \n",
            " Is in spirit....\n",
            "\n",
            "Oh! for it is in spirit! \n",
            " Ah! for it is in spirit! \n",
            " The shrine on my throne \n",
            " Is in spirit!\n",
            " O! for it is in spirit! \n",
            " The shrine on my throne\n",
            " Is in spirit!\n",
            " Ah! for it is in spirit!\n",
            " The shrine on my throne—\n",
            " All right! o'er the sea, \n",
            " The star-tenths of the sky! \n",
            " That my soul \n",
            " Is in spirit!\n",
            " And it is on my throne—\n",
            " All right! o'er the sea—\n",
            " Over the gulfs of heaven! \n",
            " Over all the world \n",
            " With my spirit's song. \n",
            " Ah! the melody \n",
            " Of these worlds and these worlds, \n",
            " O God! that my soul \n",
            " Is in spirit!\n",
            " That my soul is in spirit! \n",
            " That my soul is in spirit! \n",
            "Ah! the music of these worlds \n",
            " Is in spirit!\n",
            " That my soul is in spirit!\n",
            " That my soul is in spirit!\n",
            " That my soul is in spirit!—Oh! \n",
            " That my soul is in spirit!—I may \n",
            " Not so safely \n",
            " Tell thee! \n",
            " Ah! there there lie \n",
            " That I have wandered.\n",
            " There lie \n",
            " That I have wandered,\n",
            " O God!\n",
            " Beyond the wilderness, \n",
            " Beyond the desert, \n",
            " Beyond the gulf, \n",
            " Beyond the mountain—\n",
            " Beyond the devil's lair. \n",
            " To all who seek \n",
            " My image, and my image \n",
            " For pride and pride and pride of spirit— \n",
            " My name, the King of angels, \n",
            " All is mine. 1838 Note Contents Note 1. This volume includes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    50  of     86. Loss: 0.21198056638240814.   Elapsed: 0:01:22.\n",
            "0:  affirmative\" (\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.2904564440250397.   Elapsed: 0:01:41.\n",
            "0:  containedThe golden eagle flying—the golden eagle hovering over her—\n",
            "The eagle flying—the bird hovering on her—\n",
            " As the golden eagle, soaring above her!\n",
            "And thus her flight was—\n",
            " The eagle soaring above her—\n",
            "She flew, soaring above her!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    70  of     86. Loss: 0.2768777310848236.   Elapsed: 0:02:00.\n",
            "0:  incentivesYou said the music grew heavy and ominous—\n",
            " In dreams to be fulfilled\n",
            " Of a lullaby in night—\n",
            " As though the music seemed to lull\n",
            " Like a lullaby into a dream\n",
            " And when the lullaby trembled like the night—\n",
            " And when the lullaby stirred like the dream,\n",
            " The music came down from the stars\n",
            " From dreams from Heaven—I tell you, my friends—\n",
            " That dream-cast in stone a star from afar\n",
            " Like the stars above, though their shadows\n",
            " Are no more than an hour apart—\n",
            " That sound that came from the far—\n",
            " And that spirit that stood by by and let\n",
            " This life—the sound that came from the distant\n",
            " Of the shadows around\n",
            " Bygone worlds and the stars that bore\n",
            " A vow, as they passed by,\n",
            " To my soul and those that lay—\n",
            " And then their shadows fell\n",
            " Like the shadows around\n",
            " The stars above the Earth—and there was—\n",
            " That one last tune that went—\n",
            " One that had gone, as if from a dream\n",
            " That should guide the hour.\n",
            " By—by—by—by—by—by—by—by—\n",
            " By—by—by—by—by—by—by, by—by, by—\n",
            " By—by—by—by—by, by—by, by—by, by, by, by, by, by\n",
            " By—by—by—by—by—by—by—by, by—by—\n",
            " By—by—by—by—by—by—by, by—by—by,\n",
            " By—by—by—by—by—by—by, by—by, by, by, by, by, by, by—\n",
            " By—by—by—by, by—by, by, by, By, by, by, by—\n",
            " by—by—by—by—by, by, by, by, by, by, by, By, by, by, by, by, by, by—\n",
            " By—by—by—by—by, by, by, by, by, by—\n",
            " By—by—by—by, by, by, by—\n",
            " By—by—by, by—by, by, by—\n",
            " By—by—by—by, by, by, by, by, by—\n",
            " Contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    80  of     86. Loss: 0.6080518364906311.   Elapsed: 0:02:18.\n",
            "0: OrWhen I hear that, to his friends who are sober and sober,\n",
            " So softly lullaby and quiet—\n",
            " And thus so softly lullaby, and so softly lullaby,\n",
            " When you see that a crowd,\n",
            " Which floats on the sea,\n",
            " Which turns and bends,\n",
            " With a sea of splendor,\n",
            " And bends and bends and bends,\n",
            " And bends, and bends and bends,\n",
            " As I pass on, as I pass,\n",
            " To a beautiful sunset,\n",
            " To a beautiful shore,\n",
            " To a lake where there is no shore!—\n",
            " To a sea where there is no shore!\n",
            "\n",
            "  Average training loss: 0.44\n",
            "  Training epoch took: 0:02:34\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.57\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 9 / 20 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    10  of     86. Loss: 0.7071723937988281.   Elapsed: 0:00:08.\n",
            "0:  inval\"!\"!\" \"I'd like to see you again;\"!\"\n",
            " The demon said to me, \"Never mind that!\"\n",
            " \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    20  of     86. Loss: 0.23302073776721954.   Elapsed: 0:00:27.\n",
            "0:  Ce\n",
            "To the moon to my head,\n",
            " And the stars and the Raven,\n",
            " As it was past.\n",
            " Which was to me an angel from heaven,\n",
            " And my bride—\n",
            " Was a mother—\n",
            " A mother,\n",
            " And my daughter—\n",
            " My boy—\n",
            " The happiest in the world.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.29661840200424194.   Elapsed: 0:00:46.\n",
            "0:  taxpayersFor a journey on this lonely mountain;\n",
            "I journey through my friends and myself! (It shall be said, in solemn opinion,\n",
            "That a journey in many regions,\n",
            "Farewell to me a worthy life—\n",
            "Such an agony, my dear Lenore Lenore!)\n",
            "A journey home in dreams—\n",
            "A journey that passes in dreams—\n",
            "With dreams—with dreams which I hope to awaken. (It shall be understood, in solemn opinion, that a journey there),\n",
            "On these strange odors, in dreams—with dreams—\n",
            "(Those dreams which I hope to awaken. )\n",
            "—I will seek to discover the truth within.\n",
            "In dreams which I think I can't,\n",
            "For the feeling of a deep loneliness, \n",
            "Is not deep enough, \n",
            " To awaken the cold that lies within my bosom \n",
            "By its very essence.—\n",
            "I have seen, and heard, but I cannot write of it.\n",
            "Upon the hills of Ulm,\n",
            "Upon the mountains of Ulm!\n",
            "Upon the streams of Neuschwanel—\n",
            "Of the Earth—and on the slopes \n",
            "That lie down there,\n",
            "To which lies a path,\n",
            "I have seen the soul of Lenore Lenore Lenore, \n",
            " In a dream and an agony!\n",
            "In a dream, to which is given the name Lenore Lenore—\n",
            " The soul of Lenore Lenore Lenore! \n",
            "(It is a gift from Heaven)\n",
            "For, as in dreams, the soul is, \n",
            "To arouse itself,\n",
            "To explore the mysteries \n",
            " That lie within its wing—\n",
            "A visitor whose spirit has,\n",
            "O'er my heart, \n",
            "Never dwelleth on that realm. \n",
            "And, lo! I know well, I know well\n",
            "That what lies within lies within me.\n",
            "Of those mysteries that lie within me\n",
            "\n",
            "—\n",
            "(Forbidden things that lie within me) \n",
            "That lie within me! \n",
            "And, lo! I know well—\n",
            " That what lies within is within me—\n",
            " That what lies within me is within me,\n",
            "And that which lies within me—\n",
            "Is the only thing that lies within me.—\n",
            "The only thing that lies within me! \n",
            " (It will be understood, in solemn opinion, that a journey home in dreams—\n",
            "Of a journey home in dreams, \n",
            "By dreams whose visions are but dim memories \n",
            "Of an angel or star;\n",
            "On those odors that lie within me! \n",
            "On those odors which lie within me!—\n",
            "On those odors whose memories are dim memories of a star!\n",
            "On those odors that lie within me!\n",
            "Upon those odors that lie within me! \n",
            "On those od\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     86. Loss: 0.5815439224243164.   Elapsed: 0:01:04.\n",
            "0: ructionNo: 132635\n",
            "\n",
            "No: 132736\n",
            "\n",
            "— All my loved minds are composed—\n",
            "— No more—No more—\n",
            " \"Never more\"— \n",
            " No more!\n",
            "\n",
            "Yet, from a time, far apart—\n",
            " And from within, I have heard— \n",
            " \"Nevermore.\" 1847 Note Contents p. 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    50  of     86. Loss: 0.3030163645744324.   Elapsed: 0:01:23.\n",
            "0:  playing!—\n",
            "A golden breath was shed,\n",
            "And a deep sleep was shed:\n",
            "A lone-eyed night was shed!\n",
            "A wandering eye \n",
            "Tells of the night!\n",
            "Yet my spirit hath gone;\n",
            "My spirit hath ceased—\n",
            "And I shall return,\n",
            "To the home of the dead—\n",
            "To the home of the dead—\n",
            "(Whose hearts shall seem—they shall lie!)\n",
            "I will return to the town where I dwell;\n",
            "And I will return,\n",
            "To the home where I dwell,\n",
            "To the home of the dead,\n",
            "To the home of the dead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.2456759214401245.   Elapsed: 0:01:42.\n",
            "0:  stainless. \"There is nothing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    70  of     86. Loss: 0.4053387939929962.   Elapsed: 0:02:01.\n",
            "0:  WelWhat doth not lie—and no more thine—\n",
            "And no more my soul is—\n",
            " Shall I leave—shall I no more lie\n",
            " \n",
            " By my heart, or my heart, and my eyes!—\n",
            " And no more I am—ah!—for this—this is not an object I could have known!\n",
            " It is only a vision of a dream.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    80  of     86. Loss: 0.13549970090389252.   Elapsed: 0:02:19.\n",
            "0:  cellWhat is thy mind? \n",
            " With a kind of beauty not too deep \n",
            " To be startled by its motion? \n",
            " Ah, to me the beauty of all! \n",
            " By reason of its strength, \n",
            " To shake my delicate delicate brain \n",
            " To\n",
            "\n",
            "  Average training loss: 0.43\n",
            "  Training epoch took: 0:02:35\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.58\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 10 / 20 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    10  of     86. Loss: 0.44695115089416504.   Elapsed: 0:00:08.\n",
            "0: úI will not return \n",
            " My love from afar, the Raven\n",
            " Asunder it passes through the Night, \n",
            " But at length it comes back from the Raven. \n",
            " It is the Raven—the Raven-Hazard!\n",
            " My dear Raven—her tears are on me; \n",
            " In the Raven, not the Raven, \n",
            " For there is no Raven!\n",
            " And yet here there is a Raven\n",
            " Which loves my heart and my hair,\n",
            " And in my Raven it does not weep,\n",
            " And in my Raven—the Raven!—\n",
            " The Raven that walks within \n",
            " A mortal eye—\n",
            " The Raven that walks beneath\n",
            " The Raven that walks only afar, \n",
            " Where in Heaven alone all mysteries \n",
            " Are found; where there lies no mystery\n",
            " No mystery upon the Raven!\n",
            " Where nothing lies hidden, \n",
            " Is the Raven's door open?\n",
            " Where my mother's door is flung \n",
            " Over the Raven's roof—\n",
            " Where my mother's door leads, \n",
            " Upon her foot!—(For the Raven's door, like a door \n",
            " To the Raven's door, leads; but—no more!)\n",
            " And thus the Raven—\n",
            " The Raven, the Raven-Hazard!\n",
            " The Raven whose spirit is deep—\n",
            " The Raven whose life is bound;\n",
            " Where life sinks and the Raven sinks, \n",
            " The Raven's life floats. (For the Raven's door\n",
            " is flung open—(For the Raven whose door I pass by—\n",
            " Where this door leads,\n",
            " To the Raven's door, I pass,)\n",
            " Where the Raven sinks and the Raven sinks,\n",
            " The Raven whose life \n",
            " Is bound—and the Raven whose life is bound!) 1839 Note Contents p. 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    20  of     86. Loss: 0.17887987196445465.   Elapsed: 0:00:26.\n",
            "0: ureau, and lilies are the happiest memories\n",
            "Of the year \n",
            " That is thus a lovely flower, \n",
            "And an ideal flower—\n",
            "The happiest hour, and the happiest hour \n",
            " That I have ever known—\n",
            "The happiest moment, and the happiest hour \n",
            " That I have ever known, \n",
            "The happiest moment of my life and my happiest hour \n",
            "And that I have ever known—\n",
            "The happiest hour that I have ever known \n",
            "By that name!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.7314406633377075.   Elapsed: 0:00:45.\n",
            "0:  ThomWe have come to take care \n",
            " The glory of the king.\n",
            " The glory of the King—\n",
            " And the pride of the monarchy—\n",
            " But all these things are the crime of their day—\n",
            " All this lies impenetrable—\n",
            " And its secrets \n",
            " Are hidden forever.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     86. Loss: 0.4671535789966583.   Elapsed: 0:01:04.\n",
            "0:  fittedFor the joy of thy grace—\n",
            " Whose hope! the glory!\n",
            " Where thy spirit! the light—\n",
            " Who dost dwell. \n",
            " Where the night-tide hangs! \n",
            " Where the skies are, and \n",
            " Which are the wintry, chilly seas.\n",
            " Whose sleep—howling, the wintry! \n",
            " Where the seas may stretch and shake and stretch—\n",
            " Where the skies swell and shake and shake—\n",
            " Where the skies thine fall!—\n",
            " Where all \n",
            " Are drowned in deep sleep!\n",
            " And all are flung into a sea of slumber, \n",
            " And all are in a dream—\n",
            " As the moon—\n",
            " As the dawn—\n",
            "\n",
            " As the dawn—\n",
            " As the sunset—\n",
            " As the dawn \n",
            " As the twilight—\n",
            " As the night-tide—\n",
            " As the dawn—and\n",
            " As the twilight—\n",
            " As the night-tide. \n",
            " Heaven! I say \n",
            " \"Sit still,\" my God! \n",
            " \"I see thee,\" my God!— \n",
            " \"Nevermore,\" my God!\n",
            " \"Nevermore\"—and there is no waking Hell! \n",
            "And then thou didst not know that! \n",
            " Hell, \n",
            " Hell, \n",
            " Night!—let it pass! \n",
            " Hell! —let a Raven pass! \n",
            " Hell! And thou didst not know that! \n",
            " Hell! And thou didst not know that! Hell! \n",
            " Hell! and thou didst not know that! \n",
            " Hell! and thou didst not know that! \n",
            " Hell! and thou didst not know that! \n",
            " Hell! and thy spells were not—\n",
            " Let them pass!—let them pass!\n",
            " Hell! I tell thee—the spell is not, \n",
            " But this spell—that is, \n",
            " Is, I tell thee, a spell of Fate.\n",
            " As, then, I tell thee, that spell passes—\n",
            " As the spell of Fate passes—\n",
            " By night-tide, by day, by night, \n",
            " As it passes— By night-time, by day, \n",
            " By night-time, by day— \n",
            " By day!\n",
            " Wherever it passes, \n",
            " And the night-time passes—by night, \n",
            " By the day-time passes—\n",
            " By the day-time passes—by night!\n",
            " Wherever it passes, it passes—\n",
            " By day-time passes—\n",
            " By night-time passes—\n",
            " By night! \n",
            " Hell! and the Raven, the Raven!—\n",
            " A Raven is gone;\n",
            " Wherever he is gone, \n",
            " Wherever he lies, in a dream-time—\n",
            " Wherever he dwells, in a dream-time, \n",
            " For a Raven sleeps—as a Raven sleeps—\n",
            " For a Raven sleeps!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    50  of     86. Loss: 0.591962456703186.   Elapsed: 0:01:23.\n",
            "0: irginOf Annabel Lee, whom that beautiful and melancholy maiden bore unto me in her childhood—the darling of Eden.\n",
            " My heart is burning with the love of God who has sent me up into Hell and into Hell!\n",
            " Ah! how happy have I been that my soul is, as the angels have called it thus—that I can have the power, but the spell, in a few dim dreams, to save my soul from Hell!—\n",
            " How happy I seem!—Ah, how happy! I feel well!\n",
            "I feel well, that I have been right all my life—that my soul is sure of me—\n",
            " That I can bear all my hopes and hopes, for once—but it was wrong that I should dwell—the wrong was wrong,\n",
            " But I know, that my soul is now at last free to seek my fate—\n",
            " A power, from above, that has enchanted me!—a power that has enchanted me;\n",
            " That the power of Fate has enchanted me!—\n",
            " It is no human power that wills. (Laudæus)\n",
            " It is no human power that can save you—it is the power of Fate!\n",
            " It is no human power that can save you—it is the power that has enchanted me!\n",
            " But it is it that has given birth to my name!\n",
            " The power, that will guide my spirit—\n",
            " The power—the gift, that will keep me still,\n",
            " From heaven! from Hell!—from Hell!—\n",
            " The power! \n",
            " The power—the power that holds my soul still—\n",
            " The power that would sever me forever! And I feel that the power that will guide my soul—\n",
            " Let no one speak so strangely in the presence of God!\n",
            " Let no one speak so strangely in the presence of God! (Thou art a demon!—and there is nothing wrong with such a demon,\n",
            " Like the demon who once subdued Lenore. \n",
            " But there is something wrong with thee, and there is something wrong with thy spirit, \n",
            " Like the demon who once conquered Len\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.9145269393920898.   Elapsed: 0:01:42.\n",
            "0: glas\" is the Raven that dances before the Raven and the Raven is the Raven that speaks\n",
            "\n",
            "Through him in the Raven's ear!\n",
            "For a moment his tears are the Raven—\n",
            "In the Raven that hangs about—\n",
            "In the Raven who beats her—\n",
            "In that Raven who hangs in the night\n",
            "And the Raven who knows only\n",
            "To hate—\n",
            "(with a heavy gurgling of my heart)\n",
            "Is the Raven who looks no more\n",
            "To the Raven—\n",
            "And to the Raven who speaks\n",
            "With a muffled and unbroken sigh!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    70  of     86. Loss: 0.3577785789966583.   Elapsed: 0:02:00.\n",
            "0:  mutationIn this world's most beautiful flowers, there's a life \n",
            " 'neath them all that's grand \n",
            " 'neath the sun \n",
            " That keeps on rolling about \n",
            " Till, in a way, \n",
            " It rolls around. \n",
            " I felt, with a sinking, \n",
            " That the sun was burning \n",
            " Around the world, but \n",
            " And the air was burning \n",
            " While the stars were burning,\n",
            " The trees on the forest floor\n",
            " Was rapping at my hair—\n",
            " And the leaves were burning, and \n",
            " Were throbbing, but \n",
            " The grass and the leaves were burning, \n",
            " And the grass and the leaves were burning\n",
            " To the soul in the heart\n",
            " To the soul in the sky.\n",
            " I\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    80  of     86. Loss: 0.20111386477947235.   Elapsed: 0:02:19.\n",
            "0:  successiveGranite\n",
            "\n",
            "I walked through this lake with a keen eye;\n",
            "I walked with a keen eye;\n",
            "My eye was drawn \n",
            "To the lake and forest;\n",
            "It was drawn in an instant!—\n",
            "It came out from nothing \n",
            "And, in the instant,\n",
            "It came out from the lake,\n",
            "And the trees \n",
            "And the grass were thrown \n",
            "In her—and I did not weep;\n",
            "I have not sorrow in these things—\n",
            "I love them dearly, \n",
            "And I confess that the things I love most \n",
            "May seem the least \n",
            "For \n",
            "My unholy hatred is the most universal \n",
            "Of all hate: \n",
            "And what I love more than good \n",
            "May seem the least\n",
            "For \n",
            "My unholy hatred is the most universal \n",
            "Of all hate:\n",
            "\n",
            "  Average training loss: 0.41\n",
            "  Training epoch took: 0:02:35\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.58\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 11 / 20 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    10  of     86. Loss: 0.343462198972702.   Elapsed: 0:00:08.\n",
            "0: KnThe bird that lulls\n",
            "\n",
            " In an ecstatic sleep.\n",
            " O, and in an ecstatic sleep,\n",
            " Are the bells bells that ring\n",
            " By night's end?\n",
            " The bells that ring—\n",
            " As a sound from a deep,\n",
            " Nightly, \n",
            " I implore—\n",
            " For all the bells that sound—\n",
            " The bells that ring\n",
            " I implore—\n",
            " For all the bells that ring—\n",
            " For all the bells that ring—\n",
            " And from afar they float\n",
            " Like the starry waters that call\n",
            " \"La Pl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    20  of     86. Loss: 0.2660728991031647.   Elapsed: 0:00:26.\n",
            "0: 017What's more, this—\n",
            "What's more—\n",
            "Is here a kingdom of Lenore,\n",
            " With all the kingdom \n",
            " Of Dunceland's Lenore, \n",
            "And all the kingdom of Milton! \n",
            "Whose dominion lieeth at Lenore! \n",
            "Whose dominion have I broken—\n",
            " What hath not that kingdom been? \n",
            "What hath not that state flown—\n",
            " What hath not that state flown?\n",
            "What hath not the state flown—\n",
            " How long—\n",
            " How long hath the state flown— \n",
            "What hath not the state flown? \n",
            "What hath not the state flown—\n",
            " Wherever that state has flown \n",
            "\n",
            "Wherever that state hath flown, \n",
            " Wherever that state hath flown, \n",
            " Wherever that state hath flown, \n",
            " Which state has flown—\n",
            " Wherever that state has flown,\n",
            " Wherever that state has flown\n",
            " Wherever that state has flown, \n",
            " That state hath flown—\n",
            " Wherever that state has flown—\n",
            " Wherever that state has flown, \n",
            "Wherever that state has flown, \n",
            " Wherever that state has flown, \n",
            " Wherever that state has flown, \n",
            " Which state hath flown \n",
            " Wherever that state hath flown, \n",
            " Wherever that state hath flown, \n",
            " Wherever that state hath flown \n",
            " Wherever that state hath flown, \n",
            " Wherever that state hath flown, \n",
            " Wherever that state hath flown, \n",
            " Wherever that state has flown, \n",
            " Wherever that state has flown, \n",
            " Wherever that state has flown, \n",
            " Wherever that state has flown, \n",
            " Wherever that state has flown, \n",
            " Wherever that state has flown, \n",
            " Wherever that state has flown, \n",
            " Wherever that state has flown, \n",
            " Wherever that state has flown, \n",
            " Wherever that state has flown, \n",
            " Wherever that state has flown, \n",
            " Wherever that state has flown, \n",
            " Wherever that state has flown, \n",
            " Wherever that state has flown, \n",
            " \n",
            " Wherever that state hath flown, \n",
            " Wherever that state hath flown, \n",
            " Wherever that state hath flown, \n",
            " Wherever that state hath flown, \n",
            " Wherever that state hath flown, \n",
            " Wherever that state hath flown, \n",
            " Wherever that state hath flown, \n",
            " Wherever that state hath flown, \n",
            " Wherever that state has flown, \n",
            " Wherever that state hath flown, \n",
            " Wherever that state hath flown, \n",
            " Wherever that state has flown, \n",
            " Wherever that state has flown, \n",
            " Wherever that state has flown, \n",
            " Wherever that state has flown, \n",
            " Wherever that state has flown, \n",
            " Wherever that state has flown, \n",
            " Wherever that state has flown, \n",
            " Wherever that state has flown, \n",
            " Wherever that state has flown, \n",
            " Wherever that state has flown, \n",
            " Wherever that state has flown, \n",
            " Wherever that state has flown, \n",
            " Wherever that state has flown, \n",
            " Wherever that state has flown, \n",
            " Wherever that state has flown, \n",
            " Wherever that state has flown, \n",
            " Wherever that state has flown, \n",
            " Wherever that state has flown, \n",
            " Wherever that state has flown, \n",
            " Wherever that state has flown, \n",
            " Wherever that state has flown, \n",
            " Wherever that state has flown, \n",
            " Note Contents p. 1 Notes p. 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.568632960319519.   Elapsed: 0:00:45.\n",
            "0:  elaborateNow in a dream, in the solitude of the night\n",
            "Of a dream that is past—\n",
            "And where the angels and demons may dwell\n",
            "And awake in thine own sleep—\n",
            "That no man but me may inherit\n",
            "The glory of Heaven, or be called\n",
            "To thy lowly station in Heaven.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     86. Loss: 0.1972671002149582.   Elapsed: 0:01:03.\n",
            "0:  SentinelWeet Contents p. 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    50  of     86. Loss: 0.30216705799102783.   Elapsed: 0:01:23.\n",
            "0:  accidental.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.5003842711448669.   Elapsed: 0:01:42.\n",
            "0:  ArmsSo—\n",
            " In my night-time\n",
            " Night-time\n",
            " Is broken—\n",
            " That time is of mine—\n",
            " That night-time I have brought\n",
            " A light into the eye;\n",
            " Now, bright is the beam—\n",
            " And then it smiles—\n",
            " It smiles—\n",
            " And now, smiling, I feel\n",
            " My spirit—\n",
            " I feel, like a lone star.\n",
            " Heaven's wide open—\n",
            " And wide, dim, dim. \n",
            " And my spirit sinks beneath it, \n",
            " To nothing save the light. \n",
            " But to everything that flows—\n",
            " In all I hope it will come,\n",
            " That it will be a mirror. \n",
            " To everything that bends,\n",
            " That it sinks below, \n",
            " That nothing more so\n",
            " Shall pass, save the light—\n",
            " And nothing more so shall pass\n",
            " Till it becomes clear—\n",
            " That every spirit of that past\n",
            " Is lost in that life—\n",
            " Till nothing more of it passes—\n",
            " Till nothing more of it dies. \n",
            " To nothing I owe\n",
            " In the old world,\n",
            " Is lost—\n",
            " To nothing my home,\n",
            " I owe nothing—\n",
            " Nor my youth;\n",
            " But I owe only—\n",
            " To Heaven—\n",
            " And the sun. 1835 Note Contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    70  of     86. Loss: 0.23000191152095795.   Elapsed: 0:02:01.\n",
            "0:  directedThe throne is a crown, \n",
            " Of the golden and pearl-jewelled throne:\n",
            " And, though the king has never left me, \n",
            " Hath never left me, \n",
            " And though he still hath loved me, \n",
            " And yet has not a tear left my brow, \n",
            " I think now, to be happy.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    80  of     86. Loss: 0.7465325593948364.   Elapsed: 0:02:19.\n",
            "0:  summon(!) Note(!) Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note! Note!\n",
            "\n",
            "  Average training loss: 0.40\n",
            "  Training epoch took: 0:02:35\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.58\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 12 / 20 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    10  of     86. Loss: 0.2863906919956207.   Elapsed: 0:00:08.\n",
            "0: severShe was not worthy\n",
            " To be loved, save\n",
            " Her name was 'Dovah, the Syrian Hell-fire\n",
            " As the angel of yore—\n",
            "\n",
            "In the midst of all the glory\n",
            "Of which was given \n",
            " And by the divine intervention of Her\n",
            " The life was devoted\n",
            "To such love, that for ever\n",
            "Its power and the beauty\n",
            "And evermore the mystery,\n",
            "With the ultimate object\n",
            " Was never—\n",
            "To have a part\n",
            "In the drama of the Passion \n",
            " To pass from the glory\n",
            "Of her life to the glory of her soul \n",
            " And then again\n",
            " In the moment of her death.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    20  of     86. Loss: 0.37861040234565735.   Elapsed: 0:00:26.\n",
            "0:  FootballGumdrops (mimes), and then that I did not take thy breath\n",
            " So soft I could not speak, \n",
            " From heart to foot, from heart to sea,\n",
            " Where angels, and other angels, and other saints, \n",
            " Tamed me with visions. And thence, when thy spirit shall come\n",
            " In sorrow at my affright—\n",
            " Shall the Heaven seem, from her own dimples,\n",
            " To me at her mercy? \n",
            " And thence from her own drowsiness I should deem\n",
            " My home—to it I would not return.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.648563027381897.   Elapsed: 0:00:45.\n",
            "0: earingThe flowers, o'er her golden hair, o'er her fair face—'\n",
            " \"'Tis the hour for me to look upon my first day as before:\n",
            " \" 'Tis the hour of duty, with all the fervor\n",
            " Of the duty \n",
            " With all the fervor of gratitude!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     86. Loss: 0.2658199071884155.   Elapsed: 0:01:04.\n",
            "0:  creatIn the midst of a storm—\n",
            "And from the shore \n",
            "In the midst of the morn and woveliness \n",
            "On the verge of ruin\n",
            "The most hated God hath made \n",
            "To be loved—with a hatred so deep—\n",
            " That every minute, when he loves \n",
            " His wife, has a moment \n",
            "Too late: he beats his tongue—and his voice \n",
            "Is deaf.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    50  of     86. Loss: 0.2295283079147339.   Elapsed: 0:01:23.\n",
            "0:  MechanThe grandeur o'er my soul\n",
            " By thy soothing dew—the beauty o'er me—\n",
            " The beauty \n",
            " In thy heart the same.\n",
            " Ah! my dear, my lovely soul! I feel\n",
            " With fever o'er thee, in thee—in thee;—in thee.\n",
            " Like thy dear sweet heart beats with out loud,\n",
            " A deep and passionate heart of hearts;\n",
            " It beats all this in a state of ecstasy,\n",
            " Which—unceasing in its fervor—\n",
            " Like thy dear heart beats with out loud. \n",
            " Quoth the Raven, \"No matter how fervently you sing,\n",
            " The lines don't seem\n",
            " To have been drawn from thy ear, but from yours.\" 1831 Note Contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.3545137941837311.   Elapsed: 0:01:41.\n",
            "0:  leaderGone was but a dream—\n",
            " For the dream is lasting—\n",
            " But now lies the Night. But then,\n",
            " Like visions of the dead in Heaven—\n",
            " So many I have never known \n",
            " The lone voice that has never flown \n",
            " My spirit down in the air \n",
            " Through my soul's soul!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    70  of     86. Loss: 0.21998882293701172.   Elapsed: 0:02:01.\n",
            "0:  steakThen \n",
            "The angels—whose pallor,\n",
            "Shall look on as they pass thee\n",
            "In their orbits afar,\n",
            "In fantasies of grandeur that are bound\n",
            "With thrones—they lie still—they lie low.\n",
            " They rest, their faces,\n",
            "Of th' eternal hope in the air;\n",
            "They are the angels whose love \n",
            "Deepls in their tears.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    80  of     86. Loss: 0.47717514634132385.   Elapsed: 0:02:19.\n",
            "0: igoFor those who know what it is I owe it unto thee, \n",
            " That, through a spirit of thine own,\n",
            " I may aspire,\n",
            "To a life that is unembodied \n",
            " Of beauty, joy, and light,\n",
            " A glory of thy glory:\n",
            " And on thy breast I feel, as thou didst, \n",
            " A crystalline garment of thy pride:\n",
            " And upon thy lute I find, by dint of ear,\n",
            " A crown of power, of renown,\n",
            " And on thy lute I feel, by oint, \n",
            " A crown of power, of renown.\n",
            "\n",
            "  Average training loss: 0.39\n",
            "  Training epoch took: 0:02:35\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.59\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 13 / 20 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    10  of     86. Loss: 0.1793462336063385.   Elapsed: 0:00:08.\n",
            "0:  reluctBy Soul to me, \n",
            " The skies were not broken by night\n",
            " And the stars \n",
            " Perched on the precipice.\n",
            " Quivering, and serene, \n",
            " The winds were driven up from the Heaven\n",
            " By their will, and from my command\n",
            " To guide the skies.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    20  of     86. Loss: 0.29724013805389404.   Elapsed: 0:00:26.\n",
            "0:  embroYou say: \"This is not an argument to my favour, and yet a fiction by the very heart of my soul,\"\n",
            " In the wilderness on the Annabel Lee St. John's St. John's, 1847 By a bold and radiant blush \n",
            " Which has never been seen before. \n",
            " The Raven in the mountain tops and hills,\n",
            " Who, wandering alone, lies adrift in a lake,\n",
            " The Raven's eye may be seen, \n",
            " Where lies the Raven, whom there hopes to be;\n",
            " But, dreaming of a future,\n",
            " She will lead me away from the danger.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.4800594449043274.   Elapsed: 0:00:45.\n",
            "0:  months\"The Lion\n",
            " On the Plutonian hill,\n",
            " And he—a bird—was given my name—\n",
            " By birth I was a maiden and maiden,\n",
            " But now, from childhood, I have flown away;\n",
            " As the summer sun is setting,\n",
            " Where I lie and fall, while my spirit-life—\n",
            " That spirit-life, I vow, I will—\n",
            " In return, for a day—for a night—for a month—\n",
            " But then, the sky turns to nothing and nothing springs\n",
            " And turns back to Earth,—\n",
            "And there lies the Lion;\n",
            " And he falls, and the stars dim and the night\n",
            " Perfume his name;\n",
            " And the sun beats down, and the moon sinks again—\n",
            " And his spirit falls, and the Earth turns back to her eternal home;\n",
            " And he lies, and the stars dim and the night\n",
            " Perfume his name—\n",
            " And the moon sinks again and the stars sink again—\n",
            " And he lies, and the stars dim and the moon sinks again—\n",
            " The Lion—whose name comes from the Persian name \n",
            " On my back, whose name is Lenore\n",
            " (or Lenore,) and whose very name is Lothar. 1849 Note Contents p. 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     86. Loss: 0.3842332065105438.   Elapsed: 0:01:04.\n",
            "0:  SrA, that is, to know no evil of the most terrible evil—to have been tempted by it—to love it, \n",
            " But it did not know at that time, by any name, \n",
            " That I should cherish in it all the joy \n",
            " And happiness of the good by the worst, \n",
            " The proud hope of the lowly lowly.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    50  of     86. Loss: 0.18250197172164917.   Elapsed: 0:01:22.\n",
            "0:  ChargersIn parting, my lord thy eternal name, \n",
            " And the skies above!\n",
            " But for the roses, \n",
            " The flowers, the flowers, \n",
            " For the stars, the leaves \n",
            " Come down in the summer sky—\n",
            " And my dear, dear, what can I say?\n",
            " And the lilies, that inherit,\n",
            " Are the flowers that the sun—\n",
            " (Poems, poems, hymns!)\n",
            " Are the flowers that the grass—\n",
            " Are the flowers that the trees—\n",
            " Is the grape vine that hearkens to\n",
            " The groan of the dead?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.9284968972206116.   Elapsed: 0:01:41.\n",
            "0: EC(!A)\n",
            "\n",
            "Lo! a spirit is moving into my chamber!\n",
            " Where lies the spirit! \n",
            " Like a spirit whose flight is bound \n",
            " To drowsy, and whose death thro'\n",
            " I feel, \n",
            " I hear, and feel, in the Silence,\n",
            " In an hour, in an hour\n",
            " Of terror, as they pass by! 1849 Note Contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    70  of     86. Loss: 0.3324025273323059.   Elapsed: 0:02:00.\n",
            "0:  GotVast and lovely:\n",
            " \"My mind is open:\n",
            " What is it that lies concealed?—which leads?—how to employ!—by the charms and the ev'n!\n",
            " How could I save my soul from sinking?—how could I save all my happiness from sinking?—How could I save all my love from sinking?—how could I save all my soul from sinking?\"—\n",
            " A melancholy voice arose from behind me,\n",
            " That called out: \"Ah, young love! thy soul that lies concealed! thy soul that lies above!\" 1838 Note Contents p. 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    80  of     86. Loss: 0.21571819484233856.   Elapsed: 0:02:19.\n",
            "0:  BuckThen she drew near her wand, and cast it o'er her eye,\n",
            " When a pinioned maiden appeared, and cast it o'er her breast, \n",
            " With one rapid eye, and a desperate eye,\n",
            " For a moment, on the spot, \n",
            " From an ancient lake—which looked far and free\n",
            " In myriad and beautiful forms, \n",
            " Quenches every part of an old or young bride.—Ah! how the Night of Judas!\n",
            " The Night of Judas!\n",
            " With a dream-like semblance of Lenore! \n",
            " (O, Lenore! that dim lake, whence Judas hath drawn o'er!!)\n",
            " O, Lenore! that sweet and lasting fountain of Hope! \n",
            " O, Lenore! to the skies which lie low\n",
            " In the sea-hills of Fate—what wreathed dross the skies!\n",
            " And how the Heaven's angels shall guide\n",
            " Through the dell, who will guide\n",
            " Amid the ealls and the turrets —\n",
            " With their long, lancing, o'er minds,—\n",
            " They are their harbingers; and yet, \n",
            " Wherever may be seen, \n",
            " The lone eagle on the wing;\n",
            " For that lone eagle is no more \n",
            " Than, in the dim, shadowy garden of Victory!\n",
            " With the startled bird who, on sight, \n",
            " Lolls down in search of a lone eagle,\n",
            " And, sinking swiftly to the naphthalm,\n",
            " In search of a lone Eagerie \n",
            " (No more—no more!)\n",
            " With the startled eagle—no more, \n",
            " With the startled eagle— no more!\n",
            " For the lone eagle, on sight,\n",
            " Hath not found \n",
            " Aught \n",
            " But a shadow of the Victory!\n",
            "\n",
            "  Average training loss: 0.38\n",
            "  Training epoch took: 0:02:34\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.59\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 14 / 20 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    10  of     86. Loss: 0.2911502718925476.   Elapsed: 0:00:08.\n",
            "0: roud\" \"Goldenrod!\" I said, \"Come—let us look!\"\n",
            " As he stepped on his white tresses, \"Neath,\" I flung out my lute, \"but where is the harp? \n",
            " For it lies \n",
            " Where we see no harp! \n",
            " Not in heaven—in Heaven! \n",
            " No Heaven—in Heaven! And yet, there \n",
            " For ever and nothing more \n",
            " Evermore.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    20  of     86. Loss: 0.5473054051399231.   Elapsed: 0:00:26.\n",
            "0: 003Hear the cry of the Lion! \n",
            "How often we dream of it,\n",
            "With the sound of the bells and bells,\n",
            "And the tinkling of the bells and bells,\n",
            "Weep—weep with all the fever of battle, \n",
            "As though we might awake the sleeping soul. 1835 Contents p. 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.6010628342628479.   Elapsed: 0:00:45.\n",
            "0: moilAnd yet that darkness within me—\n",
            "That fire within me may seem stronger!\n",
            "I cried: I cried \"Mother!\" \n",
            " \"Mother!!\"\n",
            " \"Mother!\" I sobbed. \n",
            "I mourn and weep and mourn \n",
            " For my soul and my spirit are at peace.\n",
            "Yet, the battle of the Syrian \n",
            " Stream is over! I mourn and weep and feel no pain, \n",
            " (But this time I am at thy side), \n",
            " And so join a fervor of love that \n",
            " Is sure to awaken me!\n",
            "For that sweet and lasting Night \n",
            " For all my life that is devoted \n",
            " To the Christian Hope!\n",
            "Yet I know, though with many a dread\n",
            " Of thy fervor and the fervor, \n",
            " That thy sweet memories are weak. \n",
            "Thy death throes, \n",
            " In the throes of fever!\n",
            "My spirit-long mourns, \n",
            " And so, amid all the \n",
            " Broken Night, \n",
            " And the Broken Light, \n",
            " That nothing so dear may so happily dwell \n",
            " In my heart as thy love—\n",
            "And so the tears that roll \n",
            " In my hair are thine—\n",
            " That in all my life, if a mortal \n",
            " Fell in love \n",
            " With me and I bore her,—\n",
            "Had I not died so young, \n",
            "And died so young again at the solemn vow! \n",
            " In truth, there \n",
            " Is not a life on earth that \n",
            " To cherish and cherish \n",
            " That is so dear and so sacred—\n",
            "It hangs \n",
            " Around me like an eternal burden. \n",
            " It throbs to a deep, serene, \n",
            " Deepest rest \n",
            " And trembles until it topples over\n",
            " In the mystic entablatures of heaven—\n",
            " The agony of that last Night \n",
            " Is a theme for all my heart! \n",
            "But, alas! alas! \n",
            " For that time, I have dwelt\n",
            " In a dream of a world \n",
            " Apart from this terrible Earth—\n",
            " In that dream I have striven to see \n",
            " And hope that, in return, \n",
            " It might be given me some measure \n",
            " To please: but for the present hour \n",
            " It is merely a temporary measure—\n",
            " A lasting measure—\n",
            " And an idle dream:\n",
            " In fact, such is the state of my mind!\n",
            "Yet, alas! \n",
            " That day—that day—in the future, \n",
            " That hour, in which my memory—\n",
            " Hath flown, \n",
            " Around me a dream of a world more profound \n",
            " Of beauty and of men—\n",
            " Than of any previous moment of my childhood and all \n",
            " Which can ever hope to save or explore. \n",
            " Yet, alas!\n",
            " That same night—that night, in many a dream—\n",
            " And this, too, hath flown—\n",
            " Beyond me some far-off kingdom \n",
            " And all that hath flown! \n",
            "Yet this, too, hath flown—\n",
            " Beyond the stars, some far off shore \n",
            " That now restlessly lie in the midst\n",
            "\n",
            " In motionless, dark-clouded regions.\n",
            "Yet this, too, hath flown—\n",
            " Above the heavens\n",
            " Some far flung frieze, \n",
            " Some far flung tombstone\n",
            " And none of them is more desolate or more \n",
            " Than the dim, dim-remembered scenes, \n",
            " Of the lonesome, silent world \n",
            " Of the restless planets—\n",
            " Nor the wild, wandering stars \n",
            " That lie within the dim, dim-remembered spheres.\n",
            "Yet, alas! \n",
            " That dream that once had \n",
            " A lasting and universal theme \n",
            " Which floats in the distant skies\n",
            " Like a pallid pall upon the moon \n",
            " That once dwelt, amid the stars\n",
            " As though there were some other—\n",
            " A dream that once dwelt within \n",
            " A vast, shadowy gulf \n",
            " Of the unknown.\n",
            "Yet, alas! I have dw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     86. Loss: 0.30995604395866394.   Elapsed: 0:01:03.\n",
            "0:  farmingIt fell so lowly \n",
            " That no one dared \n",
            " To\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    50  of     86. Loss: 1.6414519548416138.   Elapsed: 0:01:22.\n",
            "0:  purchIn These gardens, and the dales, \n",
            " Of witchery and of thine, \n",
            " Wherein lies the moor \n",
            " Of witchery and of thine, \n",
            " That wan'er thee to pass.\n",
            " Whereas thy birth-day—\n",
            " The dawn of thy life—\n",
            " Thy breath is upon the roses \n",
            " Wherever thou mayst be—\n",
            " Thy home lies—and the roses are gone \n",
            " With the wind and the sky,\n",
            " With the chill and the dust.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.36019593477249146.   Elapsed: 0:01:41.\n",
            "0:  establish, a world of redemptive light\n",
            " Which lies above that of the sunset.\n",
            " 'Twere the wisest of men—\n",
            " 'Twas the most radiant and serene\n",
            " Of the stars, and thine own will is bound—\n",
            " The star-haunted hope of the dream!—\n",
            " The terror of the night, the thirst for life,\n",
            " The pallid hope of the night!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    70  of     86. Loss: 0.2282417118549347.   Elapsed: 0:01:59.\n",
            "0:  FamilyThe grandeur of his birth still wafting—\n",
            " A shadow of a shadow that hangs above the moon—\n",
            " All these and nothing more—\n",
            " All this on an unseen spot—\n",
            " All this and nothing more—\n",
            " And\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    80  of     86. Loss: 0.43014395236968994.   Elapsed: 0:02:18.\n",
            "0:  femaleThe reason why man hath been made to dwell in this Earth, \n",
            " Was the duty of man an argument with God—\n",
            " Was the divine law with us: the Earth in which we dwelt—\n",
            " And the ruler of ours, in whose name we ran—\n",
            " The ruler of our strength is now.\n",
            "\n",
            "  Average training loss: 0.37\n",
            "  Training epoch took: 0:02:34\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.59\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 15 / 20 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    10  of     86. Loss: 0.31773537397384644.   Elapsed: 0:00:08.\n",
            "0:  electromGem, and giddy melody from afar.\n",
            " She hath brought no danger unto thy throne,\n",
            " Though thy word be broken \n",
            " Thy throne high above thee,\n",
            " To her eyes no crime shall be, \n",
            " By the power of thy word\n",
            " To slander thy name; \n",
            " To usur\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    20  of     86. Loss: 0.455997496843338.   Elapsed: 0:00:26.\n",
            "0:  relyingMy soul-soul-soul! Is it not the thought of thy youth that is most deeply sorrowful to me?\n",
            " (What sorrow shall there be?—how thy life shall be better then thy beauty?)\n",
            " That I should not live again?\n",
            " Shall I not awaken to the grief which my heart must feel in thee \n",
            " When my spirit is growing weary?\n",
            " Shall it not return in an instant to its sepulchre?\n",
            " When my soul's restlessness is upon me —\n",
            " When my spirit is more deeply felt—\n",
            " When the happiest is my happiest \n",
            " And the worst the worst the worst, \n",
            " Whose worst is the worst \n",
            " Is this, my heart tells me, the happiest is the happiest and\n",
            " (O, my heart tells me), the happiest, happiest\n",
            " Is this, my heart tells me, the happiest of those days\n",
            " That have been—\n",
            " The happiest! What hast thou wrought?\n",
            " With what good and unholy hope?\n",
            " But in thee is the happiest I have known\n",
            " Who knew more then then how to crush \n",
            " Thy thoughts.\n",
            " No wonder then, that so sweet a memory \n",
            " Is still lingering:\n",
            " Nor that so bright a spring has gone \n",
            " In thee a ray that o'er thy eyelids will see \n",
            " With light—oh, how well!\n",
            " All around me the light, as if it were seen—\n",
            " That sunshine thro' my eyes\n",
            " And a sort of mist that is hovering over thee,\n",
            " A demon within my breast—a spirit within thy heart—\n",
            " A maiden that tells no fear—\n",
            " A maiden that tells no fear—\n",
            " And a maiden who tells no fear—\n",
            " And the maiden, for whose charms and mysteries\n",
            " Are a mystery to the Eldorado,\n",
            " Is the happiest woman—and the happiest girl—\n",
            " O, I pray, thou wisest that thy life be happiest.\n",
            " Ah, that mystery which hangs in thine eye—\n",
            " A mystery so young that it hath no end—\n",
            " What shall thy life be? What shall thy sorrow be \n",
            " Upon thy spirit—which hath died to me?\n",
            " Where hath thy heart gone? Where no soul has gone \n",
            " Though I have sought thee—\n",
            " Where no soul hath been loved? The angels, whose presence I never foresaw \n",
            " The mortal life to be—\n",
            " Who can discover it?\n",
            " How canst thou be that I have known the happiest life—\n",
            " In heaven, on thine path \n",
            " Of love! on thine path alone—\n",
            " Where no man can discover my presence;\n",
            " Who couldst discover me?—whose presence would bring \n",
            " My soul home safely, to me?\n",
            " Where no man can find my soul:\n",
            " And so, in heaven, no man may seem \n",
            " A mortal to me.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.3068348467350006.   Elapsed: 0:00:45.\n",
            "0:  BuIf the lord be happy and be kind to us \n",
            " The happy and the lovely, and all the happiest and all the happiest \n",
            " Of all things, \n",
            " We might laugh at her proud face,\n",
            " The sad sad faces of our youth—\n",
            " And smile in the radiant sunshine.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     86. Loss: 0.2411709576845169.   Elapsed: 0:01:03.\n",
            "0:  FulO! with what power of wit thou hast \n",
            " Of all my senses that the air hath \n",
            " With a quickening motion around my wing,\n",
            " Of my brain and my spirit in a state of disquiet \n",
            " And even that motion which we call passion \n",
            " All—\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    50  of     86. Loss: 0.8988806009292603.   Elapsed: 0:01:22.\n",
            "0:  SpiderThere is a radiant gleaming in the valley \n",
            " From the very spot where the sun-ray\n",
            " Of a dead woman hath fallen.—\n",
            " The soul that breathes here is dead.—\n",
            " The eye that looks at me is dead.—\n",
            " And the spirit that looks at me is dead: for here \n",
            " Is my visitor's cottage \n",
            " And my visitor's grave \n",
            " On the\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.33781227469444275.   Elapsed: 0:01:41.\n",
            "0:  Creek' midnight! (Whose heart it is, or the worst of dreams!)\n",
            " I lie dreaming of a bright garden and a lovely woodland \n",
            " Of stars all well-blasted from out—\n",
            "A giddy dream about the sky.\n",
            " Strange light, dim and sober,\n",
            " As the night-wind blows, from out, \n",
            " Leaving behind it a pallid mist—\n",
            " The moon and star-light and night-time \n",
            " In all its nameless splendor.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    70  of     86. Loss: 0.34431707859039307.   Elapsed: 0:02:03.\n",
            "0:  enthusAt the bidding of god! thou art my most humble object—\n",
            " Let it be for thy sake that this night be \n",
            " A dream unto thee—\n",
            " (Loses its meaning immediately!)\n",
            "For, in thy youth and grief, I had seen,\n",
            " A star to star—\n",
            " A colossal star to star;—\n",
            " A star from out of the cold—\n",
            "I trembled, and trembled, and trembled, \n",
            " As if by some power of my own,\n",
            " I had seen thee from out the cold.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    80  of     86. Loss: 0.36034703254699707.   Elapsed: 0:02:22.\n",
            "0: ن\"Blessed are the names of those who hast thou gaily offered me?\" \n",
            " They were names of those who by thine own will alone hast lent thee hope \n",
            " The hopes of the lost;\n",
            " And all praise be to God.\n",
            "They were names—\n",
            "Of those who would never perish. \n",
            "But were they now dead?—\n",
            "They died on the cross. \n",
            "For to them this town of yore—\n",
            "They pass, with boundless gratitude,\n",
            "For evermore dear names to thee:\n",
            "And all gratitude will be given. \n",
            "And all reverence shall be given. \n",
            "They passed by, as they passed by,\n",
            "With unceasing gratitude,\n",
            "To those who were first seen\n",
            "With hopes of immortality—\n",
            "To those who would not inherit\n",
            "The radiant memories enshrined\n",
            "By thine own will—\n",
            "To those whose tears were more lasting\n",
            "Than that of a dying saint. \n",
            "And yet, in thy heart, I feel, \n",
            "Ah, the love that springs from the dew \n",
            " Of that saintly breast that hath been yours forever, \n",
            "And with that soul of yours is mine forevermore. \n",
            "That holy old God! thou art so worthy \n",
            "That nevermore, evermore\n",
            "With love I should deem thee worthy of pilgrimage—\n",
            "To thy love at last. \n",
            "Yet, thou art so very bold,\n",
            "And that love on thy lips is a token\n",
            "Of the eternal truth \n",
            " That every tongue tells is right \n",
            " And every word from its source is wrong \n",
            " In this world a mockery\n",
            "Of the faith that is in thee. \n",
            " Thou art not so, but not so—\n",
            "For as the angels and man—\n",
            "Who wax and wane by night, \n",
            "With the power of God,\n",
            "Keeping watch over the morrow, \n",
            "Keeping watch over the morrow, \n",
            "Keeping watch over the morrow; \n",
            "Keeping watch over the pathway that leads to Heaven.\n",
            "Keeping watch over the pathway that leads to Heaven. \n",
            "Keeping watch over the path that leads to Hell, \n",
            "Keeping watch over the path that leads to Heaven; \n",
            "Keeping watch over the pathway that leads to Hell, \n",
            "Keeping watch over the pathway that leads to Heaven. 1839 Contents p. 3\n",
            "\n",
            "  Average training loss: 0.37\n",
            "  Training epoch took: 0:02:37\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.60\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 16 / 20 ========\n",
            "Training...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 👨‍🚀 Summary of the training process"
      ],
      "metadata": {
        "id": "EKkI6RKJyWnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "metadata": {
        "id": "KRupsj2jyWeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "63-wmk0x0r16",
        "outputId": "ece30ab8-0ba7-427e-d0fa-5a3f3896287e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Training Loss  Valid. Loss Training Time Validation Time\n",
              "epoch                                                          \n",
              "1              10.20         7.58       0:00:56         0:00:05\n",
              "2               4.97         3.06       0:00:58         0:00:05\n",
              "3               2.24         3.12       0:00:59         0:00:05\n",
              "4               1.71         2.27       0:01:00         0:00:05\n",
              "5               1.28         0.89       0:01:01         0:00:05\n",
              "6               0.99         0.99       0:01:01         0:00:05\n",
              "7               0.90         0.83       0:01:01         0:00:05\n",
              "8               0.85         0.82       0:01:01         0:00:05"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a7523093-4b8d-47b1-a370-3e2ce5fe7942\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10.20</td>\n",
              "      <td>7.58</td>\n",
              "      <td>0:00:56</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.97</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0:00:58</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.24</td>\n",
              "      <td>3.12</td>\n",
              "      <td>0:00:59</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.71</td>\n",
              "      <td>2.27</td>\n",
              "      <td>0:01:00</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.28</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0:01:01</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.99</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0:01:01</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.90</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0:01:01</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.85</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0:01:01</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a7523093-4b8d-47b1-a370-3e2ce5fe7942')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a7523093-4b8d-47b1-a370-3e2ce5fe7942 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a7523093-4b8d-47b1-a370-3e2ce5fe7942');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 👨‍🚀 Performance Summary"
      ],
      "metadata": {
        "id": "VGqxIrB50D2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "9Zs42UKH0GX2",
        "outputId": "4c4faa94-2b79-4feb-bf1a-65ff0fae5c4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4, 5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7_MfmInrSeNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##🌌 Model Info"
      ],
      "metadata": {
        "id": "bMzwiVH5yl4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(poem_model.named_parameters())\n",
        "\n",
        "print('The GPT-2 model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:2]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[2:14]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-2:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "metadata": {
        "id": "WDpr7xdD0dpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Saving & Loading Fine-Tuned Model\n"
      ],
      "metadata": {
        "id": "KMaFNHYw0Jkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = home_directory +'/model_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = poem_model.module if hasattr(poem_model, 'module') else poem_model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ],
      "metadata": {
        "id": "2qxncMRnyvae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "home_directory+'/model_save/'"
      ],
      "metadata": {
        "id": "OYg_S0691HjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l --block-size=K /content/drive/MyDrive/proyecto_NLP/models/model_save/"
      ],
      "metadata": {
        "id": "EsObwP6r07Ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l --block-size=M /content/drive/MyDrive/proyecto_NLP/models/model_save/pytorch_model.bin"
      ],
      "metadata": {
        "id": "OFtW-6ka1BUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy the model files to a directory in your Google Drive.\n",
        "#!cp -r /content/drive/MyDrive/proyecto_NLP/models/model_save/  $data_dir\n",
        "\n",
        "# # Load a trained model and vocabulary that you have fine-tuned\n",
        "#model = GPT2LMHeadModel.from_pretrained(output_dir)\n",
        "#tokenizer = GPT2Tokenizer.from_pretrained(output_dir)\n",
        "#model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAb9n45p1Wk0",
        "outputId": "9e10e8ed-b917-40c8-9764-b15a343f0fec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: missing destination file operand after '/content/drive/MyDrive/proyecto_NLP/models/model_save/'\n",
            "Try 'cp --help' for more information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Poems Generation"
      ],
      "metadata": {
        "id": "NoydP2C61uXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "poem_model.eval()\n",
        "\n",
        "prompt = 'love is ridiculous'\n",
        "\n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)\n",
        "\n",
        "sample_outputs = poem_model.generate(\n",
        "                                generated, \n",
        "                                do_sample=True,   \n",
        "                                top_k=50, \n",
        "                                max_length = MAX_LEN,\n",
        "                                top_p=0.95, \n",
        "                                num_return_sequences=3,\n",
        "                                num_beams=5, no_repeat_ngram_size=2, early_stopping=True\n",
        "                                )\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
      ],
      "metadata": {
        "id": "Fz81cMW91gn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lTNBBc1I14nV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}