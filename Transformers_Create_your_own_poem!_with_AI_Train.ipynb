{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformers: Create your own poem! with AI_Train.ipynb",
      "provenance": [],
      "mount_file_id": "1xWtxFtplWzx7f6ZTEWcjLshe7KXwmPA8",
      "authorship_tag": "ABX9TyOcHizIeSrj3151MJlY7S+c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ancastillar/Transformers-Create-your-own-poem-/blob/main/Transformers_Create_your_own_poem!_with_AI_Train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import libraries"
      ],
      "metadata": {
        "id": "4B9XFhexfkY5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Abywl7XSNs8",
        "outputId": "05741257-af2b-451f-814e-cea92a438b8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: aitextgen in /usr/local/lib/python3.7/dist-packages (0.5.2)\n",
            "Requirement already satisfied: transformers>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from aitextgen) (4.20.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from aitextgen) (1.11.0+cu113)\n",
            "Requirement already satisfied: pytorch-lightning>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from aitextgen) (1.6.4)\n",
            "Requirement already satisfied: fire>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from aitextgen) (0.4.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire>=0.3.0->aitextgen) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from fire>=0.3.0->aitextgen) (1.15.0)\n",
            "Requirement already satisfied: torchmetrics>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (0.9.2)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (4.1.1)\n",
            "Requirement already satisfied: protobuf<=3.20.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (3.17.3)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (2.8.0)\n",
            "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (2022.5.0)\n",
            "Requirement already satisfied: pyDeprecate>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (0.3.2)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (6.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (4.64.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (3.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning>=1.3.1->aitextgen) (3.0.9)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.6.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.37.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.4.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (57.4.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.46.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (3.3.7)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (3.2.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.5.1->aitextgen) (0.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.5.1->aitextgen) (3.7.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.5.1->aitextgen) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.5.1->aitextgen) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (2.0.12)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (1.3.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (21.4.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (6.0.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (0.13.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (1.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (1.7.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.7/dist-packages (0.0.25)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (0.12.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: Jinja2>=2.4 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n",
            "Requirement already satisfied: click>=2.0 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous>=0.21 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug>=0.7 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.4->Flask>=0.8->flask-ngrok) (2.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: flask==0.12.2 in /usr/local/lib/python3.7/dist-packages (0.12.2)\n",
            "Requirement already satisfied: itsdangerous>=0.21 in /usr/local/lib/python3.7/dist-packages (from flask==0.12.2) (1.1.0)\n",
            "Requirement already satisfied: Jinja2>=2.4 in /usr/local/lib/python3.7/dist-packages (from flask==0.12.2) (2.11.3)\n",
            "Requirement already satisfied: Werkzeug>=0.7 in /usr/local/lib/python3.7/dist-packages (from flask==0.12.2) (1.0.1)\n",
            "Requirement already satisfied: click>=2.0 in /usr/local/lib/python3.7/dist-packages (from flask==0.12.2) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.4->flask==0.12.2) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install aitextgen\n",
        "!pip install flask-ngrok\n",
        "!pip install flask==0.12.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "#Visualizations\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "sns.set(rc = {'figure.figsize':(35,10)})\n",
        "sns.set_palette(\"Paired\")\n",
        "sns.set_style(\"white\")\n",
        "from flask import Flask, request, render_template\n",
        "from flask_ngrok import run_with_ngrok\n",
        "\n",
        "##########Models\n",
        "from aitextgen import aitextgen\n",
        "import torch\n",
        "import sys\n",
        "import os\n",
        "import random\n",
        "import time \n",
        "import datetime\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    current_device = torch.cuda.current_device()\n",
        "    print(\"Available GPUs: \", torch.cuda.get_device_name(current_device))\n",
        "    print()\n",
        "\n",
        "!nvidia-smi\n",
        "\n",
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, GPT2Config, AdamW, get_linear_schedule_with_warmup, GPT2TokenizerFast\n",
        "from torch.utils.data import Dataset, random_split, DataLoader, RandomSampler, SequentialSampler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAInlBf8TN3_",
        "outputId": "2d6c940c-6d25-4995-9d1e-11773d91fd0c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available GPUs:  Tesla T4\n",
            "\n",
            "Sun Jul  3 17:34:04 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   73C    P0    33W /  70W |  10626MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Data"
      ],
      "metadata": {
        "id": "UM66iavGf3aQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "col_poem = \"stanza_text\"\n",
        "\n",
        "#------------------------------------------------\n",
        "\n",
        "df_poems = pd.read_csv(\"/content/drive/MyDrive/proyecto_NLP/data/poe_poems_stanzas.csv\")\n",
        "df_poems = df_poems[(df_poems[col_poem].notna()) & (df_poems[col_poem]!=\" \")]\n",
        "\n",
        "df_poems = df_poems.drop(137, axis=0)\n",
        "print(\"Dimension of datase:\", df_poems.shape)"
      ],
      "metadata": {
        "id": "Cj-VEZsSTvgj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e76a36f7-91c4-40af-c2ac-9f3d85150c2d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimension of datase: (214, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##📜 Global Functions"
      ],
      "metadata": {
        "id": "vbAy8fYFjuTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PoemDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, data, tokenizer, max_length, gpt2_type='gpt2'):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.input_ids = []\n",
        "        self.attn_masks = []\n",
        "        \n",
        "        for i in data:\n",
        "          \n",
        "            encodings_dict = tokenizer('<BOS>' + i + '<EOS>',\n",
        "                                     truncation=True,\n",
        "                                     max_length=max_length,\n",
        "                                     padding='max_length'\n",
        "                                    )\n",
        "\n",
        "            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
        "            self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
        "\n",
        "    def __len__(self):\n",
        "        \n",
        "        return len(self.input_ids)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        return self.input_ids[idx], self.attn_masks[idx]\n",
        "\n",
        "\n",
        "\n",
        "#----------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "def format_time(elapsed):\n",
        "    return str(datetime.timedelta(seconds=int(round((elapsed)))))\n",
        "    \n",
        "\n",
        "#-----------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "def train_val_split(split, dataset):\n",
        "\n",
        "    train_size = int(split * len(dataset))\n",
        "    val_size = len(dataset) - train_size\n",
        "    return train_size, val_size\n",
        "\n"
      ],
      "metadata": {
        "id": "a0q2WQhsjwuX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "RANDOM_SEED = 73\n",
        "BATCH_SIZE = 2\n",
        "epochs = 25\n",
        "MAX_LEN = 1024\n",
        "home_directory = \"/content/drive/MyDrive/proyecto_NLP/models\"\n",
        "###################################################################################################################################################################################################\n",
        "\n",
        "pretrained_weights = 'gpt2' ## as over 1.5 billion parameters\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(pretrained_weights)\n",
        "\n",
        "special_tokens_dict = {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'pad_token': '<PAD>'}\n",
        "num_added_tokens = tokenizer.add_special_tokens(special_tokens_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6y4DMPmrj82",
        "outputId": "f7a443dc-044c-491e-b20d-637bfe175ce9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/gpt2/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
            "loading file https://huggingface.co/gpt2/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "loading file https://huggingface.co/gpt2/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/gpt2/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/gpt2/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "Assigning <BOS> to the bos_token key of the tokenizer\n",
            "Adding <BOS> to the vocabulary\n",
            "Assigning <EOS> to the eos_token key of the tokenizer\n",
            "Adding <EOS> to the vocabulary\n",
            "Assigning <PAD> to the pad_token key of the tokenizer\n",
            "Adding <PAD> to the vocabulary\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🕸 Text Generation - GPT-2"
      ],
      "metadata": {
        "id": "s99fEDcBgTk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combined_poems = df_poems.groupby(['title'])[col_poem].transform(lambda x: ''.join(x)).drop_duplicates().reset_index(drop=True)"
      ],
      "metadata": {
        "id": "gV0QRdMehDro"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_poem_length = max([len(tokenizer.encode(poem)) for poem in combined_poems])\n",
        "min_poem_length = min([len(tokenizer.encode(poem)) for poem in combined_poems])\n",
        "print('Longest Poem:', max_poem_length, 'tokens long.')\n",
        "print('Shortest Poem:', min_poem_length, 'tokens long.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zk_vZr0jhXSi",
        "outputId": "f6aefec3-095d-456b-873d-0e44d4ed0efd"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1668 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Longest Poem: 4427 tokens long.\n",
            "Shortest Poem: 55 tokens long.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stanza_length = [len(tokenizer.encode(stanza)) for stanza in df_poems[col_poem].values]\n",
        "max_stanza_length = max(stanza_length)\n",
        "min_stanza_length = min(stanza_length)\n",
        "print('Number of stanzas longer than max length: ', sum([st_len > MAX_LEN for st_len in stanza_length])) \n",
        "print('Longest Stanza:', max_stanza_length, 'tokens long.')\n",
        "print('Shortest Stanza:', min_stanza_length, 'tokens long.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apZtigEeiW2v",
        "outputId": "7ebee929-b346-40c0-fb1b-1b0c075baabd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of stanzas longer than max length:  0\n",
            "Longest Stanza: 875 tokens long.\n",
            "Shortest Stanza: 15 tokens long.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "poem_dataset = PoemDataset(df_poems[col_poem].values, tokenizer, max_length=MAX_LEN)"
      ],
      "metadata": {
        "id": "tKEq4EmgjVkH"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##🐝 Train-Test Split"
      ],
      "metadata": {
        "id": "O5sEf3nPoTq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "poem_train_size, poem_val_size = train_val_split(0.8, poem_dataset)\n",
        "\n",
        "# random split imported from troch.utils\n",
        "poem_train_dataset, poem_val_dataset = random_split(poem_dataset, [poem_train_size, poem_val_size])\n",
        "\n",
        "\n",
        "#-------------------------------------------------------Random Seeds\n",
        "\n",
        "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lHya30gkKz6",
        "outputId": "4e19b225-c2c7-4c58-f9a4-5fefa4ede6ce"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f995c9f0130>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##🐝 Data Loaders"
      ],
      "metadata": {
        "id": "HAPt-zIgp1CT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "poem_train_dataloader = DataLoader(poem_train_dataset,\n",
        "                              sampler=RandomSampler(poem_train_dataset),\n",
        "                              batch_size=BATCH_SIZE)\n",
        "\n",
        "poem_val_dataloader = DataLoader(poem_val_dataset,\n",
        "                            sampler=SequentialSampler(poem_val_dataset),\n",
        "                            batch_size=BATCH_SIZE)\n",
        "\n",
        "#-------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "# helper function for logging time\n",
        "def format_time(elapsed):\n",
        "    return str(datetime.timedelta(seconds=int(round((elapsed)))))\n",
        "\n",
        "# hyperparameters\n",
        "learning_rate = 1e-4\n",
        "eps = 1e-8\n",
        "warmup_steps = 50\n",
        "# this produces sample output every 100 steps\n",
        "sample_every = 30\n",
        "\n",
        "# create text generation seed prompt\n",
        "device = torch.device('cuda')\n",
        "\n",
        "prompt = \"<BOS>\"\n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)"
      ],
      "metadata": {
        "id": "YyLRR5WWkhve"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##🚀 FineTunning: Training"
      ],
      "metadata": {
        "id": "w5pNjrn1rLwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "configuration = GPT2Config(vocab_size=len(tokenizer), n_positions=MAX_LEN).from_pretrained('gpt2', output_hidden_states=True)\n",
        "\n",
        "poem_model = GPT2LMHeadModel.from_pretrained('gpt2', config=configuration)\n",
        "\n",
        "poem_model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "poem_model.cuda()\n",
        "\n",
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "optimizer = AdamW(poem_model.parameters(), lr=learning_rate, eps=eps)\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "total_steps = len(poem_train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "# This changes the learning rate as the training loop progresses\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps=warmup_steps,\n",
        "                                            num_training_steps=total_steps)\n",
        "\n",
        "#------------------------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7p0KsD0qDS-",
        "outputId": "bbe910d5-8100-4cf5-b796-15e5a2bdca8d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
            "Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"output_hidden_states\": true,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/gpt2/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/752929ace039baa8ef70fe21cdf9ab9445773d20e733cf693d667982e210837e.323c769945a351daa25546176f8208b3004b6f563438a7603e7932bae9025925\n",
            "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_t0 = time.time()\n",
        "\n",
        "training_stats = []\n",
        "total_t0 = time.time()\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "\n",
        "poem_model = poem_model.to(device)\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
        "\n",
        "poem_model = poem_model.to(device)\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    total_train_loss = 0\n",
        "\n",
        "    poem_model.train()\n",
        "\n",
        "    for step, batch in enumerate(poem_train_dataloader):\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "\n",
        "        poem_model.zero_grad()        \n",
        "\n",
        "        outputs = poem_model(b_input_ids,\n",
        "                          labels=b_labels, \n",
        "                          attention_mask = b_masks,\n",
        "                          token_type_ids=None\n",
        "                        )\n",
        "\n",
        "        loss = outputs[0]  \n",
        "\n",
        "        batch_loss = loss.item()\n",
        "        total_train_loss += batch_loss\n",
        "\n",
        "        # Get sample every x batches.\n",
        "        if step % sample_every == 0 and not step == 0:\n",
        "\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}. Loss: {:>5,}.   Elapsed: {:}.'.format(step, len(poem_train_dataloader), batch_loss, elapsed))\n",
        "\n",
        "            poem_model.eval()\n",
        "\n",
        "            sample_outputs = poem_model.generate(\n",
        "                                    bos_token_id= random.randint(1,30000),\n",
        "                                    do_sample=True,   \n",
        "                                    top_k=50, \n",
        "                                    max_length = MAX_LEN,\n",
        "                                    top_p=0.95, \n",
        "                                    num_return_sequences=1\n",
        "                                )\n",
        "            for i, sample_output in enumerate(sample_outputs):\n",
        "                  print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n",
        "            poem_model.train()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(poem_train_dataloader)       \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================entario\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    poem_model.eval()\n",
        "\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in poem_val_dataloader:\n",
        "        \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "        \n",
        "        with torch.no_grad():        \n",
        "\n",
        "            outputs  = poem_model(b_input_ids, \n",
        "#                            token_type_ids=None, \n",
        "                             attention_mask = b_masks,\n",
        "                            labels=b_labels)\n",
        "          \n",
        "            loss = outputs[0]  \n",
        "            \n",
        "        batch_loss = loss.item()\n",
        "        total_eval_loss += batch_loss        \n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(poem_val_dataloader)\n",
        "    \n",
        "    validation_time = format_time(time.time() - t0)    \n",
        "\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
        "\n",
        "torch.save(poem_model.state_dict(), home_directory + 'poem_stanza_model.pth')"
      ],
      "metadata": {
        "id": "o1a8iqGPrwOt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9117a67d-ef35-4161-d163-90047afde9e0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training complete!\n",
            "Total training took 0:00:00 (h:mm:ss)\n",
            "\n",
            "======== Epoch 1 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 1.192217469215393.   Elapsed: 0:00:22.\n",
            "0:  Poké\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 1.7561231851577759.   Elapsed: 0:00:55.\n",
            "0: aven\n",
            "\n",
            "\n",
            "  Average training loss: 2.33\n",
            "  Training epoch took: 0:01:25\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.69\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 2 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 1.101786732673645.   Elapsed: 0:00:22.\n",
            "0:  Erdar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.2003844827413559.   Elapsed: 0:00:55.\n",
            "0:  sensors to\n",
            "\n",
            "  Average training loss: 0.55\n",
            "  Training epoch took: 0:01:24\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.63\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 3 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.401620090007782.   Elapsed: 0:00:22.\n",
            "0: atility:\n",
            "\n",
            "The joy of the new:\n",
            "\n",
            "But no joy of the old:\n",
            "By the hand of the old,\n",
            "That now grows the spirit.\n",
            "\n",
            "(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.58506178855896.   Elapsed: 0:00:55.\n",
            "0:  heavel and\n",
            "\n",
            "  Average training loss: 0.50\n",
            "  Training epoch took: 0:01:24\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.62\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 4 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.39622610807418823.   Elapsed: 0:00:22.\n",
            "0:  Danny\n",
            "\n",
            "Of\n",
            "\n",
            "The stars in the woods\n",
            "Upon a snowy night\n",
            " I saw\n",
            "\n",
            "And saw that this forest\n",
            "Was once—\n",
            " On\n",
            "Twas within\n",
            "The hills: and the hills did move again\n",
            "That night,\n",
            " In their own chamber,\n",
            " On the night-time—\n",
            " When there was no light,\n",
            "But a flickering light,—\n",
            "A chamber where all things were at hand,\n",
            "Were quiet, and, when they were burning,\n",
            "That was a chamber,\n",
            "Where all men slept,\n",
            "And slept a night to a day—\n",
            "And where all men fell asleep.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.9440230131149292.   Elapsed: 0:00:55.\n",
            "0:  AmongWhat is so beautiful and so unmeasurable are so many things that are so many things that are so easy—they are only in this world where the most universal joy and passion lie—but that which is a mystery to the world—a mystery to every human life! As well as such as God hath given a mystery unto them—as, the world will become known unto us!\n",
            "\n",
            "By an eagle!\n",
            "A sea of angels\n",
            "Their beauty hath not extinguished—\n",
            "And they will not perish!\n",
            "\n",
            "For they will not perish!\n",
            "Yet their glory will be not only the gift of God's sovereignty\n",
            "And the kingdom of his angels\n",
            "On whose throne this throne is held!\n",
            "A golden-hearted\n",
            "Whose heart loves thee more than the sun—\n",
            "But the gold-hued\n",
            "With whom we worship—\n",
            "The gold-clad, the golden-clad,\n",
            "With whom we adore.\n",
            "The angel, whom the queen hath known\n",
            "Of the angels, who know not how\n",
            " Of angels, whom the queen hath known\n",
            "Upon which this throne there is the throne of Truth—\n",
            "Upon which it is wrought,\n",
            " And that it is not yet found!\n",
            " In this world are all angels. The angel, whose presence is not so profound\n",
            " That some will believe,\n",
            "And others may not believe—\n",
            "And whose heart is not so low That some will believe—\n",
            "For the glory of God is the light of glory!\n",
            " But each angel—who, when he comes,\n",
            " Is not so lofty, nor so lofty\n",
            "As the throne of Deity—\n",
            "Which they might see and comprehend,\n",
            "And which they would not see—\n",
            "Are not so low: nor so lofty,—\n",
            "The throne of Heaven may no more pass,\n",
            "Upon the throne of Heaven!\n",
            " The throne of Heaven hath not so high\n",
            "Nor can be so low\n",
            "In the throne of Heaven—or, more obscure!\n",
            "\n",
            "What will the angels believe?—\n",
            " Wherever they know not,\n",
            "What shall their eyes see?\n",
            "Which they would not see—\n",
            "Whatever they should believe!\n",
            "What shall they teach?\n",
            " And what should they teach?—\n",
            "Wherever they are bound!—\n",
            " Wherever they belong!—\n",
            "Where they dwell!\n",
            "How many years have not the angels taught!\n",
            "How many years they have taught—\n",
            " Wherever they are bound—\n",
            "How many years have passed—\n",
            " Where they have been bound!\n",
            "The angels, by a light that leaves not the shadow\n",
            "And their souls—\n",
            "Were not so rare in the sky,\n",
            " As their angels have been—\n",
            "They bore all their beauty—\n",
            " They bore all the beauty!\n",
            "The angels of Heaven, whose eyes,\n",
            "Were not so rare in the sky—\n",
            " Were not so rare in the sky,\n",
            " As their angels have been—\n",
            "Their beauty was not so rare:\n",
            "Their beauty was not so rare!\n",
            "Their beauty was not so rare!\n",
            "There was never a world that was so unutterly dull\n",
            " As the world in which we now dwell.\n",
            " Wherever you stand, you stand—\n",
            "\n",
            "And the angel, whom you have heard\n",
            "Of the angels, who have known\n",
            "Of the angels' voice.\n",
            "The angels, whom you see—\n",
            "Where you have seen,\n",
            "How the angels have known—\n",
            "How you feel, how well you feel!\n",
            "The angels, who have known you—\n",
            "Where you have known,\n",
            "How well you feel—\n",
            "The angels' voice!\n",
            "How a God, who is the heart Of the human soul—\n",
            " Where I see, and, by God!—\n",
            "How a human heart—whose light cannot pass—\n",
            "whose light cannot be seen!\n",
            " Where the angels have seen—\n",
            "Are not so bold!\n",
            "How God hath seen—\n",
            " Where they seem to lie!\n",
            " Where the angels seem to lie—\n",
            "Who may tell!\n",
            "And that all their words,\n",
            "Are not so common—\n",
            " Are not so rare!\n",
            "\n",
            "They hath seen—\n",
            " Where the angels have seen—\n",
            " Where they have seen—\n",
            "How all their secrets are concealed—\n",
            "How all their mysteries are not so rare—\n",
            "How all their secrets are not so scarce—\n",
            " How all their secrets are not so fleeting,\n",
            "They have been alone—\n",
            "And they have been alone—\n",
            "The only one that hath uttered!\n",
            "Their only voice!\n",
            "Their only voice!\n",
            "Their only voice! They have left me—\n",
            " As far as I can see!—\n",
            " Where I can see— As far as I can see!\n",
            " Where I can see— As far\n",
            " As I can see—\n",
            "Where I can see— As far I can see!—\n",
            " That I can see— That I can see! I can see!\n",
            "The angels, whose eyes,\n",
            "Were not so rare in the sky,\n",
            "Are not so rare in the sky,\n",
            "—\n",
            "that they could never be so much\n",
            "\n",
            "  Average training loss: 0.48\n",
            "  Training epoch took: 0:01:25\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.62\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 5 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.7106380462646484.   Elapsed: 0:00:22.\n",
            "0: avoriteI'll lie down on the floor of a lakeWith all my heart and all my soul to the sublime, And I'll tell of that day, and I'll believe it;And, as I sing, I'll say, I'll see it! I'll say,— \n",
            "What a melancholy!\n",
            "What a melancholy! What a melancholy!\n",
            " The spirit which tells the tale,\n",
            " The spirit which tells the tale,\n",
            " When one loves a good thing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.2926653325557709.   Elapsed: 0:00:55.\n",
            "0: cial and divine\n",
            "\n",
            "  Average training loss: 0.46\n",
            "  Training epoch took: 0:01:24\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.62\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 6 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.24874833226203918.   Elapsed: 0:00:22.\n",
            "0: anyahu,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.2216719686985016.   Elapsed: 0:00:55.\n",
            "0: GroupTo(start,end),start,start) {\n",
            "\n",
            "\n",
            "  Average training loss: 0.45\n",
            "  Training epoch took: 0:01:24\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.62\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 7 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 1.2231088876724243.   Elapsed: 0:00:22.\n",
            "0:  BeerThe bowers, all that we see, are silent; we cannot think of them, but we see them; we see them sitting in the bosom of the garden; the wild flowers, all their foliage, that float so high in the breeze, seem like those of a thousand others. It is the light in a dream, in a dream, in a dream—they are the light of a light—but, as in the dream, it is so bright that, when we\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.18940120935440063.   Elapsed: 0:00:55.\n",
            "0: iasm' to thee—\n",
            "\n",
            "Then, all around, a sea, which hath never seen daylight before,\n",
            " Whose starry skies are lighted by the stars,\n",
            " By whose dim streams the waters flow—\n",
            " And thus that my heart may be heard,\n",
            " And that my hope may be extinguished—\n",
            " From all the glory that I now revere!\n",
            "\n",
            "  Average training loss: 0.43\n",
            "  Training epoch took: 0:01:24\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.62\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 8 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.2327970266342163.   Elapsed: 0:00:22.\n",
            "0:  prosecutI have sent unto thee,\n",
            " Yea,\n",
            " A woman, \n",
            " She is my mother,\n",
            " To whom every year I cherish\n",
            " Some sweet and tender gift,\n",
            " I cherish thee—\n",
            " And now that thy birth is in my life, \n",
            " I will remember thee forever!\n",
            " A young woman, \n",
            " To whom a token of my love\n",
            " Thou hast known my birth, \n",
            " And to whom my name hath been sung,\n",
            " And which, in Heaven, \n",
            " I have known for a thousand years, \n",
            " And that I must pass before thee with one of those solemn hymn-strings \n",
            " Of whom I can still see a tear and a murmur—\n",
            " And thus, at last, I will not—\n",
            " And with one eye, in reality, \n",
            " I will look on thee with the pride of a monarch,\n",
            " And with a blush of pride,\n",
            " On thy faces, amid the beauty of the skies.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.2335754781961441.   Elapsed: 0:00:54.\n",
            "0: mouth, and there,\n",
            "\n",
            "  Average training loss: 0.42\n",
            "  Training epoch took: 0:01:24\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.62\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 9 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.3031338155269623.   Elapsed: 0:00:22.\n",
            "0: owersI have told thee the tale of its length, when the sea went down athwart a sea, and there a man wandered among the sea.\"\n",
            "—\n",
            "In that same Annabel Lee tale—\n",
            "In a rhyme, in a rhyme \n",
            " Thence—\n",
            "In that Raven's lair \n",
            " Where the Raven of Lenore saw her,\n",
            " And then I forgot—\n",
            " Then I would not forget it.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.13639302551746368.   Elapsed: 0:00:54.\n",
            "0:  commI hope in this kingdom, \n",
            " But I must do unto death this dream of immortality, \n",
            " In hopes that if my soul hath a spirit in it,\n",
            " It may return to me in the dead,\n",
            " But that my brain may not live—\n",
            " And that my mind may not speak again till the last waking hour \n",
            " Of a dead brain,— \" \n",
            " \"\n",
            " \"\n",
            " \"— \" (Edition: original; Page\n",
            "\n",
            "  Average training loss: 0.41\n",
            "  Training epoch took: 0:01:23\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.62\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 10 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.32563892006874084.   Elapsed: 0:00:22.\n",
            "0: nesotaGone in the light of day.\"\n",
            "I passed his hand with a sigh, \n",
            "And he looked me upon a sober eye\n",
            "Not at my pride, \n",
            "But in a state of rest, \n",
            "Upon a mellow, quiet rest.\n",
            "I felt him smile—not at my heart, \n",
            "Yet at my heart,\n",
            "With a gentle, radiant smile; \n",
            " I looked upon him as I did when I saw\n",
            "His beauty, with a sort of pride, \n",
            "And a sort of pride, as he looked upon me at once.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.2969532012939453.   Elapsed: 0:00:54.\n",
            "0:  waited.\n",
            "\n",
            "  Average training loss: 0.40\n",
            "  Training epoch took: 0:01:24\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.62\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 11 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.2950354516506195.   Elapsed: 0:00:22.\n",
            "0:  YugFor the kingdom of the holy,\n",
            " Thy holy spirit hath been shed, \n",
            " While thy angels have been aching\n",
            " Thy soul,\n",
            " The angels—who dwell—with thee! \n",
            " That thy spirit hath been cast \n",
            " Like a pallid pall in thy chamber,\n",
            " Though its drapery pale \n",
            " Is the pallor of thy tomb.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.3309040069580078.   Elapsed: 0:00:54.\n",
            "0:  tutorials'\n",
            "\n",
            "'Let me see '\n",
            "'The stars\n",
            "Are shining within a crowd of travellers—\n",
            "'\n",
            "'And the stars will pass by on their journey'\n",
            "And they shall pass by on their journey. The Heaven that is above\n",
            " Is the Raven—\n",
            " That all men may know:\n",
            "'Bitter in the coldest of hours\n",
            " Of early summer—\n",
            " And the sweetest and worst of all sweets—\n",
            " Thy glory is not in the cold:——\n",
            " Thy glory is in the light\n",
            " Of early summer,\n",
            " And the Raven of Raven-haunted days\n",
            " Shall be sure— Thy delight!\n",
            " Thy pride and terror shall be known\n",
            " Thy pride and pride in the stars—\n",
            " Thy glory shall be seen!\n",
            " Thy pride and terror shall be known\n",
            " Thy pride and terror shall be seen\n",
            " Thy pride and terror shall be seen\n",
            " Thy pride and terror shall be seen\n",
            " Thy pride and terror shall be seen'\n",
            "In my youthful years I dwelt in the solitude\n",
            " Of Raven-haunted nights,\n",
            " In the solitary and shadowy halls Of Raven-haunted nights \n",
            " And in the dim and undisturbed lands of Raven-haunted days\n",
            " In the dim and undist\n",
            "\n",
            "  Average training loss: 0.39\n",
            "  Training epoch took: 0:01:24\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.62\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 12 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.47081273794174194.   Elapsed: 0:00:22.\n",
            "0:  TrFelled, \n",
            " The wind of night thro' \n",
            " The shore of Hope's bier;\n",
            " I heard her whisper \n",
            " Of a proud maiden, whose spirit \n",
            " Was sweetly drawn up by her.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.5450824499130249.   Elapsed: 0:00:54.\n",
            "0:  panicWe let him flee into the dark woods \n",
            " As if he were a queen—\n",
            " Where the mollified waters—\n",
            " Were serenity'd at her side—\n",
            " And the gush of her delight\n",
            " Like a lake of a thousand flowers in each side—\n",
            " And the mien of it—The dew\n",
            " Up to him there was an echo—\n",
            " Like the voice in the woods,\n",
            " With a quiet voice—\n",
            " With a strange melody \n",
            " Like the gush—\n",
            " In each side of the tree\n",
            " Is the beauty of that tree—\n",
            " And the gush of her delight \n",
            " Is the beauty of the lake in each side—\n",
            " Till then, in thine heart, I saw \n",
            " The sweetest of all\n",
            " The flowers whose flowers sprang from the trunk—\n",
            " And all those which flew down from above\n",
            " And were all—the lovely flowers whose flowers we loved—\n",
            " And all the radiant gems, whose flowers were all—\n",
            " Each of them—the only object in Heaven.\n",
            "\n",
            "  Average training loss: 0.39\n",
            "  Training epoch took: 0:01:23\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.62\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 13 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.2370227575302124.   Elapsed: 0:00:22.\n",
            "0:  exclusively\"\n",
            "\n",
            "But then, outspread that spirit\n",
            "Of pride and discord that is here, \n",
            " Forlorn and lovely,\n",
            " As if flown on a gale\n",
            " Around my throne, \n",
            " And so long I beheld, \n",
            " In my sleep a star—\n",
            "And in my dream a thousand\n",
            "Stars—that are still\n",
            " But dim and shadowy;\n",
            " My name is Liberty!\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.35912683606147766.   Elapsed: 0:00:54.\n",
            "0: worthyBut I saw ye in his presence—\n",
            " And the angels that knew nothing—\n",
            " And saw their glory not but in the glory, \n",
            " And the wealth not from their wealth but from their labor:\n",
            " The angels whose power were in store \n",
            " For this world's glory: \"Nevermore,\" said the angels, \n",
            " \"have ever known.\"\n",
            "\n",
            "  Average training loss: 0.38\n",
            "  Training epoch took: 0:01:23\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.62\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 14 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.9646149277687073.   Elapsed: 0:00:22.\n",
            "0:  mealsBy the moon-light, \n",
            " All the flowers, \n",
            " How strangely and faintly they bloom \n",
            " Each year, to-night,\n",
            " O love, love this lake?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.25442996621131897.   Elapsed: 0:00:54.\n",
            "0:  tokensBalls of the skies;\n",
            "But when the glory is gone \n",
            "And the bustles go down \n",
            "And the bells go down, \n",
            "My spirit is gone \n",
            "And the angels lie,\n",
            "And the ghosts—I will not help \n",
            "Keeping watch over the skies.\"\n",
            "\n",
            "  Average training loss: 0.36\n",
            "  Training epoch took: 0:01:23\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.63\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 15 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.14980226755142212.   Elapsed: 0:00:22.\n",
            "0: educ\" \n",
            "But they drank, and fell ill,\n",
            " And cried and knelt,\n",
            " \"'Breath of the dead!\n",
            " (Come and look!)'\n",
            " Where then may spring, \n",
            " The first woe-remenning star\n",
            " Of all the human world.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.23235096037387848.   Elapsed: 0:00:54.\n",
            "0:  Single\" in all things—the very fabric of Nature—the fabric of the human mind—the fabric of men's pride—the fabric of our pride—the fabric of our pride—\n",
            " The fabric of ours a fabric of pride—the fabric of ours a pride,\n",
            "\n",
            "By reason of our innate nature, as the human eye knows well,—\n",
            "The fabric of our pride—the fabric of it a pride—\n",
            "By reason of my human nature, as the human mind knows well,—\n",
            " It would seem that no fabric of pride lies apart:\n",
            " But in what way this fabric—the fabric of it,\n",
            "Which is the most common of all the human types—\n",
            "The fabric of ours a pride—\n",
            "The fabric of ours a pride—\n",
            " By reason of my innate nature,—\n",
            "It would seem that no fabric apart from this and all the human\n",
            "\n",
            "Habits contain pride—this God, alone, without pride\n",
            " Is in truth the only God!—\n",
            "And yet no pride in pride lies apart—\n",
            "To us! Love is a token of that love that cannot be broken. Love lies in the measure of the love that passes through us\n",
            "In the measure of our innate nature,—the measure of our love that passes through us.\n",
            "And yet no pride in pride lies apart—to us!\n",
            "By God alone, alone—by God alone—\n",
            "The God of love, unbroken by the love of the world\n",
            "How long has he known the love of his own essence? No pride in pride lies apart!\n",
            " By God alone, without pride:—by God alone!\n",
            "It would seem that no pride lies apart—from us!\n",
            "By God alone, without pride!\n",
            "By God alone, without pride:—by God alone, without pride. 1849 Contents p. 2\n",
            "\n",
            "  Average training loss: 0.36\n",
            "  Training epoch took: 0:01:24\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.63\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 16 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.5345574021339417.   Elapsed: 0:00:22.\n",
            "0: obe\" \n",
            " \"Well, my God! \n",
            " No more need I to speak!\"\n",
            " \"Nevermore!\"\n",
            " \"Nevermore!\"\n",
            " \"Nevermore!\n",
            " No more—\n",
            " Nothing more!\"\n",
            " \"Nevermore!\"\n",
            " \"Nevermore!\" \n",
            "\n",
            "Nevermore! \n",
            " Nevermore \n",
            " \n",
            "\n",
            "Nevermore\n",
            "\n",
            "! This is the route of Hope\n",
            " Over Hell! \n",
            " On Hope's path—\n",
            " Over Hell it is written! \n",
            " \"There is a route that holds all—\n",
            " Under Heaven—\n",
            " Over Hell it is written;\n",
            " But treads not thus: \n",
            " Upon Heaven alone,\n",
            " Israfel\n",
            " Irafel!\" \n",
            " 1849 Note Contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.21182383596897125.   Elapsed: 0:00:54.\n",
            "0: brance\"\n",
            "\n",
            "\"Ah! wo! wo! wo! wo! wo!\n",
            " Woe! in the pit of the Mad Time—as in the throes of fire—as in the slumber of the Hell-fire.\"\n",
            "\n",
            "I uttered these words so gently that the crowd—and my brain—fell within a minute or two of agreeing, when,\n",
            "\n",
            "  Average training loss: 0.35\n",
            "  Training epoch took: 0:01:23\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.63\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 17 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.2928674519062042.   Elapsed: 0:00:22.\n",
            "0:  ObAll lights of the sun\n",
            " Shone dimly; \n",
            " As though from heaven on high\n",
            " I soared with the hope of a brighter Heaven\n",
            " Like a gallant knight at Rome's door. 1849 Contents p. 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.16308072209358215.   Elapsed: 0:00:54.\n",
            "0:  assigned'Enemy of the King!\" —\n",
            "And, lifting a hand in affright,\n",
            "And clasping, knelt, \n",
            "On the velvet floor \n",
            "Where the King sat.\n",
            "The monarch looked down upon his dead father,\n",
            " And muttered, \"A new start shall start,\n",
            "Upon the path of the newly-mended path.\" 1827 Note Contents\n",
            "\n",
            "  Average training loss: 0.34\n",
            "  Training epoch took: 0:01:24\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.64\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 18 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.31913062930107117.   Elapsed: 0:00:22.\n",
            "0: ipesMy heart, then, was light and sober;\n",
            " But the world was dark and sober,\n",
            " Like the stars in summer,\n",
            " Like a pallid pall on the black Earth.\n",
            " That pall was still and quiet,\n",
            " Like a shadow that fell from my chamber door,\n",
            " Like a pall in a theatre, \n",
            " A pall in the chamber of the dead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.18803106248378754.   Elapsed: 0:00:55.\n",
            "0: avier. \n",
            "I grew in love with her,\n",
            "For a very fair maiden was there: \n",
            "What made her blush was the love \n",
            "Of a fair maiden,\n",
            "For a fair maiden whom I loved well, \n",
            "I loved her for who she was,\n",
            "And by her side in life, \n",
            "She loved me so well \n",
            "That when her heart was beaten \n",
            "I could no longer help laughing at her; \n",
            "Her heart sank \n",
            "In a sort of dreamy, low moan.\n",
            "\n",
            "  Average training loss: 0.34\n",
            "  Training epoch took: 0:01:25\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.65\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 19 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.4165072739124298.   Elapsed: 0:00:22.\n",
            "0:  totallyIt was my ambition to see that my heart grew bolder—as a poet—as a man—while, with a view to my own happiness and well-being, I wandered in the wilderness,\n",
            " In the bosom of a most remote region far above us, While some traveller intrude, as he passes,\n",
            " T'othermyr, within the bosom of the calm waters—\n",
            " 'Tis a common fact of the life of man that in his solitary solitude a state of spirit\n",
            " Is not altered by its environment;\n",
            " That all the time he walks or m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.4211231470108032.   Elapsed: 0:00:55.\n",
            "0:  slogThe Hours\n",
            "\n",
            "And the Hours\n",
            "\n",
            "And the Hours\n",
            "\n",
            "Are Hours\n",
            "\n",
            "Of my Earthly ways:\n",
            "How they were wrought\n",
            " On this Earth; \n",
            "Yet\n",
            "By their own power and labor, \n",
            " They left \n",
            "And bound \n",
            " My Earthly ways,\n",
            " To the winds—\n",
            " To the seas,\n",
            " To the skies—\n",
            " From the winds—\n",
            "And from the stars—\n",
            " I flung \n",
            " And hurled \n",
            " A ray—\n",
            " Of light as in a dream:—\n",
            "\n",
            "  Average training loss: 0.33\n",
            "  Training epoch took: 0:01:26\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.65\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 20 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.5348502397537231.   Elapsed: 0:00:22.\n",
            "0:  pissedAt noon the first blush grew bright—\n",
            " As I walked upon the threshold, \n",
            " As I reached the door, the lamp\n",
            " Shone with an intenser gleam—\n",
            " And I trembled—\n",
            " My heart weighed not—I trembled—\n",
            " But I trembled.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.19002974033355713.   Elapsed: 0:00:55.\n",
            "0: mph\"\n",
            "\n",
            "Now it trembles on the tresses of its hair\n",
            " As the moon is sinking, \n",
            " The vapor of its pride \n",
            " The vapor of its pride \n",
            " Shams its pride on the weak and dead; \n",
            " But love's venom—\n",
            " To her loveliness, to her pride\n",
            " With the venom in the winds, \n",
            " With the venom in the floods, \n",
            " She holds it high, \n",
            " And the venom it caresses \n",
            " Is with a sort of holy vow—\n",
            " But her spell\n",
            " Is with a kind of vow—\n",
            " \"My dear, my forgiveness!\"\n",
            " To my God my forgiveness!\n",
            " For I am thy red-lettering: \n",
            " That my heart beats with a solemn tone—\n",
            " That my soul beats with a resolute tone, \n",
            " And that my name is uttered, \n",
            " \"Ah, my God,\" says I,\n",
            " \"by the voice of God.\"\n",
            "\n",
            "  Average training loss: 0.32\n",
            "  Training epoch took: 0:01:25\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.65\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 21 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.23084066808223724.   Elapsed: 0:00:22.\n",
            "0: SimilarlyA shadow on the floor \n",
            " Hath wooed me \n",
            " A lovely dream:\n",
            " A dreamy dream,\n",
            " And a dreamy dream \n",
            " To which I have not long \n",
            " Seen thee, and only thee; \n",
            " For the very moment \n",
            " Is gone, the dream still, \n",
            " And I feel \n",
            " Thy presence on my very soul, \n",
            " Too late, for this is a dream.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.2000531256198883.   Elapsed: 0:00:54.\n",
            "0: ellig\"\n",
            "\n",
            "—Lionnaire de Condorcet, S. V.\n",
            "\n",
            "The plot falls apart after this letter—\n",
            "And, after failing, to me the solace that was in Lemnos!\n",
            "Thus followed my journey down from Lem\n",
            "\n",
            "  Average training loss: 0.32\n",
            "  Training epoch took: 0:01:23\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.66\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 22 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.17875109612941742.   Elapsed: 0:00:22.\n",
            "0:  compassionWhen the sun came down, there was still nothing that remainedBut light, until the moon,\n",
            " As the sun did, it still dallied happily by;\n",
            " As the stars did, their destinies went unpolluted.\n",
            " The winds they left, in a myriad of forms,\n",
            " Perfumed the sky; the seas they stirred up \n",
            " Through the air of Ghastly Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian Stygian\n",
            " \n",
            " On Earth—I'll call it Love. \n",
            " On God—I'll call\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.6616799235343933.   Elapsed: 0:00:54.\n",
            "0:  slatedFor the grandeur of her estate,\n",
            " I longed in dreams, \n",
            " I long have dreamed of her—\n",
            " Her home on this rock—\n",
            " Her shore on the sea;\n",
            " She hath no bounds \n",
            " To explore \n",
            " That is her home—\n",
            " Wherever she may lead me!—\n",
            " No pathway o'er the calm \n",
            " Hath left her—but the lone,\n",
            " Overlooking the tarns\n",
            " Of the tarns, tarns—\n",
            " Hath drawn me—oh, in dreams, \n",
            " She hath not left me desolate \n",
            " Of every shore \n",
            " To me! \n",
            " No shore—no shore—no cliff \n",
            " Hath left her—\n",
            " Nor—I must confess—\n",
            " Hath striven alone—and alone—\n",
            " None of the world hath left her alone! \n",
            " No cliff—no tarn—no dank ruin \n",
            " Within my view—\n",
            " Nor dank shore—no dim lake \n",
            " Within my home—\n",
            " But no tarn—no tarn—no tarn\n",
            " No tarn—no dank lake \n",
            " Within my own!\n",
            " No tarn—no tarn—no d\n",
            "\n",
            "  Average training loss: 0.31\n",
            "  Training epoch took: 0:01:23\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.66\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 23 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.24791069328784943.   Elapsed: 0:00:22.\n",
            "0:  upstairsIn that shadowy garden of the valley where the mountains lie, \n",
            " A lonely, sad maiden,\n",
            " Wrapped in a velvet pewter pall, \n",
            " And flung in myriad pæan cushions \n",
            " Around her, gazing at the dew-drops \n",
            " That drip, drip, drip, drip of dew—\n",
            " Till, amid the gray dew,\n",
            " The pæan air of a funeral dirge \n",
            " Over every lowly grave \n",
            " Transforming itself into that dewy, maddened tomb \n",
            " Where,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.21566912531852722.   Elapsed: 0:00:54.\n",
            "0:  grants. 1849: \"This summer hath lit my spirit bright with eagle-eye,\" said I, \"while the sun was sinking in the Stygian Stygian sea, \n",
            " Aghast at the coming of the Lion of Tethruc-Maria, who, when all the earth was blue, lay—aghast—aghast—embryo!\" 1849: \"Never,\" I replied, \"never.\" 1849: \"Nevermore.\" 1849: \"Nevermore.\"\n",
            " 1849: \"Nevermore.\" 1849: \"Nevermore.\" 1849: \"Nevermore.\" 1849: \"Nevermore.\" 1849: \"Nevermore.\"\n",
            " 1849: \"Nevermore.\" 1849: \"Nevermore.\" 1849: \"Nevermore.\"\n",
            " 1849: \"Nevermore.\" 1849: \"Nevermore.\"\n",
            " 1849: \"Nevermore.\" 1849: \"Nevermore.\" 1849: \"Nevermore.\"\n",
            " 1849: \"Never\n",
            "\n",
            "  Average training loss: 0.31\n",
            "  Training epoch took: 0:01:24\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.66\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 24 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.23161472380161285.   Elapsed: 0:00:22.\n",
            "0:  Sixth(!) of the Age of Light\n",
            " was a garden—a shrine, in solemnest yearning called \n",
            " Radiant Earth,\n",
            " From which the light, so called, flitting\n",
            " Bubbles, grew up and died. \n",
            " Where the sunshine died and died, \n",
            " The cold, the fever\n",
            " And the slumber were brought.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.21685539186000824.   Elapsed: 0:00:54.\n",
            "0:  mining.\n",
            "\n",
            "But the storm that\n",
            "\n",
            "  Average training loss: 0.30\n",
            "  Training epoch took: 0:01:23\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.67\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 25 / 25 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    30  of     86. Loss: 0.2945840060710907.   Elapsed: 0:00:22.\n",
            "0:  MoO! Is this the city of Athens, that is the seat of our glory—\n",
            " The grand statue, which my grand master \n",
            " Said, \n",
            " \"Never again dost move thee,\"\n",
            " But, on thy wandering hither,\n",
            " \"Nevermore,\" I say,\n",
            " For this very spot shall be thy seat.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    60  of     86. Loss: 0.2936598062515259.   Elapsed: 0:00:54.\n",
            "0:  Jr' s father, whose\n",
            "\n",
            "  Average training loss: 0.30\n",
            "  Training epoch took: 0:01:23\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.67\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:37:10 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 👨‍🚀 Summary of the training process"
      ],
      "metadata": {
        "id": "EKkI6RKJyWnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "metadata": {
        "id": "KRupsj2jyWeQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 864
        },
        "outputId": "ea443ca5-12bb-4b0d-9be0-091c651b0b33"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Training Loss  Valid. Loss Training Time Validation Time\n",
              "epoch                                                          \n",
              "1               2.33         0.69       0:01:25         0:00:05\n",
              "2               0.55         0.63       0:01:24         0:00:05\n",
              "3               0.50         0.62       0:01:24         0:00:05\n",
              "4               0.48         0.62       0:01:25         0:00:05\n",
              "5               0.46         0.62       0:01:24         0:00:05\n",
              "6               0.45         0.62       0:01:24         0:00:05\n",
              "7               0.43         0.62       0:01:24         0:00:05\n",
              "8               0.42         0.62       0:01:24         0:00:05\n",
              "9               0.41         0.62       0:01:23         0:00:05\n",
              "10              0.40         0.62       0:01:24         0:00:05\n",
              "11              0.39         0.62       0:01:24         0:00:05\n",
              "12              0.39         0.62       0:01:23         0:00:05\n",
              "13              0.38         0.62       0:01:23         0:00:05\n",
              "14              0.36         0.63       0:01:23         0:00:05\n",
              "15              0.36         0.63       0:01:24         0:00:05\n",
              "16              0.35         0.63       0:01:23         0:00:05\n",
              "17              0.34         0.64       0:01:24         0:00:05\n",
              "18              0.34         0.65       0:01:25         0:00:05\n",
              "19              0.33         0.65       0:01:26         0:00:05\n",
              "20              0.32         0.65       0:01:25         0:00:05\n",
              "21              0.32         0.66       0:01:23         0:00:05\n",
              "22              0.31         0.66       0:01:23         0:00:05\n",
              "23              0.31         0.66       0:01:24         0:00:05\n",
              "24              0.30         0.67       0:01:23         0:00:05\n",
              "25              0.30         0.67       0:01:23         0:00:05"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2f3934a0-c428-4a70-8964-6d49ee81d9c3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.33</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0:01:25</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.55</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0:01:24</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.50</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0:01:24</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.48</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0:01:25</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.46</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0:01:24</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.45</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0:01:24</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.43</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0:01:24</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.42</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0:01:24</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.41</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0:01:23</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.40</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0:01:24</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.39</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0:01:24</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.39</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0:01:23</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.38</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0:01:23</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.36</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0:01:23</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.36</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0:01:24</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.35</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0:01:23</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.34</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0:01:24</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.34</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0:01:25</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.33</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0:01:26</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.32</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0:01:25</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.32</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0:01:23</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.31</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0:01:23</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.31</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0:01:24</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.30</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0:01:23</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.30</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0:01:23</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2f3934a0-c428-4a70-8964-6d49ee81d9c3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2f3934a0-c428-4a70-8964-6d49ee81d9c3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2f3934a0-c428-4a70-8964-6d49ee81d9c3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 👨‍🚀 Performance Summary"
      ],
      "metadata": {
        "id": "VGqxIrB50D2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4, 5, 6, 7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "4CUiEobzQ2yB",
        "outputId": "d0d42945-53f0-4548-d437-53aa1b6ae936"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##🌌 Model Info"
      ],
      "metadata": {
        "id": "bMzwiVH5yl4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(poem_model.named_parameters())\n",
        "\n",
        "print('The GPT-2 model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:2]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[2:14]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-2:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "metadata": {
        "id": "WDpr7xdD0dpU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a50ce1a8-eb15-4af8-a814-292a4c244437"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The GPT-2 model has 148 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "transformer.wte.weight                                  (50260, 768)\n",
            "transformer.wpe.weight                                   (1024, 768)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "transformer.h.0.ln_1.weight                                   (768,)\n",
            "transformer.h.0.ln_1.bias                                     (768,)\n",
            "transformer.h.0.attn.c_attn.weight                       (768, 2304)\n",
            "transformer.h.0.attn.c_attn.bias                             (2304,)\n",
            "transformer.h.0.attn.c_proj.weight                        (768, 768)\n",
            "transformer.h.0.attn.c_proj.bias                              (768,)\n",
            "transformer.h.0.ln_2.weight                                   (768,)\n",
            "transformer.h.0.ln_2.bias                                     (768,)\n",
            "transformer.h.0.mlp.c_fc.weight                          (768, 3072)\n",
            "transformer.h.0.mlp.c_fc.bias                                (3072,)\n",
            "transformer.h.0.mlp.c_proj.weight                        (3072, 768)\n",
            "transformer.h.0.mlp.c_proj.bias                               (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "transformer.ln_f.weight                                       (768,)\n",
            "transformer.ln_f.bias                                         (768,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Saving & Loading Fine-Tuned Model\n"
      ],
      "metadata": {
        "id": "KMaFNHYw0Jkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = home_directory +'/model_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = poem_model.module if hasattr(poem_model, 'module') else poem_model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ],
      "metadata": {
        "id": "2qxncMRnyvae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3d0399e-345b-4fa4-d201-4c3c5bb441de"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Configuration saved in /content/drive/MyDrive/proyecto_NLP/models/model_save/config.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to /content/drive/MyDrive/proyecto_NLP/models/model_save/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model weights saved in /content/drive/MyDrive/proyecto_NLP/models/model_save/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/proyecto_NLP/models/model_save/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/proyecto_NLP/models/model_save/special_tokens_map.json\n",
            "added tokens file saved in /content/drive/MyDrive/proyecto_NLP/models/model_save/added_tokens.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/proyecto_NLP/models/model_save/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/proyecto_NLP/models/model_save/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/proyecto_NLP/models/model_save/vocab.json',\n",
              " '/content/drive/MyDrive/proyecto_NLP/models/model_save/merges.txt',\n",
              " '/content/drive/MyDrive/proyecto_NLP/models/model_save/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "home_directory+'/model_save/'"
      ],
      "metadata": {
        "id": "OYg_S0691HjR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "60677016-5aaf-4974-9796-64ca8c889ae9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/proyecto_NLP/models/model_save/'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l --block-size=K /content/drive/MyDrive/proyecto_NLP/models/model_save/"
      ],
      "metadata": {
        "id": "EsObwP6r07Ob",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47b06736-1833-4f4e-e9a4-a0199f185ab4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 499869K\n",
            "-rw------- 1 root root      1K Jul  3 18:13 added_tokens.json\n",
            "-rw------- 1 root root      1K Jul  3 18:13 config.json\n",
            "-rw------- 1 root root    446K Jul  3 18:13 merges.txt\n",
            "-rw------- 1 root root 498444K Jul  3 18:13 pytorch_model.bin\n",
            "-rw------- 1 root root      1K Jul  3 18:13 special_tokens_map.json\n",
            "-rw------- 1 root root      1K Jul  3 18:13 tokenizer_config.json\n",
            "-rw------- 1 root root    976K Jul  3 18:13 vocab.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l --block-size=M /content/drive/MyDrive/proyecto_NLP/models/model_save/pytorch_model.bin"
      ],
      "metadata": {
        "id": "OFtW-6ka1BUK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b3fa261-2814-4953-c653-277568140514"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw------- 1 root root 487M Jul  3 18:13 /content/drive/MyDrive/proyecto_NLP/models/model_save/pytorch_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy the model files to a directory in your Google Drive.\n",
        "#!cp -r /content/drive/MyDrive/proyecto_NLP/models/model_save/  $data_dir\n",
        "\n",
        "# # Load a trained model and vocabulary that you have fine-tuned\n",
        "#model = GPT2LMHeadModel.from_pretrained(output_dir)\n",
        "#tokenizer = GPT2Tokenizer.from_pretrained(output_dir)\n",
        "#model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAb9n45p1Wk0",
        "outputId": "9e10e8ed-b917-40c8-9764-b15a343f0fec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: missing destination file operand after '/content/drive/MyDrive/proyecto_NLP/models/model_save/'\n",
            "Try 'cp --help' for more information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Poems Generation"
      ],
      "metadata": {
        "id": "NoydP2C61uXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "poem_model.eval()\n",
        "\n",
        "prompt = 'love is'\n",
        "\n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)\n",
        "\n",
        "sample_outputs = poem_model.generate(\n",
        "                                generated, \n",
        "                                do_sample=True,   \n",
        "                                top_k=40, \n",
        "                                max_length = 100,\n",
        "                                top_p=0.95, \n",
        "                                num_return_sequences=3,\n",
        "                                num_beams=5, no_repeat_ngram_size=4, early_stopping=True\n",
        "                                )\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAKb4iCOxMxf",
        "outputId": "5dcfa4a8-86de-47a1-c011-89a5664e290f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: love is the light of the night—\n",
            " And the shadow of the mountain \n",
            " And the mist of the sea \n",
            " Is a barrier—\n",
            " And a barrier that will not be broken \n",
            " By the battle-cry \n",
            " Of the trumpet-thunder-thunder,\n",
            " But by the roar of the battle \n",
            " Shall be the battle cry of the dead \n",
            " And shall be the cry of the living—\n",
            " And by the roar shall be the roar\n",
            " Of the battle-\n",
            "\n",
            "\n",
            "1: love is the light of life;\n",
            "It glows in the dim of night;\n",
            "It flickers with the light of day,\n",
            "And in the mist of day, \n",
            "It trembles with the chilly eye \n",
            "Of the lonesome and the dead.\n",
            "\n",
            "\n",
            "2: love is a synonym for love,\n",
            " For love is a double-edged sword—\n",
            " And love is a gift from God—\n",
            " For the love of God is a gift of life—\n",
            " And the love of man is a gift given by God—\n",
            " And we are saved only by the grace of God.\"\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "poem_model.eval()\n",
        "\n",
        "prompt = 'heaven is good'\n",
        "\n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)\n",
        "\n",
        "sample_outputs = poem_model.generate(\n",
        "                                generated, \n",
        "                                do_sample=True,   \n",
        "                                top_k=40, \n",
        "                                max_length = 150,\n",
        "                                top_p=0.95, \n",
        "                                num_return_sequences=3,\n",
        "                                num_beams=5, no_repeat_ngram_size=4, early_stopping=True\n",
        "                                )\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
      ],
      "metadata": {
        "id": "d62W2SzcSpza",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f16f2d7-9a6a-4536-cd58-b2b76c135240"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: heaven is good, and light is light;\n",
            "And all things which are holy, \n",
            "Are light, and all things which seem \n",
            "To be a gift from God to us, \n",
            "And to us a token of our gratitude. 18\n",
            "¹ ¿ 18\n",
            "\n",
            "\n",
            "1: heaven is good,\n",
            "And the winds are gentle, \n",
            "And the skies are clear—\n",
            "And the stars seem to be smiling—\n",
            "And there is no need \n",
            "To sing the hymns of the hymn-winds, \n",
            "Unless, perhaps, you are a poet or a hymn-stringer—\n",
            "And you will sing the hymn of the sun-ray, \n",
            "Of the moon-ray,\n",
            "Of the stars,\n",
            "And there will be no need\n",
            "For you to sing the song of the moon, \n",
            " Of the stars, or of the angels, \n",
            "With the accompaniment of the bells and the bells of the bells, \n",
            "So that you may feel no need\n",
            "\n",
            "\n",
            "2: heaven is good, \n",
            " And all things are light, \n",
            " That is, I believe, the reason \n",
            " That all things are bright—\n",
            " And all that is gray—\n",
            " That all that is sad, \n",
            " Is the reason that all things seem \n",
            " To be of one essence, \n",
            " But that all things are of one essence—\n",
            " And that all things—all things—have one essence— \n",
            " The reason why all things are \n",
            " One and the same—\n",
            " Why all things are one and the same \n",
            " And why all things—and all things—have a single essence \n",
            " That alone can be comprehended \n",
            " By reason alone—\n",
            " And yet all things have a single essence—\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "poem_model.eval()\n",
        "\n",
        "prompt = 'I have a dream'\n",
        "\n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)\n",
        "\n",
        "sample_outputs = poem_model.generate(\n",
        "                                generated, \n",
        "                                do_sample=True,   \n",
        "                                top_k=40, \n",
        "                                max_length = 150,\n",
        "                                top_p=0.95, \n",
        "                                num_return_sequences=3,\n",
        "                                num_beams=5, no_repeat_ngram_size=3, early_stopping=True\n",
        "                                )\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgP6WqTk0sbg",
        "outputId": "ed6406ef-85a2-4f54-d0d6-c9bd3c856db9"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: I have a dream—a dream I can never control—\n",
            " A dream I cannot control—but a dream\n",
            " That I can't control—and a dream that I can only dream\n",
            " Of a night of rest in which I can lie—\n",
            " And a dream of a day of rest\n",
            " In which my heart beats at the thought\n",
            " Of what I have been dreaming of—\n",
            " Of the things that I have not been dreaming\n",
            " Of—what I have never been dreaming—\n",
            " Dreams that I do not know how to bring\n",
            " To pass my restlessness—\n",
            " But a dream in which my mind\n",
            " Is at rest—in which my spirit is at rest\n",
            " And I can no more lie\n",
            " Than I can at rest.\n",
            "\n",
            "\n",
            "1: I have a dream—a dream—that is to be,\n",
            " A dream that I have never known—\n",
            "A dream I have not seen before—\n",
            "I have not dreamed of waking up,\n",
            "A waking-up-to-life, \n",
            "A dreaming-out-of-life—\n",
            "For I have been dreaming, dreaming,\n",
            "Of waking up—\n",
            "And waking up in the morning,\n",
            "And dreaming of a brighter future—\n",
            "Of a brighter home—\n",
            "To a happier home,\n",
            "To happier skies—\n",
            "With a brighter heart—\n",
            " To a happier heart—with a brighter spirit—\n",
            " With a brighter mind—\n",
            " A brighter heart!\n",
            "\n",
            "\n",
            "2: I have a dream—a dream—that I can't help but dream of—\n",
            "A dream of a future in which I can only dream\n",
            "Of a happier future—\n",
            "Of an ultimate bliss—\n",
            " Of a happier and more peaceful life—\n",
            "And of a happier, happier, more 18 18 18� ¿¿¾½‑ ½£¨ �ºÈ È¿ ¿ �\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "poem_model.eval()\n",
        "\n",
        "prompt = 'I have a dream'\n",
        "\n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)\n",
        "\n",
        "sample_outputs = poem_model.generate(\n",
        "                                generated, \n",
        "                                do_sample=True,   \n",
        "                                top_k=50, \n",
        "                                max_length = 150,\n",
        "                                top_p=0.95, \n",
        "                                num_return_sequences=3,\n",
        "                                num_beams=5, no_repeat_ngram_size=2, early_stopping=True\n",
        "                                )\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZ6vE0QbRIlW",
        "outputId": "442559d7-1266-4061-8600-edbd8f14aedd"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: I have a dream. \n",
            " I am dreaming of a mountain—\n",
            " A mountain that trembles with the dew\n",
            " Of a demon that has tempted me,\n",
            " And has torn me from my senses. p. See! 18 p.} ¡¡ ¿¿ ½ Á½Á ÓÉ¢£$€�‑Ã±¨®°ºâánéúáóſ��ûñô¯èà�ïén\n",
            "\n",
            "\n",
            "1: I have a dream—a dream of a brighter and brighter future! 18 ¤¤ ¡ ä¡¦Ó¢¢ cents pædæmmenspædin³PæDæmens pédalesñƒƓ¿pi£º½áné¨èúÃíáóÉà°â±ſ�½ �‑ ½��®§� ° 18\n",
            "\n",
            "\n",
            "2: I have a dream. \n",
            " It is a vision of the future,\n",
            " And all I can do is look on\n",
            " As it glistens on the sky—\n",
            " But what is it to me now?\n",
            " What is to be said of that dream\n",
            " That I have not seen before,?\"\n",
            " Quoth the Raven, \"Nevermore.\" p. Yes, I remember well\n",
            " The first time I panted, 1849\n",
            " Of the night I fell— 1845\n",
            " I scarcely remember it— 1846\n",
            " Was it not the dream that I had earlier\n",
            " Tamed—that I first dreamt of\n",
            " My own being— 1847\n",
            " When I was twelve\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SFdyRv51R3P3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}