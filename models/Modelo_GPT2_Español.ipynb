{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adrincont/Proyecto-IA-PLN/blob/main/Modelo_GPT2_Espa%C3%B1ol.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHkYFOFNvqi-"
      },
      "source": [
        "# **Modelo 2 (Generacion de Poemas) GPT2**\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers -U"
      ],
      "metadata": {
        "id": "WGXNdxfBLrwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyyaml==5.4.1"
      ],
      "metadata": {
        "id": "ZPW3kb2Hv6vf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install plotly_express"
      ],
      "metadata": {
        "id": "nFuvT-Wcv7yA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2SAgacGzvqjB",
        "outputId": "ab2e5164-3e75-41d7-e65b-1942776dc83a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
            "  defaults = yaml.load(f)\n"
          ]
        }
      ],
      "source": [
        "# Basicas\n",
        "import pandas as pd\n",
        "import plotly.express as plx\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "import os\n",
        "import time\n",
        "import datetime\n",
        "# Pytorch\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
        "# Texto\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "from transformers import get_scheduler\n",
        "import random\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, GPT2Config, AdamW, get_linear_schedule_with_warmup\n",
        "from tqdm import tqdm, trange\n",
        "from transformers import pipeline\n",
        "# Sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Funciones y variables\n",
        "def format_time(elapsed): return str(datetime.timedelta(seconds=int(round((elapsed)))))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Informacion del modelo ------------------------------------------------------\\\n",
        "max_length = 1000 # Longitud maxima de los poemas\n",
        "modelo_gpt = \"DeepESP/gpt2-spanish\" # Modelo pre entrenado\n",
        "RANDOM_SEED = 2022 # Semilla"
      ],
      "metadata": {
        "id": "239Pi91Mv66B"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Datos**"
      ],
      "metadata": {
        "id": "J1yX23FRe0yd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://raw.githubusercontent.com/andreamorgar/poesIA/master/data/poems.csv'\n",
        "poems_df = pd.read_csv(url)\n",
        "poems_df = poems_df.dropna()"
      ],
      "metadata": {
        "id": "1YLm8TDBezt-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar poemas grandes\n",
        "poems_df['string'] = poems_df.apply(lambda row: f'\\n{row[\"title\"]}\\n{row[\"content\"]}', axis=1)\n",
        "poems_df['length'] = poems_df.string.map(len)\n",
        "poems_filtered = poems_df[poems_df.length < max_length]\n",
        "_ , poems_filtered = train_test_split(poems_filtered, test_size = 0.95 ,shuffle=True,random_state = 2022)\n",
        "poems_filtered"
      ],
      "metadata": {
        "id": "1g4lr7TxghDE",
        "outputId": "f39450e8-cf8b-42a8-9a0b-ff169b912eab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         author  \\\n",
              "3926     Gustavo Adolfo Bécquer   \n",
              "1475                Nacho Buzón   \n",
              "3574       Carmen Conde Abellán   \n",
              "1776              Jorge Debravo   \n",
              "3216           Alfredo Lavergne   \n",
              "...                         ...   \n",
              "1173               Lope de Vega   \n",
              "1710  Luis Cañizal de la Fuente   \n",
              "2678            Marilina Rébora   \n",
              "923   Ismael Enrique Arciniegas   \n",
              "4902        Manuel Altolaguirre   \n",
              "\n",
              "                                                content  \\\n",
              "3926  \\nFingiendo realidades \\ncon sombra vana, \\nde...   \n",
              "1475  sobre la mesa un cenicero\\ncon siete colillas\\...   \n",
              "3574  \\n\\n¡Cuán hermosa tú, la desvelada!\\nTe lleva ...   \n",
              "1776  \\n\\nHoy mi vida no tiene peso alguno:\\nes un v...   \n",
              "3216  Mientras buscamos\\nUn nombre al arte que dará ...   \n",
              "...                                                 ...   \n",
              "1173  \\n\\nSilvio a una blanca corderilla suya,\\nde c...   \n",
              "1710  \\n\\n   Quién esconde palabras, quién escatima ...   \n",
              "2678  \\n\\nA bautizarse acuden las gentes al Jordán.\\...   \n",
              "923   \\n\\nYa aspiro los aromas de su huerto;\\nLas br...   \n",
              "4902  \\n\\n¡Qué sola estabas por dentro!\\n\\nCuando me...   \n",
              "\n",
              "                                    title  \\\n",
              "3926                         Rima LXXVIII   \n",
              "1475                       fumar es bueno   \n",
              "3574                       LLUVIA EN MAYO   \n",
              "1776                      APUNTE INTERIOR   \n",
              "3216                               Camino   \n",
              "...                                   ...   \n",
              "1173  Silvio a una blanca corderilla suya   \n",
              "1710                          LANDRE COMA   \n",
              "2678                    SAN JUAN BAUTISTA   \n",
              "923                             EN SUEÑOS   \n",
              "4902                                 BESO   \n",
              "\n",
              "                                                 string  length  \n",
              "3926  \\nRima LXXVIII\\n\\nFingiendo realidades \\ncon s...     148  \n",
              "1475  \\nfumar es bueno\\nsobre la mesa un cenicero\\nc...     172  \n",
              "3574  \\nLLUVIA EN MAYO\\n\\n\\n¡Cuán hermosa tú, la des...     470  \n",
              "1776  \\nAPUNTE INTERIOR\\n\\n\\nHoy mi vida no tiene pe...     570  \n",
              "3216  \\nCamino\\nMientras buscamos\\nUn nombre al arte...     192  \n",
              "...                                                 ...     ...  \n",
              "1173  \\nSilvio a una blanca corderilla suya\\n\\n\\nSil...     574  \n",
              "1710  \\nLANDRE COMA\\n\\n\\n   Quién esconde palabras, ...     955  \n",
              "2678  \\nSAN JUAN BAUTISTA\\n\\n\\nA bautizarse acuden l...     734  \n",
              "923   \\nEN SUEÑOS\\n\\n\\nYa aspiro los aromas de su hu...     785  \n",
              "4902  \\nBESO\\n\\n\\n¡Qué sola estabas por dentro!\\n\\nC...     387  \n",
              "\n",
              "[3530 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bb5b0679-59f2-4aad-9e63-94c9c864a802\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>content</th>\n",
              "      <th>title</th>\n",
              "      <th>string</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3926</th>\n",
              "      <td>Gustavo Adolfo Bécquer</td>\n",
              "      <td>\\nFingiendo realidades \\ncon sombra vana, \\nde...</td>\n",
              "      <td>Rima LXXVIII</td>\n",
              "      <td>\\nRima LXXVIII\\n\\nFingiendo realidades \\ncon s...</td>\n",
              "      <td>148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1475</th>\n",
              "      <td>Nacho Buzón</td>\n",
              "      <td>sobre la mesa un cenicero\\ncon siete colillas\\...</td>\n",
              "      <td>fumar es bueno</td>\n",
              "      <td>\\nfumar es bueno\\nsobre la mesa un cenicero\\nc...</td>\n",
              "      <td>172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3574</th>\n",
              "      <td>Carmen Conde Abellán</td>\n",
              "      <td>\\n\\n¡Cuán hermosa tú, la desvelada!\\nTe lleva ...</td>\n",
              "      <td>LLUVIA EN MAYO</td>\n",
              "      <td>\\nLLUVIA EN MAYO\\n\\n\\n¡Cuán hermosa tú, la des...</td>\n",
              "      <td>470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1776</th>\n",
              "      <td>Jorge Debravo</td>\n",
              "      <td>\\n\\nHoy mi vida no tiene peso alguno:\\nes un v...</td>\n",
              "      <td>APUNTE INTERIOR</td>\n",
              "      <td>\\nAPUNTE INTERIOR\\n\\n\\nHoy mi vida no tiene pe...</td>\n",
              "      <td>570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3216</th>\n",
              "      <td>Alfredo Lavergne</td>\n",
              "      <td>Mientras buscamos\\nUn nombre al arte que dará ...</td>\n",
              "      <td>Camino</td>\n",
              "      <td>\\nCamino\\nMientras buscamos\\nUn nombre al arte...</td>\n",
              "      <td>192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1173</th>\n",
              "      <td>Lope de Vega</td>\n",
              "      <td>\\n\\nSilvio a una blanca corderilla suya,\\nde c...</td>\n",
              "      <td>Silvio a una blanca corderilla suya</td>\n",
              "      <td>\\nSilvio a una blanca corderilla suya\\n\\n\\nSil...</td>\n",
              "      <td>574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1710</th>\n",
              "      <td>Luis Cañizal de la Fuente</td>\n",
              "      <td>\\n\\n   Quién esconde palabras, quién escatima ...</td>\n",
              "      <td>LANDRE COMA</td>\n",
              "      <td>\\nLANDRE COMA\\n\\n\\n   Quién esconde palabras, ...</td>\n",
              "      <td>955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2678</th>\n",
              "      <td>Marilina Rébora</td>\n",
              "      <td>\\n\\nA bautizarse acuden las gentes al Jordán.\\...</td>\n",
              "      <td>SAN JUAN BAUTISTA</td>\n",
              "      <td>\\nSAN JUAN BAUTISTA\\n\\n\\nA bautizarse acuden l...</td>\n",
              "      <td>734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>923</th>\n",
              "      <td>Ismael Enrique Arciniegas</td>\n",
              "      <td>\\n\\nYa aspiro los aromas de su huerto;\\nLas br...</td>\n",
              "      <td>EN SUEÑOS</td>\n",
              "      <td>\\nEN SUEÑOS\\n\\n\\nYa aspiro los aromas de su hu...</td>\n",
              "      <td>785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4902</th>\n",
              "      <td>Manuel Altolaguirre</td>\n",
              "      <td>\\n\\n¡Qué sola estabas por dentro!\\n\\nCuando me...</td>\n",
              "      <td>BESO</td>\n",
              "      <td>\\nBESO\\n\\n\\n¡Qué sola estabas por dentro!\\n\\nC...</td>\n",
              "      <td>387</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3530 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb5b0679-59f2-4aad-9e63-94c9c864a802')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bb5b0679-59f2-4aad-9e63-94c9c864a802 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bb5b0679-59f2-4aad-9e63-94c9c864a802');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(poems_filtered['string'])[3])"
      ],
      "metadata": {
        "id": "QRpHDSqjhS56",
        "outputId": "d98617db-97ea-4797-9fa4-65b618b36758",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "APUNTE INTERIOR\n",
            "\n",
            "\n",
            "Hoy mi vida no tiene peso alguno:\n",
            "es un viento, menos que un viento, menos\n",
            "que una raya de luz.\n",
            "                                       Ahora ninguno\n",
            "puede serme oneroso.\n",
            "                                                  No hay terrenos\n",
            "resquemores debajo de mi alma.\n",
            "\n",
            "Mi sangre es una roja armonía viva.\n",
            "Estoy en armonía con la brasa y la calma,\n",
            "con la voz amorosa y la voz vengativa.\n",
            "\n",
            "Parece que mis manos no existieran, parece\n",
            "que mi cuerpo nadara en un agua inocente.\n",
            "Como un viento desnudo de mi corazón se mece\n",
            "y hace sonar campanadas dulcemente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tokens para los datos (modelo DeepESP/gpt2-spanish)**"
      ],
      "metadata": {
        "id": "F2gZ7FTsiC70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = poems_filtered['string'] # Datos\n",
        "# Tokenizador del modelo pre entrenado ----------------------------------------\\\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(modelo_gpt)\n",
        "special_tokens_dict = {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'pad_token': '<PAD>'}\n",
        "num_added_tokens = tokenizer.add_special_tokens(special_tokens_dict)"
      ],
      "metadata": {
        "id": "z8C56b9OqUPG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizador del modelo ------------------------------------------------------\\\n",
        "class DataTokens(Dataset):\n",
        "  def __init__(self, data, tokenizer, gpt2_type=\"gpt2\", max_length=max_length):\n",
        "    self.tokenizer = tokenizer\n",
        "    self.input_ids = []\n",
        "    self.attn_masks = []\n",
        "    for row in data:\n",
        "      self.encodings_dict = self.tokenizer('<BOS>' + row + '<EOS>', padding=\"max_length\", truncation=True, max_length=max_length)\n",
        "      self.input_ids.append(torch.tensor(self.encodings_dict['input_ids']))\n",
        "      self.attn_masks.append(torch.tensor(self.encodings_dict['attention_mask']))\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "  def __getitem__(self, idx):\n",
        "    return self.input_ids[idx], self.attn_masks[idx]\n",
        "# Clase de los datos ----------------------------------------------------------\\\n",
        "class DataModule():\n",
        "  # Definimos un tamaño de lote en la clase\n",
        "  def __init__(self, dataset, tokenizer, gpt2_type=\"gpt2\", p = 0.8):\n",
        "      super(DataModule,self).__init__()\n",
        "      self.dataset = dataset\n",
        "      self.tokenizer = tokenizer\n",
        "      self.p = p\n",
        "      self.gpt2_type = gpt2_type\n",
        "  # Definimos el tratamiento de los datos\n",
        "  def train_val_split(self, split, dataset):\n",
        "    train_size = int(split * len(dataset))\n",
        "    val_size = len(dataset) - train_size\n",
        "    return train_size, val_size\n",
        "  def setup(self, stage=None):\n",
        "    self.dataset = DataTokens(self.dataset, self.tokenizer, gpt2_type=self.gpt2_type)\n",
        "    train_size, val_size = self.train_val_split(self.p, self.dataset)\n",
        "    self.train_dataset, self.val_dataset = random_split(self.dataset, [train_size, val_size])\n",
        "  # Iterable de entrenamiento\n",
        "  def train_dataloader(self, batch_size = 32):\n",
        "      return torch.utils.data.DataLoader(self.train_dataset, batch_size=batch_size)\n",
        "  # Iterable de validacion\n",
        "  def val_dataloader(self, batch_size = 32):\n",
        "      return torch.utils.data.DataLoader(self.val_dataset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "baMTYb6qxl7o"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reentrenamiento para el modelo (DeepESP/gpt2-spanish)**"
      ],
      "metadata": {
        "id": "Vw0DxarOic-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fijar semillas --------------------------------------------------------------\\\n",
        "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)"
      ],
      "metadata": {
        "id": "9-XZRfiNsyDT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b390f5e4-dba5-4ee9-8728-bb278d15492a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f8d7d2801b0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accumulated batch size (since GPT2 is so big)\n",
        "def pack_tensor(new_tensor, packed_tensor, max_seq_len):\n",
        "    if packed_tensor is None:\n",
        "        return new_tensor, True, None\n",
        "    if new_tensor[0].size()[1] + packed_tensor[0].size()[1] > max_seq_len:\n",
        "        return packed_tensor, False, new_tensor\n",
        "    else:\n",
        "        packed_tensor = [torch.cat([new_tensor[0], packed_tensor[0][:, 1:]], dim=1)\n",
        "          ,torch.cat([new_tensor[1], packed_tensor[1][:, 1:]], dim=1)]\n",
        "        return packed_tensor, True, None\n",
        "# Entrenamiento del modelo ----------------------------------------------------\\\n",
        "class Trainer_poet():\n",
        "    def __init__(self, dataset, model, batch_size=16, epochs=5, learning_rate = 1e-4, eps = 1e-8, warmup_steps=50):\n",
        "      # DataLoaders\n",
        "      self.data_loader = dataset\n",
        "      self.data_loader.setup()\n",
        "      self.train_dataloader = self.data_loader.train_dataloader(batch_size = 1)\n",
        "      self.val_dataloader = self.data_loader.val_dataloader(batch_size = 1)\n",
        "      # Modelo\n",
        "      self.model = model\n",
        "      self.batch_size = batch_size\n",
        "      self.epochs = epochs\n",
        "      self.optimizer = AdamW(model.parameters(), lr=learning_rate, eps=eps)\n",
        "      total_steps = len(self.train_dataloader) * epochs\n",
        "      self.scheduler = get_linear_schedule_with_warmup(optimizer=self.optimizer,num_warmup_steps=warmup_steps,num_training_steps=total_steps)\n",
        "    def train(self):\n",
        "      device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "      model = self.model\n",
        "      optimizer =  self.optimizer\n",
        "      scheduler = self.scheduler\n",
        "      model.to(device)\n",
        "      model.train()\n",
        "      start_time = time.time()\n",
        "      training_stats = []\n",
        "      # Entrenamiento\n",
        "      print('Inicio entrenamiento ....')\n",
        "      train_dataloader = self.train_dataloader\n",
        "      val_dataloader = self.val_dataloader\n",
        "      for epoch_i in range(self.epochs):\n",
        "        print(f'Epoch {epoch_i + 1} de {self.epochs}')\n",
        "        t0 = time.time()\n",
        "        total_train_loss = 0\n",
        "        input_tensor = None\n",
        "        accumulating_batch_count = 0\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "          (input_tensor, carry_on, remainder) = pack_tensor(batch, input_tensor, 768)\n",
        "          if carry_on and step != len(train_dataloader) - 1: continue\n",
        "\n",
        "          b_input_ids = input_tensor[0].to(device)\n",
        "          b_masks = input_tensor[1].to(device)\n",
        "          input_tensor = [b_input_ids, b_masks]\n",
        "          outputs = model(b_input_ids,labels=b_input_ids,attention_mask=b_masks)\n",
        "          loss = outputs[0]\n",
        "          loss.backward()\n",
        "          if (accumulating_batch_count % self.batch_size) == 0:\n",
        "            batch_loss = loss.item()\n",
        "            total_train_loss += batch_loss\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "            model.zero_grad()\n",
        "          accumulating_batch_count += 1\n",
        "          input_tensor = None\n",
        "        avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "        training_time = format_time(time.time() - t0)\n",
        "        print(f'Average Training Loss: {avg_train_loss}. Epoch Training Time: {training_time}')\n",
        "        # Validacion\n",
        "        t0 = time.time()\n",
        "        model.eval()\n",
        "        total_eval_loss = 0\n",
        "        nb_eval_steps = 0\n",
        "        for batch in val_dataloader:\n",
        "          b_input_ids = batch[0].to(device)\n",
        "          b_masks = batch[1].to(device)\n",
        "          with torch.no_grad():\n",
        "            outputs  = model(b_input_ids,attention_mask=b_masks,labels=b_input_ids)\n",
        "            loss = outputs[0]\n",
        "          batch_loss = loss.item()\n",
        "          total_eval_loss += batch_loss\n",
        "        avg_val_loss = total_eval_loss / len(val_dataloader)\n",
        "        validation_time = format_time(time.time() - t0) \n",
        "        print(f'Average Validation Loss: {avg_val_loss}')\n",
        "        # Guardar estadisticas\n",
        "        training_stats.append(\n",
        "            {\n",
        "              'epoch': epoch_i + 1,\n",
        "              'Training Loss': avg_train_loss,\n",
        "              'Valid. Loss': avg_val_loss,\n",
        "              'Training Time': training_time,\n",
        "              'Validation Time': validation_time\n",
        "             }\n",
        "          )\n",
        "      self.training_stats = training_stats\n",
        "      self.model = model\n",
        "      print(f'Total Training Time: {format_time(time.time()-start_time)}')\n",
        "      return model"
      ],
      "metadata": {
        "id": "Vu3otaqQO0kO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "configuration = GPT2Config(vocab_size=len(tokenizer), n_positions=max_length).from_pretrained(modelo_gpt, output_hidden_states=True)\n",
        "model_gpt2_esp = GPT2LMHeadModel.from_pretrained(modelo_gpt, config=configuration)\n",
        "model_gpt2_esp.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "Dataset = DataModule(df, tokenizer, gpt2_type=modelo_gpt)\n",
        "Trainer_model = Trainer_poet(Dataset, model_gpt2_esp, epochs=15, batch_size=32)"
      ],
      "metadata": {
        "id": "f4PX7_szsFOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Trainer_model.train()\n",
        "torch.save(model, 'modelo_gpt2_poesia.pt')"
      ],
      "metadata": {
        "id": "x-bpHQUuRVnc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a17ef507-429d-401d-a9b1-80183b6f7951"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inicio entrenamiento ....\n",
            "Epoch 1 de 15\n",
            "Average Training Loss: 0.03861743366878701. Epoch Training Time: 0:04:21\n",
            "Average Validation Loss: 0.675128022905323\n",
            "Epoch 2 de 15\n",
            "Average Training Loss: 0.010056267384302514. Epoch Training Time: 0:04:12\n",
            "Average Validation Loss: 0.6165350283002718\n",
            "Epoch 3 de 15\n",
            "Average Training Loss: 0.009423496352017939. Epoch Training Time: 0:04:12\n",
            "Average Validation Loss: 0.6023391436141713\n",
            "Epoch 4 de 15\n",
            "Average Training Loss: 0.009071878967516484. Epoch Training Time: 0:04:12\n",
            "Average Validation Loss: 0.5964555137819761\n",
            "Epoch 5 de 15\n",
            "Average Training Loss: 0.008792536538991307. Epoch Training Time: 0:04:12\n",
            "Average Validation Loss: 0.593659351133971\n",
            "Epoch 6 de 15\n",
            "Average Training Loss: 0.008532874283536466. Epoch Training Time: 0:04:12\n",
            "Average Validation Loss: 0.5925637610235566\n",
            "Epoch 7 de 15\n",
            "Average Training Loss: 0.008276351041585292. Epoch Training Time: 0:04:12\n",
            "Average Validation Loss: 0.5927099464804187\n",
            "Epoch 8 de 15\n",
            "Average Training Loss: 0.008015219668301071. Epoch Training Time: 0:04:12\n",
            "Average Validation Loss: 0.5939618242751522\n",
            "Epoch 9 de 15\n",
            "Average Training Loss: 0.007743168978426848. Epoch Training Time: 0:04:12\n",
            "Average Validation Loss: 0.5962222820839108\n",
            "Epoch 10 de 15\n",
            "Average Training Loss: 0.007457815904814022. Epoch Training Time: 0:04:12\n",
            "Average Validation Loss: 0.5994201746766611\n",
            "Epoch 11 de 15\n",
            "Average Training Loss: 0.007153434990232457. Epoch Training Time: 0:04:12\n",
            "Average Validation Loss: 0.603563602971541\n",
            "Epoch 12 de 15\n",
            "Average Training Loss: 0.006827256170024953. Epoch Training Time: 0:04:12\n",
            "Average Validation Loss: 0.6084818428978535\n",
            "Epoch 13 de 15\n",
            "Average Training Loss: 0.006477057535422929. Epoch Training Time: 0:04:12\n",
            "Average Validation Loss: 0.6146002298025758\n",
            "Epoch 14 de 15\n",
            "Average Training Loss: 0.006103258397926184. Epoch Training Time: 0:04:12\n",
            "Average Validation Loss: 0.6218882607501898\n",
            "Epoch 15 de 15\n",
            "Average Training Loss: 0.005697134742381383. Epoch Training Time: 0:04:12\n",
            "Average Validation Loss: 0.6307455219813852\n",
            "Total Training Time: 1:14:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_stats = pd.DataFrame(data=Trainer_model.training_stats)\n",
        "df_stats"
      ],
      "metadata": {
        "id": "hpYPUv2Yw63B",
        "outputId": "56475ba9-82fe-45b5-bad9-24a7d8349598",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    epoch  Training Loss  Valid. Loss Training Time Validation Time\n",
              "0       1       0.038617     0.675128       0:04:21         0:00:44\n",
              "1       2       0.010056     0.616535       0:04:12         0:00:44\n",
              "2       3       0.009423     0.602339       0:04:12         0:00:44\n",
              "3       4       0.009072     0.596456       0:04:12         0:00:44\n",
              "4       5       0.008793     0.593659       0:04:12         0:00:44\n",
              "5       6       0.008533     0.592564       0:04:12         0:00:44\n",
              "6       7       0.008276     0.592710       0:04:12         0:00:44\n",
              "7       8       0.008015     0.593962       0:04:12         0:00:44\n",
              "8       9       0.007743     0.596222       0:04:12         0:00:44\n",
              "9      10       0.007458     0.599420       0:04:12         0:00:44\n",
              "10     11       0.007153     0.603564       0:04:12         0:00:44\n",
              "11     12       0.006827     0.608482       0:04:12         0:00:44\n",
              "12     13       0.006477     0.614600       0:04:12         0:00:44\n",
              "13     14       0.006103     0.621888       0:04:12         0:00:44\n",
              "14     15       0.005697     0.630746       0:04:12         0:00:44"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fa29a24c-d9ae-41a6-a7fe-554ee3b8e910\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.038617</td>\n",
              "      <td>0.675128</td>\n",
              "      <td>0:04:21</td>\n",
              "      <td>0:00:44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.010056</td>\n",
              "      <td>0.616535</td>\n",
              "      <td>0:04:12</td>\n",
              "      <td>0:00:44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.009423</td>\n",
              "      <td>0.602339</td>\n",
              "      <td>0:04:12</td>\n",
              "      <td>0:00:44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.009072</td>\n",
              "      <td>0.596456</td>\n",
              "      <td>0:04:12</td>\n",
              "      <td>0:00:44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.008793</td>\n",
              "      <td>0.593659</td>\n",
              "      <td>0:04:12</td>\n",
              "      <td>0:00:44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>0.008533</td>\n",
              "      <td>0.592564</td>\n",
              "      <td>0:04:12</td>\n",
              "      <td>0:00:44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>0.008276</td>\n",
              "      <td>0.592710</td>\n",
              "      <td>0:04:12</td>\n",
              "      <td>0:00:44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>0.008015</td>\n",
              "      <td>0.593962</td>\n",
              "      <td>0:04:12</td>\n",
              "      <td>0:00:44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>0.007743</td>\n",
              "      <td>0.596222</td>\n",
              "      <td>0:04:12</td>\n",
              "      <td>0:00:44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>0.007458</td>\n",
              "      <td>0.599420</td>\n",
              "      <td>0:04:12</td>\n",
              "      <td>0:00:44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>0.007153</td>\n",
              "      <td>0.603564</td>\n",
              "      <td>0:04:12</td>\n",
              "      <td>0:00:44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>0.006827</td>\n",
              "      <td>0.608482</td>\n",
              "      <td>0:04:12</td>\n",
              "      <td>0:00:44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>0.006477</td>\n",
              "      <td>0.614600</td>\n",
              "      <td>0:04:12</td>\n",
              "      <td>0:00:44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>0.006103</td>\n",
              "      <td>0.621888</td>\n",
              "      <td>0:04:12</td>\n",
              "      <td>0:00:44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>0.005697</td>\n",
              "      <td>0.630746</td>\n",
              "      <td>0:04:12</td>\n",
              "      <td>0:00:44</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa29a24c-d9ae-41a6-a7fe-554ee3b8e910')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fa29a24c-d9ae-41a6-a7fe-554ee3b8e910 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fa29a24c-d9ae-41a6-a7fe-554ee3b8e910');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure([\n",
        "        go.Scatter(x=df_stats['epoch'], y=df_stats['Training Loss'],name=\"Train\",hovertemplate=\"%{y}%{_xother}\")\n",
        "        ,go.Scatter(x=df_stats['epoch'], y=df_stats['Valid. Loss'],name=\"Val\",hovertemplate=\"%{y}%{_xother}\")\n",
        "        ])\n",
        "fig.update_layout(\n",
        "      xaxis_title=\"Epoch\",\n",
        "      yaxis_title='Loss',\n",
        "      hovermode=\"x unified\"\n",
        "  )\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "4jOBqfKmusC2",
        "outputId": "e37f24a2-328e-4d2d-b026-f832aeac6ebf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"56fd3ab6-891a-4124-bdd7-6cb25a196202\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"56fd3ab6-891a-4124-bdd7-6cb25a196202\")) {                    Plotly.newPlot(                        \"56fd3ab6-891a-4124-bdd7-6cb25a196202\",                        [{\"hovertemplate\":\"%{y}%{_xother}\",\"name\":\"Train\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],\"y\":[0.03861743366878701,0.010056267384302514,0.009423496352017939,0.009071878967516484,0.008792536538991307,0.008532874283536466,0.008276351041585292,0.008015219668301071,0.007743168978426848,0.007457815904814022,0.007153434990232457,0.006827256170024953,0.006477057535422929,0.006103258397926184,0.005697134742381383],\"type\":\"scatter\"},{\"hovertemplate\":\"%{y}%{_xother}\",\"name\":\"Val\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],\"y\":[0.675128022905323,0.6165350283002718,0.6023391436141713,0.5964555137819761,0.593659351133971,0.5925637610235566,0.5927099464804187,0.5939618242751522,0.5962222820839108,0.5994201746766611,0.603563602971541,0.6084818428978535,0.6146002298025758,0.6218882607501898,0.6307455219813852],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"title\":{\"text\":\"Epoch\"}},\"yaxis\":{\"title\":{\"text\":\"Loss\"}},\"hovermode\":\"x unified\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('56fd3ab6-891a-4124-bdd7-6cb25a196202');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Generación de Poesía**"
      ],
      "metadata": {
        "id": "8Tl7dP3niubb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('modelo_gpt2_poesia.pt')"
      ],
      "metadata": {
        "id": "AKftdGuSRz-K"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to('cpu')"
      ],
      "metadata": {
        "id": "JwhQFJCWCxL4",
        "outputId": "e596502a-c0ba-4b25-bf38-e27b72266452",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50260, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50260, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Generación de texto antes de entrenar el modelo**"
      ],
      "metadata": {
        "id": "xBHLfQ19tN_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "configuration = GPT2Config(vocab_size=len(tokenizer), n_positions=max_length).from_pretrained(modelo_gpt, output_hidden_states=True)\n",
        "model_gpt2esp = GPT2LMHeadModel.from_pretrained(modelo_gpt, config=configuration)\n",
        "model_gpt2esp.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "Palabra = 'MI MUERTE '\n",
        "input_ids = tokenizer.encode(Palabra, return_tensors=\"pt\")\n",
        "output = model_gpt2esp.generate(\n",
        "      input_ids,\n",
        "      do_sample=True,\n",
        "      top_k=50,\n",
        "      max_length=200,\n",
        "      top_p=0.95,\n",
        "      num_return_sequences=1\n",
        "  )\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "P8_yhYgWmKRB",
        "outputId": "7deb5f47-27ef-415e-b282-c535265bbc07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MI MUERTE _el otro extremo de una soga para la horca, que debe seguir al otro extremo de la soga, la que a partir de hoy puede ser el hilo del tormento. \n",
            "\n",
            "216\n",
            "\n",
            "En el camino de acceso al calabozo hay dos o tres compañeros que trabajan para otro preso: el primero es un condenado, pero no lo es el segundo. Al final de éste, el otro es un condenado de más de diez años que trabaja para otro preso, y el último es una mujer con hijos que se llama María de Jesús y que se llama Cecilia; al principio se ha intentado explicar el camino del suplicio, pero se ha llegado a un acuerdo porque no se ha llegado a saber exactamente quién es el condenado; lo único que le interesa es el lugar de suplicio donde se ha visto a un preso. También en las prisiones se hace referencia a las tres mujeres que se hacen pasar por allí en su coche oficial: Jesús y Cecilia, que a la vez han de ser vigil\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Generación de texto luego de entrenar el modelo**"
      ],
      "metadata": {
        "id": "Y6CRSTUquNyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Generate2(model,Palabra):\n",
        "  input_ids = tokenizer.encode(Palabra, return_tensors=\"pt\")\n",
        "  output = model.generate(\n",
        "      input_ids,\n",
        "      do_sample=True,\n",
        "      top_k=50,\n",
        "      max_length=200,\n",
        "      top_p=0.95,\n",
        "      num_return_sequences=1,\n",
        "      #temperature=1.5\n",
        "      #no_repeat_ngram_size=2,\n",
        "  )\n",
        "  output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "  return output"
      ],
      "metadata": {
        "id": "tUxkbcRVP2Fn"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Palabra = 'MI MUERTE'\n",
        "text = Generate2(model.to('cpu'),Palabra)\n",
        "print(text)"
      ],
      "metadata": {
        "id": "SQQ_9VMaSEL6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87682874-bf23-43e2-ab40-df0c3c9cf2f5"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MI MUERTE\n",
            "\n",
            "\n",
            "Yo vi pasar una barca\n",
            "desde el puerto,\n",
            "sobre un puente de barcas.\n",
            "Mi madre,\n",
            "la de los ojos llorosos,\n",
            "se detuvo a mirar la orilla\n",
            "de la lluvia.\n",
            "Entonces,\n",
            "mirando atrás,\n",
            "de un bote en bote a proa,\n",
            "la barca,\n",
            "me dijo:?-eng,\n",
            "¿qué te parece tu barca?\n",
            "?Vente, mar, mar,\n",
            "dejaré que la lleven\n",
            "entre sus barcas.\n",
            "Si es la barca de los pies llorosos,\n",
            "y las esmirriadas gaviotas,\n",
            "no me preguntes por qué,\n",
            "delante de las gentes,\n",
            "no me digas nada.\n",
            "\n",
            "lleva su barca, su barca, toda\n",
            "con la inscripción M. D. A LA CAMBIOSA DE LOS HIJOS\n",
            "\n",
            "Y no temas,\n",
            "que voy a tu barca a cambiar de\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Palabra = 'OCÉANO'\n",
        "text = Generate2(model.to('cpu'),Palabra)\n",
        "print(text)"
      ],
      "metadata": {
        "id": "qkG_ItxypMIi",
        "outputId": "0fc284b1-fb49-407d-90ce-281ee52af59c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OCÉANOCHE\n",
            "\n",
            "\n",
            "Como un bosque,\n",
            "como una flor,\n",
            "como una rosa,\n",
            "como una manzana\n",
            "como un vaso\n",
            "como un café.\n",
            "Tu alma te lo canta,\n",
            "y si no lo hace,\n",
            "es porque tu Dios\n",
            "no se lo piensa\n",
            "y lo único\n",
            "\n",
            " lo sabe.\n",
            "Todo su canto\n",
            "en la nieve\n",
            "en los pies le dice\n",
            "no hay nada:\n",
            "se está conteniendo\n",
            "y sus labios dicen\n",
            "tu boca dice\n",
            "tu boca es una hoja,\n",
            "\n",
            "y tus manos gritan\n",
            "hasta el fin...\n",
            "\n",
            "Sólo tu cuerpo,\n",
            "es la cosa,\n",
            "tu alma lo que dices,\n",
            "es la cosa,\n",
            "tu cuerpo lo que te dice...\n",
            "\n",
            "Sinceramente\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Palabra = 'MELANCOLÍA'\n",
        "text = Generate2(model.to('cpu'),Palabra)\n",
        "print(text)"
      ],
      "metadata": {
        "id": "QoXmojQ-pk7z",
        "outputId": "9137b0c8-69cb-4a3b-b9b4-f0a6e1525e73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MELANCOLÍA\n",
            "\n",
            "\n",
            "(Las hojas secas\n",
            "\n",
            "Las hojas secas y mojadas.)\n",
            "\n",
            "¿Qué hace el musgo en la tierra?\n",
            "\n",
            "No importa. Tiene un sabor amargo\n",
            "\n",
            "y un sabor vago.\n",
            "\n",
            "Sí, es la tierra seca la que lo limpia..\n",
            "                                                                                                                                  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Palabra = 'LUZ '\n",
        "text = Generate2(model.to('cpu'),Palabra)\n",
        "print(text)"
      ],
      "metadata": {
        "id": "EonjKid4FPP1",
        "outputId": "a88c640e-03e9-4ed2-b194-7cb36876eb25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LUZ  \n",
            "\n",
            "Las mariposas negras en la tarde\n",
            "teman tu cara.\n",
            "Las mariposas en la tarde\n",
            "teman tu piel.\n",
            "\n",
            "Las mariposas en la tarde\n",
            "teman tu alma.\n",
            "\n",
            "Las mariposas en la tarde\n",
            "teman tu rostro.\n",
            "\n",
            "Las mariposas en la tarde.\n",
            "\n",
            "Las flores en la tarde.\n",
            "\n",
            "Las golondrinas en la mañana.\n",
            "Las golondrinas en la tarde.\n",
            "Las golondrinas en la mañana.\n",
            "\n",
            "Las flores en la noche.\n",
            "\n",
            "Las golondrinas en la noche.\n",
            "Los mirlos en la noche.\n",
            "\n",
            "Las golondrinas en la noche.,\n",
            "ya se arreglarán las cosas.\n",
            "\n",
            "Cuando tú lo dijiste.\n",
            "?No hay flores en la noche.\n",
            "\n",
            "Ya están listos tus floreados trinos\n",
            "en que se hará cola mi flor.\n",
            "\n",
            "en el árbol a cuál le mirará el día\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Palabra = 'ESCUELA '\n",
        "text = Generate2(model.to('cpu'),Palabra)\n",
        "print(text)"
      ],
      "metadata": {
        "id": "UOFPTGcXFriJ",
        "outputId": "bdebaace-7710-4a5a-d86a-47f2dbfaf8c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ESCUELA \n",
            "\n",
            "Si el cristal tiene que hacer el amor \n",
            "tiene derecho a sentirse vivo. \n",
            "Si el tiempo tiene la facultad de hacer \n",
            "cómo borrar la línea de su vida \n",
            "qué puede borrarla de sus páginas. \n",
            "Si el aire tiene que borrar la línea de sus páginas. \n",
            "Si el agua tiene que borrar de sus páginas. \n",
            "Si el agua tiene que borrar de sus páginas las huellas de su nombre. \n",
            "Si el cielo tiene que borrar de sus páginas las huellas de su nombre. \n",
            "Si el aire tiene que borrar de su vida el nombre de sus páginas. \n",
            "Si el aire tiene que borrar de sus páginas las huellas de su nombre. \n",
            "Si el agua tiene que borrar de sus páginas las huellas de su nombre. \n",
            "Si el aire tiene que borrar de sus páginas las huellas de su nombre. \n",
            "Si el agua tiene que borrar de sus páginas las huellas de su nombre. \n",
            "Si el\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Palabra = 'amor '\n",
        "text = Generate2(model.to('cpu'),Palabra)\n",
        "print(text)"
      ],
      "metadata": {
        "id": "_pAyfJW8F9Ck",
        "outputId": "21fa3721-e4f2-48b2-b3cd-09e33bff6392",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "amor \n",
            "El amor es un poema \n",
            "que evoca el amor y es un poema \n",
            "o más bien un poema. \n",
            "Es un poema \n",
            "o más o menos la misma letra \n",
            "que evoca el amor y es la misma letra \n",
            "y menos la misma letra \n",
            "que aparece en el poema en el que las palabras \n",
            "lo forman en el poema \n",
            "que se transforma en la letra \n",
            "y los versos en otra letra \n",
            "la que transforma el poema \n",
            "y la letra en otra letra \n",
            "la que transforma el poema \n",
            "y las dos que transforma el poema \n",
            "y la letra \n",
            "y las dos que transforma el poema \n",
            "y el poema \n",
            " Y el poema \n",
            "  la última letra en otra letra \n",
            "la que transforma el poema \n",
            "y la letra en otra letra \n",
            "la que transforma el poema \n",
            "en otra caligrafía \n",
            "la que transforma el poema \n",
            "la que cambia el poema \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Palabra = 'CEMENTERIO'\n",
        "text = Generate2(model.to('cpu'),Palabra)\n",
        "print(text)"
      ],
      "metadata": {
        "id": "-dAi2qbLGJ0g",
        "outputId": "7481e477-0955-4cee-cf3a-5cb2dea56f3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CEMENTERIO DE LLEVAR\n",
            "\n",
            "\n",
            "El mar tiene tu mar\n",
            "y tu fuego es mi fuego\n",
            "y tu aire y tus cabellos\n",
            "y tu frente son mi mirada\n",
            "y tu boca son mis ojos?\n",
            "\n",
            "Mas mi corazón y mis riñones\n",
            "han afirmado no,\n",
            "no eran ya ni mi voz la voz\n",
            "y el mar es mi fuego y mi corazón\n",
            "y mi cuerpo mi música\n",
            "y tu voz mi fuego y tus cabellos\n",
            "y tu cabello tu piel\n",
            "y tus manos y tu rostro\n",
            "y tu cuerpo son tus pies y mi boca\n",
            "y tu frente\n",
            "\n",
            "El mar no es\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "94e7570899995adebab4ebab5cd3752e227f734c99b4f5f3f0d280f8bef09b63"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('IA')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "Gasolina.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}